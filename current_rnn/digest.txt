Directory structure:
└── current_rnn/
    ├── data_alm_current.py
    ├── debug.py
    ├── eval_current_alm.py
    ├── losses.py
    ├── main_train_alm_current.py
    ├── model_current.py
    ├── plotting.py
    ├── training_current.py
    └── utils_celltype.py

================================================
FILE: data_alm_current.py
================================================
# current_rnn/data_alm_current.py

import os
from typing import List, Optional, Dict, Any, Tuple

import numpy as np
import torch


def build_tone_waveform(
    T: int,
    fps: float,
    S_frame: int,
    sample_len_sec: float = 1.15,
    on_sec: float = 0.15,
    off_sec: float = 0.10,
    n_bursts: int = 5,
) -> np.ndarray:
    
    x = np.zeros(T, dtype=np.float32)

    on_frames = int(round(on_sec * fps))
    off_frames = int(round(off_sec * fps))
    sample_frames = int(round(sample_len_sec * fps))

    start = int(S_frame)
    end = min(T, start + sample_frames)

    t = start
    for k in range(n_bursts):
        if t >= end:
            break
        # ON
        t_on_end = min(end, t + on_frames)
        x[t:t_on_end] = 1.0
        t = t_on_end
        # OFF (last burst can omit off)
        if k < n_bursts - 1:
            t_off_end = min(end, t + off_frames)
            # already zeros
            t = t_off_end

    return x

def _normalize_cond_names(arr) -> List[str]:
    """
    Ensure cond_names loaded from npz is a list of Python strings.
    """
    if isinstance(arr, np.ndarray):
        # Could be array of bytes/str/object
        return [str(x) for x in arr.tolist()]
    # Fallback
    return [str(x) for x in list(arr)]


def build_dale_mask_from_types(is_excitatory: np.ndarray) -> torch.Tensor:
    """
    return dale_mask: [N, N]：
        excitatory → J[:, j] >= 0  (mask = +1)
        inhibitory → J[:, j] <= 0  (mask = -1)
    """
    N = is_excitatory.shape[0]
    dale_mask = np.zeros((N, N), dtype=np.int8)

    exc_idx = np.where(is_excitatory)[0]
    inh_idx = np.where(~is_excitatory)[0]

    # excitatory columns
    dale_mask[:, exc_idx] = 1
    # inhibitory columns
    dale_mask[:, inh_idx] = -1

    # do not constrain self-connection
    np.fill_diagonal(dale_mask, 0)

    return torch.from_numpy(dale_mask)

def load_alm_psth_npz(
    npz_path: str,
    cond_filter: Optional[List[str]] = None,
    max_time: Optional[int] = None,
    device: Optional[torch.device] = None,
    dtype: torch.dtype = torch.float32,
) -> Tuple[torch.Tensor, Dict[str, Any]]:
    """
    Load trial-averaged PSTH and metadata from a Stage 1 .npz file
    produced by alm_data/0.average.py.

    The .npz is expected to contain (see 0.average.py):
        - session_id, plane, animal
        - cond_names: array of condition names (keys of cell_psth)
        - cell_psth: dict[name] -> ndarray (cells, time)
        - cell_clusters, cell_subclasses
        - fps, t0_frame, event_frames, pre_frames, post_frames
        - keep_idx, n_cells_before
        - cond_counts, source_used, pkl_key_used, ...

    This function:
        1) Selects conditions to use (e.g. ['left_correct', 'right_correct']).
        2) Builds a tensor psth of shape [C, T, N], where:
           - C = number of selected conditions
           - T = number of time points (optionally truncated by max_time)
           - N = number of neurons after cell-type filtering
        3) Returns (psth, meta), where psth is a torch.Tensor and meta is a dict.

    Args:
        npz_path:   path to the Stage 1 npz file.
        cond_filter:
            - If None: try to use ['left_correct', 'right_correct'] if present,
              otherwise use all available conditions found in cell_psth.
            - If list: use the intersection of this list with available keys.
              If nothing matches, raise ValueError.
        max_time:
            - If not None: truncate time dimension to [0:max_time] frames.
        device:
            - Optional torch device to move psth tensor onto.
        dtype:
            - torch dtype for the returned psth.

    Returns:
        psth: torch.Tensor of shape [C, T, N]
        meta: dict containing metadata and numpy arrays (celltype info, etc.)
    """
    if not os.path.isfile(npz_path):
        raise FileNotFoundError(f"npz file not found: {npz_path}")

    data = np.load(npz_path, allow_pickle=True)

    # -------------------------------------------------------------------------
    # Condition names & cell_psth
    # -------------------------------------------------------------------------
    cond_names_all = _normalize_cond_names(data["cond_names"])
    cell_psth_obj = data["cell_psth"]
    # cell_psth was saved as a dict (object array), need .item() to recover
    if isinstance(cell_psth_obj, np.ndarray):
        cell_psth: Dict[str, np.ndarray] = cell_psth_obj.item()
    else:
        cell_psth = cell_psth_obj

    # --- decide which conditions to use ---
    if cond_filter is None:
        preferred = ["left_correct", "right_correct"]
        cond_names = [c for c in preferred if c in cell_psth]
        if not cond_names:
            # fallback: use all conditions that actually exist in cell_psth
            cond_names = [c for c in cond_names_all if c in cell_psth]
    else:
        cond_names = [c for c in cond_filter if c in cell_psth]
        if not cond_names:
            raise ValueError(
                f"No requested conditions {cond_filter} found in cell_psth keys "
                f"({list(cell_psth.keys())})."
            )

    if not cond_names:
        raise ValueError(
            f"No valid conditions found in npz file {npz_path}. "
            "Check that 0.average.py produced non-empty cell_psth."
        )

    # -------------------------------------------------------------------------
    # Build PSTH array: [C, T, N]
    # Each cell_psth[name] has shape (cells, time)
    # We transpose to (T, N) and then stack -> (C, T, N)
    # -------------------------------------------------------------------------
    psth_list = []
    T_min = None
    N = None

    # First pass: ensure all conditions have consistent (cells, time)
    for name in cond_names:
        M = cell_psth[name]  # (cells, time)
        if M is None:
            raise ValueError(f"cell_psth['{name}'] is None in {npz_path}")

        if N is None:
            N = M.shape[0]
        elif M.shape[0] != N:
            raise ValueError(
                f"Inconsistent neuron count among conditions in {npz_path}: "
                f"condition '{name}' has {M.shape[0]} cells, expected {N}."
            )

        if T_min is None:
            T_min = M.shape[1]
        else:
            T_min = min(T_min, M.shape[1])

    # If max_time is specified, clip by max_time; otherwise use min length across conditions
    if max_time is not None:
        T = min(T_min, max_time)
    else:
        T = T_min

    for name in cond_names:
        M = cell_psth[name]  # (cells, time)
        M = M[:, :T]         # truncate time if needed -> (N, T)
        M = M.T              # (T, N)
        psth_list.append(M)

    # stack to get (C, T, N)
    psth_np = np.stack(psth_list, axis=0)
    psth = torch.as_tensor(psth_np, dtype=dtype)
    if device is not None:
        psth = psth.to(device)

    # -------------------------------------------------------------------------
    # Collect metadata for later analyses
    # -------------------------------------------------------------------------
    # Cell-type info
    cell_clusters = np.asarray(data["cell_clusters"])
    cell_subclasses = np.asarray(data["cell_subclasses"])
    # some npz also stores 'cell_types'; keep if present
    cell_types = np.asarray(data["cell_types"]) if "cell_types" in data else cell_clusters

    # Time / alignment info
    fps = float(data["fps"])
    t0_frame = int(data["t0_frame"])
    pre_frames = int(data["pre_frames"])
    post_frames = int(data["post_frames"])

    # event_frames saved as a dict -> unwrap
    event_frames_obj = data["event_frames"]
    if isinstance(event_frames_obj, np.ndarray):
        # usually a 0-d object array containing a dict
        event_frames = event_frames_obj.item()
    else:
        event_frames = event_frames_obj

    # Index mapping and counts
    keep_idx = np.asarray(data["keep_idx"], dtype=int)
    n_cells_before = int(data["n_cells_before"])
    cond_counts_obj = data["cond_counts"]
    if isinstance(cond_counts_obj, np.ndarray):
        cond_counts = cond_counts_obj.item()
    else:
        cond_counts = cond_counts_obj

    # Session-level info
    session_id = str(data["session_id"])
    plane = str(data["plane"])
    animal = str(data["animal"])
    align_to = str(data["align_to"])
    source_used = str(data["source_used"])
    pkl_key_used = str(data["pkl_key_used"])

    meta: Dict[str, Any] = {
        # Core dimensions
        "cond_names": cond_names,
        "all_cond_names": cond_names_all,
        "C": len(cond_names),
        "T": T,
        "N": N,

        # Time / alignment
        "fps": fps,
        "t0_frame": t0_frame,
        "pre_frames": pre_frames,
        "post_frames": post_frames,
        "event_frames": event_frames,  # dict like {'S': ss, 'D': ld, 'R': go}
        "align_to": align_to,

        # Cell-type / indexing
        "cell_clusters": cell_clusters,
        "cell_subclasses": cell_subclasses,
        "cell_types": cell_types,
        "keep_idx": keep_idx,
        "n_cells_before": n_cells_before,

        # Condition counts (per condition)
        "cond_counts": cond_counts,

        # Session identifiers
        "session_id": session_id,
        "plane": plane,
        "animal": animal,

        # Provenance
        "source_used": source_used,
        "pkl_key_used": pkl_key_used,
        "npz_path": os.path.abspath(npz_path),
    }

    return psth, meta



================================================
FILE: debug.py
================================================
#!/usr/bin/env python
'''
python debug.py --npz /home/jingyi.xu/ALM/results/stage1/kd95/psth_20220823_205730.0.npz --go_only

'''
import argparse
import numpy as np


def _find_cond_idx(cond_names, target):
    target = target.lower()
    for i, n in enumerate(cond_names):
        if str(n).lower() == target:
            return i
    raise ValueError(f"Condition '{target}' not found in cond_names: {cond_names}")


def _summarize_one(name, t, lickL, lickR, rew, go_only=True):
    if go_only:
        m = (t >= 0)
        tag = "post-go"
    else:
        m = slice(None)
        tag = "all"

    # peak and mean in post-go window
    peakL = float(np.max(lickL[m]))
    peakR = float(np.max(lickR[m]))
    meanL = float(np.mean(lickL[m]))
    meanR = float(np.mean(lickR[m]))
    peakRew = float(np.max(rew[m]))
    meanRew = float(np.mean(rew[m]))

    # dominance (use peak; mean is also printed)
    dom = "LEFT" if peakL > peakR else ("RIGHT" if peakR > peakL else "TIE")
    ratio = float((peakL + 1e-9) / (peakR + 1e-9))

    print(f"[{name}] ({tag}) "
          f"lick_peak L={peakL:.3f} R={peakR:.3f}  "
          f"lick_mean L={meanL:.3f} R={meanR:.3f}  "
          f"reward_peak={peakRew:.3f} reward_mean={meanRew:.3f}  "
          f"dominant={dom}  peak(L/R)={ratio:.3f}")

    return dom, peakL, peakR, peakRew


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--npz", required=True, help="stage1 psth npz (updated with lick/reward fields)")
    ap.add_argument("--go_only", action="store_true", help="Only evaluate t_rel_go_sec>=0 window (recommended)")
    ap.add_argument("--min_reward_peak", type=float, default=0.2,
                    help="Minimum expected reward peak (heuristic) to call it 'present'")
    args = ap.parse_args()

    z = np.load(args.npz, allow_pickle=True)

    # required fields
    cond_names = z["cond_names"].tolist()
    t = np.asarray(z["t_rel_go_sec"], float)
    lickL_all = np.asarray(z["lick_rate_left"], float)    # [C,T]
    lickR_all = np.asarray(z["lick_rate_right"], float)   # [C,T]
    rew_all = np.asarray(z["reward_trace"], float)        # [C,T]

    iLC = _find_cond_idx(cond_names, "left_correct")
    iRC = _find_cond_idx(cond_names, "right_correct")

    print(f"[INFO] npz={args.npz}")
    print(f"[INFO] C={len(cond_names)} T={lickL_all.shape[1]}  "
          f"LC idx={iLC}  RC idx={iRC}")
    print(f"[INFO] pre-go reward max = {float(np.max(rew_all[:, t < 0])):.6f}")
    print(f"[INFO] post-go reward max = {float(np.max(rew_all[:, t >= 0])):.6f}")
    print("")

    domLC, lcL, lcR, lcRew = _summarize_one(
        "left_correct", t, lickL_all[iLC], lickR_all[iLC], rew_all[iLC], go_only=args.go_only
    )
    domRC, rcL, rcR, rcRew = _summarize_one(
        "right_correct", t, lickL_all[iRC], lickR_all[iRC], rew_all[iRC], go_only=args.go_only
    )

    print("\n[CHECK] Expected symmetry:")
    print("  - left_correct: LEFT should dominate (lick_left > lick_right), reward should be present")
    print("  - right_correct: RIGHT should dominate (lick_right > lick_left), reward should be present\n")

    ok_LC = (domLC == "LEFT") and (lcRew >= args.min_reward_peak)
    ok_RC = (domRC == "RIGHT") and (rcRew >= args.min_reward_peak)

    if ok_LC and ok_RC:
        print("[OK] LC/RC symmetry looks consistent. No swap likely needed.")
        return

    # Heuristic suggestion: if dominance is flipped (LC looks RIGHT-dominant and RC looks LEFT-dominant),
    # then p1/p2 (or left/right assignment) is likely swapped.
    flipped = (domLC == "RIGHT") and (domRC == "LEFT")
    if flipped:
        print("[WARN] Dominance appears flipped (LC is RIGHT-dominant, RC is LEFT-dominant).")
        print("       This strongly suggests left/right channels are swapped.")
        print("       Recommended action: re-run build_lick_reward_trace.py with --swap_p1_p2 and overwrite npz.")
    else:
        print("[WARN] Symmetry check failed but not a clean flip.")
        if domLC != "LEFT":
            print(f"       LC dominant={domLC} (expected LEFT).")
        if domRC != "RIGHT":
            print(f"       RC dominant={domRC} (expected RIGHT).")
        if lcRew < args.min_reward_peak or rcRew < args.min_reward_peak:
            print("       Reward peak is low in at least one condition; check reward_mode, only_correct, and alignment.")
        print("       Next step: print trial-level lick counts (or inspect licks.npy structure) to confirm mapping.")

if __name__ == "__main__":
    main()



================================================
FILE: eval_current_alm.py
================================================
# current_rnn/eval_current_alm.py
# Supports:
#   (A) single-session eval: --npz <stage1_npz>
#   (B) batch eval across registry: --eval_all --registry_dir <dir> --animal <id>
#
# Plots:
#   - One mosaic figure containing all selected neurons (each neuron is one subplot),
#     and time axis restricted to the SAME time_mask used in training (sample+delay+resp).
#   - In batch mode, neurons are sampled uniformly from all sessions' inhibitory units.
'''
python eval_current_alm.py --eval_all --registry_dir /home/jingyi.xu/ALM/results/registry/kd95 --animal kd95 --n_exc_virtual 800 --model /home/jingyi.xu/code_rnn/results_current/20251230/rnn_current_kd95_global_nobs200_nexc800_ntotal1000.pt --psth_bin_ms 200 --sample_ignore_ms 50 --resp_sec 2.0 --out_dir /home/jingyi.xu/code_rnn/results_global/eval_kd95

'''
from __future__ import annotations

import argparse
import csv
import json
import math
import os
import random
from collections import defaultdict
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Sequence, Tuple

import numpy as np
import torch as tch
import matplotlib.pyplot as plt
import heapq


from data_alm_current import load_alm_psth_npz  # returns psth [C,T,N] + meta dict
from model_current import ALMCurrentRNN
from training_current import (
    _load_default_parameters,
    _maybe_attach_lick_reward_to_meta,
    _build_input_tensor,
    _time_bin_smooth_ctn,
    _build_time_mask_sample_delay_resp,
)

# -----------------------------
# Plot utilities
# -----------------------------
import numpy as np
from typing import Any, Dict, Tuple, Optional

def compute_time_mask_tsec_zero_at_R(
    meta: Dict[str, Any],
    T: int,
    sample_ignore_ms: float,
    resp_sec: float,
) -> Tuple[np.ndarray, np.ndarray, Dict[str, float]]:
    """
    Returns:
      mask_np: [T] bool, same loss window mask as training.
      t_sec:   [Tm] float, seconds for masked indices, with R(go cue) as t=0.
      ev_sec:  dict of event times in seconds relative to R, e.g. {"S":..., "D":..., "R":0.0}
    """
    fps = float(meta["fps"])

    # same mask builder as training (you already use it in eval)
    m = _build_time_mask_sample_delay_resp(
        T=T,
        fps=fps,
        meta=meta,
        sample_ignore_ms=float(sample_ignore_ms),
        resp_sec=float(resp_sec),
    )
    idx = np.where(m)[0]  # indices kept by mask

    ev = meta.get("event_frames", {}) or {}
    # robustly fetch event frames
    def _get_ev_frame(name: str, default: int) -> int:
        if isinstance(ev, dict) and (name in ev):
            return int(ev[name])
        return int(default)

    S = _get_ev_frame("S", 0)
    D = _get_ev_frame("D", S)
    R = _get_ev_frame("R", D)  # go cue

    # time axis in seconds for masked indices, zeroed at R
    t_sec = (idx - R) / fps

    # event lines in seconds relative to R
    ev_sec = {
        "S": (S - R) / fps,
        "D": (D - R) / fps,
        "R": 0.0,
    }
    return m, t_sec, ev_sec

import os
import math
import numpy as np
import torch as tch
import matplotlib.pyplot as plt
from typing import Optional, Sequence, Dict

def plot_psth_comparison_R0_with_events(
    t_sec: np.ndarray,
    psth_used: tch.Tensor,          # [C, Tm, N]
    rates_used: tch.Tensor,         # [C, Tm, N]
    idx_neurons: Sequence[int],
    mse_per_neuron: Optional[np.ndarray],
    cond_names: Sequence[str],
    out_path: str,
    ncols: int = 6,
    title: Optional[str] = None,
    event_sec: Optional[Dict[str, float]] = None,  # {"S":..., "D":..., "R":0.0}
    show_event_labels: bool = True,
    event_linewidth: float = 0.8,
) -> None:
    """
    Mosaic plot:
      - x-axis: seconds, with R(go cue) as t=0 (caller must pass t_sec computed that way).
      - draws vertical event lines for S/D/R if event_sec is provided
      - removes y=0 horizontal reference line (no axhline)
      - GT solid, Fit dashed, same color per condition (as in your current function)
    """
    idx_neurons = list(map(int, idx_neurons))
    n_sel = len(idx_neurons)
    if n_sel == 0:
        raise ValueError("idx_neurons is empty.")

    C = int(psth_used.shape[0])
    if C < 2:
        raise ValueError(f"Expected at least 2 conditions (LC/RC). Got C={C}.")

    ncols = max(1, int(ncols))
    nrows = int(math.ceil(n_sel / ncols))

    fig_w = 3.2 * ncols
    fig_h = 2.6 * nrows
    fig, axes = plt.subplots(
        nrows, ncols, figsize=(fig_w, fig_h),
        squeeze=False, sharex=False, sharey=False
    )

    cond0 = str(cond_names[0]) if len(cond_names) > 0 else "cond0"
    cond1 = str(cond_names[1]) if len(cond_names) > 1 else "cond1"

    for i, n in enumerate(idx_neurons):
        r = i // ncols
        c = i % ncols
        ax = axes[r][c]

        gt0 = psth_used[0, :, n].detach().cpu().numpy()
        pr0 = rates_used[0, :, n].detach().cpu().numpy()
        gt1 = psth_used[1, :, n].detach().cpu().numpy()
        pr1 = rates_used[1, :, n].detach().cpu().numpy()

        # Same-condition same-color: draw GT first, reuse its color for Fit
        l0, = ax.plot(t_sec, gt0, label=f"{cond0} GT")
        ax.plot(t_sec, pr0, linestyle="--", color=l0.get_color(), label=f"{cond0} Fit")

        l1, = ax.plot(t_sec, gt1, label=f"{cond1} GT")
        ax.plot(t_sec, pr1, linestyle="--", color=l1.get_color(), label=f"{cond1} Fit")

        # --- event lines (S/D/R), with R as 0 ---
        if event_sec is not None:
            # draw R line (t=0) emphasized slightly
            if "R" in event_sec:
                ax.axvline(float(event_sec["R"]), linestyle="-", linewidth=event_linewidth)
            if "S" in event_sec:
                ax.axvline(float(event_sec["S"]), linestyle=":", linewidth=event_linewidth)
            if "D" in event_sec:
                ax.axvline(float(event_sec["D"]), linestyle="--", linewidth=event_linewidth)

            if show_event_labels:
                # put small labels near top-left region inside axes
                y0, y1 = ax.get_ylim()
                y_text = y1 - 0.05 * (y1 - y0)
                # only label within visible x-range
                xmin, xmax = ax.get_xlim()
                for key in ["S", "D", "R"]:
                    if key in event_sec:
                        x = float(event_sec[key])
                        if xmin <= x <= xmax:
                            ax.text(x, y_text, key, fontsize=7, ha="center", va="top")

        # title
        if mse_per_neuron is not None:
            ax.set_title(f"n={n}  mse={float(mse_per_neuron[n]):.2e}", fontsize=9)
        else:
            ax.set_title(f"n={n}", fontsize=9)

        # IMPORTANT: remove y=0 line (do NOT draw axhline)
        # ax.axhline(0.0, linewidth=0.5)  # removed

        if i == 0:
            ax.legend(fontsize=8, loc="best")

    # hide unused axes
    for j in range(n_sel, nrows * ncols):
        rr = j // ncols
        cc = j % ncols
        axes[rr][cc].axis("off")

    if title is not None:
        fig.suptitle(title, fontsize=12)

    fig.tight_layout()
    os.makedirs(os.path.dirname(out_path) or ".", exist_ok=True)
    fig.savefig(out_path, dpi=200)
    plt.close(fig)
    print(f"[OK] Saved mosaic figure -> {out_path}")

def plot_psth_comparison(
    t_sec: np.ndarray,
    psth_used: tch.Tensor,          # [C, Tm, Nsel]
    rates_used: tch.Tensor,         # [C, Tm, Nsel]
    idx_neurons: Sequence[int],
    mse_per_neuron: Optional[np.ndarray],
    cond_names: Sequence[str],
    out_path: str,
    ncols: int = 6,
    title: Optional[str] = None,
) -> None:
    """
    A single large figure that tiles all selected neurons into a grid.
    Each subplot contains:
      - LC ground-truth vs prediction
      - RC ground-truth vs prediction
    Time axis is already restricted to the training time_mask.
    """
    idx_neurons = list(map(int, idx_neurons))
    n_sel = len(idx_neurons)
    if n_sel == 0:
        raise ValueError("idx_neurons is empty.")

    C = int(psth_used.shape[0])
    if C < 2:
        raise ValueError(f"Expected at least 2 conditions (LC/RC). Got C={C}.")

    ncols = max(1, int(ncols))
    nrows = int(math.ceil(n_sel / ncols))

    fig_w = 3.2 * ncols
    fig_h = 2.6 * nrows
    fig, axes = plt.subplots(nrows, ncols, figsize=(fig_w, fig_h), squeeze=False, sharex=False, sharey=False)

    cond0 = str(cond_names[0]) if len(cond_names) > 0 else "cond0"
    cond1 = str(cond_names[1]) if len(cond_names) > 1 else "cond1"

    for i, n in enumerate(idx_neurons):
        r = i // ncols
        c = i % ncols
        ax = axes[r][c]

        gt0 = psth_used[0, :, n].detach().cpu().numpy()
        pr0 = rates_used[0, :, n].detach().cpu().numpy()
        gt1 = psth_used[1, :, n].detach().cpu().numpy()
        pr1 = rates_used[1, :, n].detach().cpu().numpy()

        l0, = ax.plot(t_sec, gt0, label=f"{cond0} GT")                  # GT 实线
        ax.plot(t_sec, pr0, linestyle="--", color=l0.get_color(),       # Fit 虚线，同色
        label=f"{cond0} Fit")

        l1, = ax.plot(t_sec, gt1, label=f"{cond1} GT")
        ax.plot(t_sec, pr1, linestyle="--", color=l1.get_color(),
        label=f"{cond1} Fit")


        if mse_per_neuron is not None:
            ax.set_title(f"n={n}  mse={float(mse_per_neuron[n]):.2e}", fontsize=9)
        else:
            ax.set_title(f"n={n}", fontsize=9)

        ax.axhline(0.0, linewidth=0.5)
        if i == 0:
            ax.legend(fontsize=8, loc="best")

    # hide unused axes
    for j in range(n_sel, nrows * ncols):
        r = j // ncols
        c = j % ncols
        axes[r][c].axis("off")

    if title is not None:
        fig.suptitle(title, fontsize=12)

    fig.tight_layout()
    os.makedirs(os.path.dirname(out_path) or ".", exist_ok=True)
    fig.savefig(out_path, dpi=200)
    plt.close(fig)
    print(f"[OK] Saved mosaic figure -> {out_path}")


def _select_neurons_by_mse(
    psth_used: tch.Tensor,   # [C,Tm,N]
    rates_used: tch.Tensor,  # [C,Tm,N]
    num_neurons: int,
    mode: str,
    rng_seed: int,
) -> Tuple[tch.Tensor, np.ndarray]:
    """
    mode:
      - best:  choose neurons with smallest MSE
      - worst: choose neurons with largest MSE
      - random: random subset
    """
    with tch.no_grad():
        err = (psth_used - rates_used) ** 2
        mse = err.mean(dim=(0, 1)).detach().cpu().numpy()  # [N]

    N = int(mse.shape[0])
    k = min(int(num_neurons), N)
    if k <= 0:
        raise ValueError("num_neurons must be > 0.")

    if mode == "best":
        idx = np.argsort(mse)[:k]
    elif mode == "worst":
        idx = np.argsort(mse)[-k:][::-1]
    elif mode == "random":
        rng = np.random.default_rng(int(rng_seed))
        idx = rng.choice(N, size=k, replace=False)
    else:
        raise ValueError(f"Unknown mode={mode}")

    idx_t = tch.as_tensor(idx, dtype=tch.long)
    return idx_t, mse


# -----------------------------
# Registry helpers (batch eval)
# -----------------------------

@dataclass
class RegistryRow:
    unit_key: str
    global_idx: int
    array_idx: int
    npz_path: str

def _read_registry_csv(registry_dir: str, animal: str) -> List[RegistryRow]:
    """
    Expected columns include: unit_key, global_idx, array_idx, npz_path
    (others are ignored).
    """
    cand1 = os.path.join(registry_dir, f"{animal}_registry.csv")
    cand2 = os.path.join(registry_dir, "registry.csv")
    path = cand1 if os.path.exists(cand1) else cand2
    if not os.path.exists(path):
        raise FileNotFoundError(f"Registry CSV not found: {cand1} or {cand2}")

    rows: List[RegistryRow] = []
    with open(path, "r", newline="") as f:
        reader = csv.DictReader(f)
        for rr in reader:
            rows.append(
                RegistryRow(
                    unit_key=str(rr["unit_key"]),
                    global_idx=int(float(rr["global_idx"])),
                    array_idx=int(float(rr["array_idx"])),
                    npz_path=str(rr["npz_path"]),
                )
            )
    if len(rows) == 0:
        raise ValueError(f"Empty registry: {path}")
    print(f"[INFO] Loaded registry: {path} (rows={len(rows)})")
    return rows


def _build_keepidx_pos_map(keep_idx: np.ndarray) -> Dict[int, int]:
    keep_idx = np.asarray(keep_idx, dtype=int)
    return {int(a): int(i) for i, a in enumerate(keep_idx.tolist())}


def _group_rows_by_unit(rows: List[RegistryRow]) -> Dict[str, List[RegistryRow]]:
    by_unit: Dict[str, List[RegistryRow]] = defaultdict(list)
    for r in rows:
        by_unit[r.unit_key].append(r)
    return by_unit


# -----------------------------
# Eval core
# -----------------------------

def _infer_device(params_path: Optional[str]) -> tch.device:
    default_parameters = _load_default_parameters(params_path)
    device_str = default_parameters.get("device", "cpu")
    device = tch.device(device_str if tch.cuda.is_available() or device_str == "cpu" else "cpu")
    return device


def _build_model_for_eval(
    model_path: str,
    D_in: int,
    N_total: int,
    params_path: Optional[str],
    device: tch.device,
) -> ALMCurrentRNN:
    default_parameters = _load_default_parameters(params_path)
    dt = float(default_parameters.get("dt", 1.0))
    tau = float(default_parameters.get("tau", 1.0))
    substeps = int(default_parameters.get("substeps", 1))

    net = ALMCurrentRNN(
        N=int(N_total),
        D_in=int(D_in),
        dt=dt,
        tau=tau,
        substeps=substeps,
        nonlinearity="tanh",
        device=device,
        dale_mask=None,  # eval 不强制 Dale；即便训练用了，也不需要从 ckpt 里恢复这块
    ).to(device)

    ckpt = tch.load(model_path, map_location=device)

    # 兼容两种保存格式：
    # (A) 直接保存 state_dict
    # (B) 保存 {"model": state_dict, "opt": ..., ...}
    if isinstance(ckpt, dict) and ("model" in ckpt) and isinstance(ckpt["model"], dict):
        state_dict = ckpt["model"]
    else:
        state_dict = ckpt

    # 清理不应由 checkpoint 驱动的条目
    if isinstance(state_dict, dict) and "dale_mask" in state_dict:
        state_dict = dict(state_dict)  # copy
        state_dict.pop("dale_mask", None)

    # 更稳妥：如果还有其他多余 key，也不应让 eval 崩溃
    missing, unexpected = net.load_state_dict(state_dict, strict=False)
    if len(unexpected) > 0:
        print(f"[WARN] Unexpected keys ignored: {unexpected[:10]}{' ...' if len(unexpected) > 10 else ''}")
    if len(missing) > 0:
        print(f"[WARN] Missing keys (left default): {missing[:10]}{' ...' if len(missing) > 10 else ''}")

    net.eval()
    return net



def _compute_time_mask_and_tsec(
    meta: Dict[str, Any],
    T: int,
    sample_ignore_ms: float,
    resp_sec: float,
) -> Tuple[np.ndarray, np.ndarray]:
    fps = float(meta["fps"])
    m = _build_time_mask_sample_delay_resp(
        T=T,
        fps=fps,
        meta=meta,
        sample_ignore_ms=float(sample_ignore_ms),
        resp_sec=float(resp_sec),
    )
    idx = np.where(m)[0]
    ev = meta.get("event_frames", {})
    S = int(ev["S"]) if isinstance(ev, dict) and "S" in ev else 0
    t_sec = (idx - S) / fps
    return m, t_sec


def eval_single_session(
    npz_path: str,
    model_path: str,
    params_path: Optional[str],
    noise_std: float,
    psth_bin_ms: float,
    sample_ignore_ms: float,
    resp_sec: float,
    num_neurons: int,
    mode: str,
    rng_seed: int,
    out_dir: Optional[str],
    device: tch.device,
) -> None:
    default_parameters = _load_default_parameters(params_path)

    psth, meta = load_alm_psth_npz(
        npz_path=npz_path,
        cond_filter=None,
        max_time=None,
        device=device,
        dtype=tch.float32,
    )
    C, T, N = psth.shape
    meta = _maybe_attach_lick_reward_to_meta(meta=meta, npz_path=npz_path, T=T)

    fps = float(meta.get("fps", 1.0))
    if psth_bin_ms is not None and float(psth_bin_ms) > 0:
        psth = _time_bin_smooth_ctn(psth, fps=fps, bin_ms=float(psth_bin_ms))

    cond_names = list(meta["cond_names"])
    amp_input = float(default_parameters.get("amp_input", 1.0))
    include_go_cue = bool(default_parameters.get("include_go_cue", True))
    go_cue_sec = float(default_parameters.get("go_cue_sec", 0.10))
    amp_go_cue = float(default_parameters.get("amp_go_cue", 1.0))
    include_reward = bool(default_parameters.get("include_reward", True))
    amp_reward = float(default_parameters.get("amp_reward", 1.0))

    u = _build_input_tensor(
        C=C,
        T=T,
        cond_names=cond_names,
        device=device,
        amp_input=amp_input,
        meta=meta,
        amp_stim=amp_input,
        sample_len_sec=1.15,
        on_sec=0.15,
        off_sec=0.10,
        n_bursts=5,
        include_go_cue=include_go_cue,
        go_cue_sec=go_cue_sec,
        amp_go_cue=amp_go_cue,
        include_reward=include_reward,
        amp_reward=amp_reward,
    )
    D_in = int(u.shape[-1])

    # NOTE: single-session eval assumes the model's N_total == N in npz
    net = _build_model_for_eval(
        model_path=model_path,
        D_in=D_in,
        N_total=N,
        params_path=params_path,
        device=device,
    )

    with tch.no_grad():
        out = net(u, h0=None, noise_std=float(noise_std), return_rate=True)
        rates_pred = out["rate"]  # [C,T,N]
        if psth_bin_ms is not None and float(psth_bin_ms) > 0:
            rates_pred = _time_bin_smooth_ctn(rates_pred, fps=fps, bin_ms=float(psth_bin_ms))

    mask_np, t_sec, ev_sec = compute_time_mask_tsec_zero_at_R(
    meta=meta, T=T,
    sample_ignore_ms=sample_ignore_ms,
    resp_sec=resp_sec,
    )
    psth_used = psth[:, mask_np, :]
    rates_used = rates_pred[:, mask_np, :]

    idx_sel, mse = _select_neurons_by_mse(
        psth_used=psth_used,
        rates_used=rates_used,
        num_neurons=int(num_neurons),
        mode=str(mode),
        rng_seed=int(rng_seed),
    )

    model_tag = os.path.splitext(os.path.basename(model_path))[0]
    save_dir = out_dir or os.path.dirname(model_path) or "."
    out_png = os.path.join(save_dir, f"psth_eval_loss_window_{model_tag}.png")

    plot_psth_comparison_R0_with_events(
    t_sec=t_sec,
    psth_used=psth_used,
    rates_used=rates_used,
    idx_neurons=idx_sel.tolist(),
    mse_per_neuron=mse,
    cond_names=cond_names,
    out_path=out_png,
    ncols=6,
    title=f"{model_tag}  unit={os.path.basename(npz_path)}  window=loss (R=0)",
    event_sec=ev_sec,
    show_event_labels=True,
    )


def eval_all_units_from_registry(
    registry_dir: str,
    animal: str,
    model_path: str,
    params_path: Optional[str],
    n_exc_virtual: int,
    noise_std: float,
    psth_bin_ms: float,
    sample_ignore_ms: float,
    resp_sec: float,
    plot_n: int,
    plot_seed: int,   # 保留参数兼容CLI；best策略下不会影响结果（除非出现完全相等的极少数tie）
    plot_cols: int,
    out_dir: str,
    device: tch.device,
) -> None:
    """
    Batch eval across all units in registry.

    - Computes per-unit loss (MSE on training loss window).
    - For plotting: selects global Top-K neurons with the smallest MSE across ALL sessions' inhibitory neurons,
      and saves ONE mosaic figure.
    - GT and Fit for the same condition share the same color (GT solid, Fit dashed).

    Plot style update:
      - x-axis is zeroed at R(go cue): t=0 at R
      - draw event lines S/D/R
      - remove y=0 horizontal line
    """
    import heapq

    os.makedirs(out_dir, exist_ok=True)

    # -----------------------------
    # Local helper: time mask + t_sec (R=0) + event lines (sec)
    # -----------------------------
    def _compute_time_mask_tsec_R0_and_events(
        meta: Dict[str, Any],
        T: int,
        sample_ignore_ms: float,
        resp_sec: float,
    ) -> Tuple[np.ndarray, np.ndarray, Dict[str, float]]:
        fps = float(meta.get("fps", 1.0))
        m = _build_time_mask_sample_delay_resp(
            T=T,
            fps=fps,
            meta=meta,
            sample_ignore_ms=float(sample_ignore_ms),
            resp_sec=float(resp_sec),
        )
        idx = np.where(m)[0]
        ev = meta.get("event_frames", {}) or {}

        def _get_ev_frame(name: str, default_val: int) -> int:
            if isinstance(ev, dict) and (name in ev):
                try:
                    return int(ev[name])
                except Exception:
                    return int(default_val)
            return int(default_val)

        S = _get_ev_frame("S", 0)
        D = _get_ev_frame("D", S)
        R = _get_ev_frame("R", D)  # if missing R, fallback to D; if missing D, fallback to S; else 0

        t_sec = (idx - R) / fps
        ev_sec = {"S": (S - R) / fps, "D": (D - R) / fps, "R": 0.0}
        return m, t_sec, ev_sec

    # -----------------------------
    # Load registry and group by unit
    # -----------------------------
    rows = _read_registry_csv(registry_dir=registry_dir, animal=animal)
    by_unit = _group_rows_by_unit(rows)

    # -----------------------------
    # Infer N_total and D_in directly from checkpoint (most reliable)
    # -----------------------------
    ckpt = tch.load(model_path, map_location=device)
    if isinstance(ckpt, dict) and ("model" in ckpt) and isinstance(ckpt["model"], dict):
        state_dict = ckpt["model"]
    else:
        state_dict = ckpt

    # remove training-only keys if present
    if isinstance(state_dict, dict) and "dale_mask" in state_dict:
        state_dict = dict(state_dict)
        state_dict.pop("dale_mask", None)

    if "J" not in state_dict or "W_in" not in state_dict:
        raise KeyError(
            "Cannot infer N_total / D_in from checkpoint. "
            "Expected keys 'J' and 'W_in' in state_dict."
        )

    N_total = int(state_dict["J"].shape[0])
    D_in_ckpt = int(state_dict["W_in"].shape[1])

    # Build model once
    net = _build_model_for_eval(
        model_path=model_path,
        D_in=D_in_ckpt,
        N_total=N_total,
        params_path=params_path,
        device=device,
    )
    print(f"[INFO] Loaded model: N_total={N_total}, D_in={D_in_ckpt}")

    # -----------------------------
    # Eval accumulators
    # -----------------------------
    per_unit_stats: List[Dict[str, Any]] = []

    # Global Top-K best neurons across all sessions:
    # store (-mse, counter, record)
    plot_k = int(plot_n)
    top_heap: List[Tuple[float, int, Dict[str, Any]]] = []
    counter = 0

    # -----------------------------
    # Iterate units
    # -----------------------------
    default_parameters = _load_default_parameters(params_path)
    amp_input = float(default_parameters.get("amp_input", 1.0))
    include_go_cue = bool(default_parameters.get("include_go_cue", True))
    go_cue_sec = float(default_parameters.get("go_cue_sec", 0.10))
    amp_go_cue = float(default_parameters.get("amp_go_cue", 1.0))
    include_reward = bool(default_parameters.get("include_reward", True))
    amp_reward = float(default_parameters.get("amp_reward", 1.0))

    for unit_key, items in by_unit.items():
        # all rows in a unit should share same npz_path
        npz_path = items[0].npz_path
        for rr in items[1:]:
            if rr.npz_path != npz_path:
                raise ValueError(f"unit_key={unit_key} has inconsistent npz_path in registry.")

        # load PSTH + meta
        psth, meta = load_alm_psth_npz(
            npz_path=npz_path,
            cond_filter=None,
            max_time=None,
            device=device,
            dtype=tch.float32,
        )
        C, T, N_kept = psth.shape
        meta = _maybe_attach_lick_reward_to_meta(meta=meta, npz_path=npz_path, T=T)

        fps = float(meta.get("fps", 1.0))

        # time bin / smooth (apply to both GT and prediction to match your training setting)
        if psth_bin_ms is not None and float(psth_bin_ms) > 0:
            psth = _time_bin_smooth_ctn(psth, fps=fps, bin_ms=float(psth_bin_ms))

        # map registry array_idx -> position in keep_idx
        keep_idx = meta.get("keep_idx", None)
        if keep_idx is None:
            raise KeyError(f"meta['keep_idx'] missing in stage1 npz: {npz_path}")
        keep_map = _build_keepidx_pos_map(np.asarray(keep_idx, dtype=int))

        pos_list: List[int] = []
        g_list: List[int] = []
        for rr in items:
            ai = int(rr.array_idx)
            if ai not in keep_map:
                raise ValueError(
                    f"array_idx={ai} not found in keep_idx of {npz_path} (unit_key={unit_key}). "
                    "Check registry builder mapping."
                )
            pos_list.append(int(keep_map[ai]))
            g_list.append(int(rr.global_idx))

        pos_t = tch.as_tensor(pos_list, dtype=tch.long, device=device)
        psth_sub = psth.index_select(dim=2, index=pos_t)  # [C,T,K]
        K = int(psth_sub.shape[2])

        # build input u with meta (must match training)
        cond_names = list(meta["cond_names"])
        u = _build_input_tensor(
            C=C,
            T=T,
            cond_names=cond_names,
            device=device,
            amp_input=amp_input,
            meta=meta,
            amp_stim=amp_input,
            sample_len_sec=1.15,
            on_sec=0.15,
            off_sec=0.10,
            n_bursts=5,
            include_go_cue=include_go_cue,
            go_cue_sec=go_cue_sec,
            amp_go_cue=amp_go_cue,
            include_reward=include_reward,
            amp_reward=amp_reward,
        )

        D_in = int(u.shape[-1])
        if D_in != D_in_ckpt:
            raise ValueError(
                f"D_in mismatch for unit_key={unit_key}: built u has D_in={D_in}, "
                f"but checkpoint expects D_in={D_in_ckpt}. "
                "This means your eval input construction differs from training."
            )

        # indices into the global net: offset inhibitory by n_exc_virtual
        idx_net = tch.as_tensor(
            [int(n_exc_virtual) + int(g) for g in g_list],
            dtype=tch.long,
            device=device,
        )

        # forward
        with tch.no_grad():
            out = net(u, h0=None, noise_std=float(noise_std), return_rate=True)
            rates_full = out["rate"]  # [C,T,N_total]
            if psth_bin_ms is not None and float(psth_bin_ms) > 0:
                rates_full = _time_bin_smooth_ctn(rates_full, fps=fps, bin_ms=float(psth_bin_ms))
            pred_sub = rates_full.index_select(dim=2, index=idx_net)  # [C,T,K]

        # time mask (same as training loss window) + t_sec zeroed at R
        mask_np, t_sec, ev_sec = _compute_time_mask_tsec_R0_and_events(
            meta=meta, T=T, sample_ignore_ms=sample_ignore_ms, resp_sec=resp_sec
        )
        mask_t = tch.as_tensor(mask_np.astype(np.bool_), device=device)

        # compute unit loss and per-neuron MSE (on loss window)
        with tch.no_grad():
            diff = (pred_sub[:, mask_t, :] - psth_sub[:, mask_t, :]) ** 2  # [C,Tm,K]
            unit_loss = float(diff.mean().detach().cpu().item())
            mse_neuron = diff.mean(dim=(0, 1)).detach().cpu().numpy()  # [K]

        per_unit_stats.append(
            {
                "unit_key": unit_key,
                "npz_path": npz_path,
                "K": int(K),
                "loss_mse": float(unit_loss),
                "mse_neuron_mean": float(np.mean(mse_neuron)),
                "mse_neuron_median": float(np.median(mse_neuron)),
            }
        )

        # -----------------------------
        # Update global Top-K best neurons for plotting
        # criterion: smallest mse_neuron (loss window)
        # Only materialize traces when the candidate can enter Top-K
        # -----------------------------
        if plot_k > 0:
            cond0 = str(cond_names[0]) if len(cond_names) > 0 else "cond0"
            cond1 = str(cond_names[1]) if len(cond_names) > 1 else "cond1"

            # heap stores (-mse, ...), so -heap[0][0] is the largest mse inside Top-K
            thr = (-top_heap[0][0]) if len(top_heap) >= plot_k else float("inf")

            for local_i in range(K):
                mse_i = float(mse_neuron[local_i])
                if (len(top_heap) < plot_k) or (mse_i < thr):
                    # materialize traces (on loss window)
                    gt0 = psth_sub[0, mask_t, local_i].detach().cpu().numpy()
                    pr0 = pred_sub[0, mask_t, local_i].detach().cpu().numpy()
                    gt1 = psth_sub[1, mask_t, local_i].detach().cpu().numpy()
                    pr1 = pred_sub[1, mask_t, local_i].detach().cpu().numpy()

                    rec = {
                        "unit_key": unit_key,
                        "npz_base": os.path.basename(npz_path),
                        "local_i": int(local_i),
                        "mse": float(mse_i),
                        "t_sec": t_sec,        # R=0
                        "ev_sec": ev_sec,      # S/D/R relative to R
                        "cond0": cond0,
                        "cond1": cond1,
                        "gt0": gt0,
                        "pr0": pr0,
                        "gt1": gt1,
                        "pr1": pr1,
                    }

                    counter += 1
                    heapq.heappush(top_heap, (-mse_i, counter, rec))
                    if len(top_heap) > plot_k:
                        heapq.heappop(top_heap)

                    thr = (-top_heap[0][0]) if len(top_heap) >= plot_k else float("inf")

    # -----------------------------
    # Save per-unit stats + summary
    # -----------------------------
    if len(per_unit_stats) == 0:
        raise ValueError("No units evaluated (empty registry?)")

    model_tag = os.path.splitext(os.path.basename(model_path))[0]

    csv_path = os.path.join(out_dir, f"eval_per_unit_{model_tag}.csv")
    with open(csv_path, "w", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=list(per_unit_stats[0].keys()))
        writer.writeheader()
        for r in per_unit_stats:
            writer.writerow(r)
    print(f"[OK] Saved per-unit stats -> {csv_path}")

    losses = np.array([r["loss_mse"] for r in per_unit_stats], dtype=float)
    summary = {
        "animal": animal,
        "model": model_path,
        "registry_dir": registry_dir,
        "n_units": int(len(per_unit_stats)),
        "n_exc_virtual": int(n_exc_virtual),
        "N_total": int(N_total),
        "D_in": int(D_in_ckpt),
        "psth_bin_ms": float(psth_bin_ms),
        "sample_ignore_ms": float(sample_ignore_ms),
        "resp_sec": float(resp_sec),
        "noise_std": float(noise_std),
        "loss_mean": float(np.mean(losses)),
        "loss_median": float(np.median(losses)),
        "loss_min": float(np.min(losses)),
        "loss_max": float(np.max(losses)),
        "plot_strategy": "best_global_topk",
        "plot_n": int(plot_k),
        "time_zero": "R(go_cue)",
        "event_lines": {"S": ":", "D": "--", "R": "-"},
    }
    json_path = os.path.join(out_dir, f"eval_summary_{model_tag}.json")
    with open(json_path, "w") as f:
        json.dump(summary, f, indent=2)
    print(f"[OK] Saved summary -> {json_path}")

    # -----------------------------
    # Build and save ONE mosaic figure using Top-K best neurons
    # -----------------------------
    picked_records = [x[2] for x in top_heap]
    picked_records.sort(key=lambda r: float(r["mse"]))  # best first

    if len(picked_records) == 0:
        print("[WARN] plot_n=0 or no candidates selected; skip mosaic plotting.")
        return

    ncols = max(1, int(plot_cols))
    nrows = int(math.ceil(len(picked_records) / ncols))
    fig, axes = plt.subplots(nrows, ncols, figsize=(3.2 * ncols, 2.6 * nrows), squeeze=False)

    for i, rec in enumerate(picked_records):
        r = i // ncols
        c = i % ncols
        ax = axes[r][c]

        t = rec["t_sec"]     # already R=0
        ev = rec.get("ev_sec", None)

        # Same-condition same-color: draw GT first, reuse its color for Fit
        l0, = ax.plot(t, rec["gt0"], label=f"{rec['cond0']} GT")  # solid
        ax.plot(t, rec["pr0"], linestyle="--", color=l0.get_color(), label=f"{rec['cond0']} Fit")

        l1, = ax.plot(t, rec["gt1"], label=f"{rec['cond1']} GT")
        ax.plot(t, rec["pr1"], linestyle="--", color=l1.get_color(), label=f"{rec['cond1']} Fit")

        # --- event lines (relative to R) ---
        if isinstance(ev, dict):
            # R at 0
            if "R" in ev:
                ax.axvline(float(ev["R"]), linestyle="-", linewidth=0.8)
            if "S" in ev:
                ax.axvline(float(ev["S"]), linestyle=":", linewidth=0.8)
            if "D" in ev:
                ax.axvline(float(ev["D"]), linestyle="--", linewidth=0.8)

        # IMPORTANT: remove y=0 line (do NOT draw axhline)
        ax.set_title(
            f"{rec['unit_key']} i={rec['local_i']} mse={float(rec['mse']):.2e}",
            fontsize=8,
        )
        if i == 0:
            ax.legend(fontsize=8, loc="best")

    # hide unused axes
    for j in range(len(picked_records), nrows * ncols):
        rr = j // ncols
        cc = j % ncols
        axes[rr][cc].axis("off")

    fig.suptitle(f"{model_tag}  BEST neurons across all sessions (loss window, R=0)", fontsize=12)
    fig.tight_layout()

    png_path = os.path.join(out_dir, f"psth_eval_all_best_mosaic_{model_tag}_R0.png")
    fig.savefig(png_path, dpi=200)
    plt.close(fig)
    print(f"[OK] Saved best-mosaic -> {png_path}")


# -----------------------------
# CLI
# -----------------------------

def main() -> None:
    ap = argparse.ArgumentParser()

    ap.add_argument("--model", type=str, required=True, help="Path to trained model .pt")
    ap.add_argument("--params", type=str, default=None, help="Path to params json/yaml used by training (optional)")

    g = ap.add_mutually_exclusive_group(required=True)
    g.add_argument("--npz", type=str, default=None, help="Stage1 psth_*.npz (single-session eval)")
    g.add_argument("--eval_all", action="store_true", help="Evaluate all units in registry (batch)")

    ap.add_argument("--registry_dir", type=str, default=None)
    ap.add_argument("--animal", type=str, default=None)
    ap.add_argument("--n_exc_virtual", type=int, default=0)

    ap.add_argument("--noise_std", type=float, default=0.05)
    ap.add_argument("--psth_bin_ms", type=float, default=200.0)
    ap.add_argument("--sample_ignore_ms", type=float, default=50.0)
    ap.add_argument("--resp_sec", type=float, default=2.0)

    ap.add_argument("--num_neurons", type=int, default=30)
    ap.add_argument("--mode", default="random", choices=["best", "worst", "random"])
    ap.add_argument("--rng_seed", type=int, default=42)

    ap.add_argument("--plot_n", type=int, default=72)
    ap.add_argument("--plot_seed", type=int, default=42)
    ap.add_argument("--plot_cols", type=int, default=6)

    ap.add_argument("--out_dir", type=str, default=None)

    args = ap.parse_args()

    device = _infer_device(args.params)
    print(f"[INFO] device={device}")

    save_dir = args.out_dir or (os.path.dirname(args.model) or ".")
    os.makedirs(save_dir, exist_ok=True)

    if args.eval_all:
        if args.registry_dir is None or args.animal is None:
            raise ValueError("--eval_all requires --registry_dir and --animal")
        eval_all_units_from_registry(
            registry_dir=args.registry_dir,
            animal=args.animal,
            model_path=args.model,
            params_path=args.params,
            n_exc_virtual=int(args.n_exc_virtual),
            noise_std=float(args.noise_std),
            psth_bin_ms=float(args.psth_bin_ms),
            sample_ignore_ms=float(args.sample_ignore_ms),
            resp_sec=float(args.resp_sec),
            plot_n=int(args.plot_n),
            plot_seed=int(args.plot_seed),
            plot_cols=int(args.plot_cols),
            out_dir=save_dir,
            device=device,
        )
    else:
        assert args.npz is not None
        eval_single_session(
            npz_path=args.npz,
            model_path=args.model,
            params_path=args.params,
            noise_std=float(args.noise_std),
            psth_bin_ms=float(args.psth_bin_ms),
            sample_ignore_ms=float(args.sample_ignore_ms),
            resp_sec=float(args.resp_sec),
            num_neurons=int(args.num_neurons),
            mode=str(args.mode),
            rng_seed=int(args.rng_seed),
            out_dir=save_dir,
            device=device,
        )


if __name__ == "__main__":
    main()



================================================
FILE: losses.py
================================================
import torch as tch 
import numpy as np




class LossSparsity:
    def __init__(self, device):
        self.device = device
        self.l1_loss = tch.nn.L1Loss()

    def __call__(self, net):
        J_rec = net.J_rec
        total_loss = self.l1_loss(J_rec, tch.zeros(J_rec.shape).to(self.device))
        return total_loss

class SelectivityLoss:
    def __init__(self, rates, params_dict):
        self.dt = params_dict['dt']
        self.t_min_input = params_dict['t_min_input']
        self.t_max_input = params_dict['t_max_input']
        self.t_start = params_dict['t_start']
        self.t_go = params_dict['t_go']
        self.ind_delay = int((self.t_max_input- self.t_start)/self.dt)
        self.ind_sample = int((self.t_min_input - self.t_start)/self.dt)
        self.ind_go = int((self.t_go - self.t_start)/self.dt)
        self.d_ind = int(0.6/self.dt)
        self.compute_factors(rates)
        self.gram_schmidt(rates)
        self.cos =  tch.nn.CosineSimilarity(dim=0)
        self.mode_sample = 0
        self.mode_delay = 1
        self.mode_choice = 2
        self.alpha_delay = 1.5
        
    def __call__(self, net):
        #sample vectors
        net_sample_alm = net.decoder_alm[self.mode_sample,:]
        #delay vectors
        net_delay_alm = net.decoder_alm[self.mode_delay,:]
        #choice vectors
        net_choice_alm = net.decoder_alm[self.mode_choice,:]

        #losses
        loss_sample = (1 - self.cos(net_sample_alm, self.sample_alm))
        loss_delay = (1 - self.cos(net_delay_alm, self.delay_alm))
        loss_choice = (1 - self.cos(net_choice_alm, self.choice_alm))

        total_loss = (loss_sample + self.alpha_delay * loss_delay + loss_choice )/3.
        return total_loss

    def compute_factors(self, rates):
        self._sample_vectors(rates)
        self._delay_vectors(rates)
        self._choice_vectors(rates)

    def gram_schmidt(self, rates):
        self._sample_vectors(rates)
        self._delay_vectors(rates)
        self._choice_vectors(rates)
        vectors = tch.stack([self.sample_alm, self.delay_alm, self.choice_alm], dim=1) 
        # Perform QR decomposition for orthonormalization
        Q, R = tch.linalg.qr(vectors)

        # Q now contains the orthonormalized vectors
        orthonormal_vectors = Q.T  # Transpose to get them as a list

        # If you need them separately
        orthonormal_sample_alm, orthonormal_delay_alm, orthonormal_choice_alm = orthonormal_vectors
        self.sample_alm = tch.sign(R[0,0]) *  orthonormal_sample_alm # right increases
        self.delay_alm = tch.sign(R[1,1]) * orthonormal_delay_alm
        self.choice_alm = tch.sign(R[2,2]) * orthonormal_choice_alm
    
    def _sample_vectors(self, rates):
        y_alm = rates
        #calculating latent vectors
        vec_alm = y_alm[1,:, :] - y_alm[0, :, :]
        self.sample_alm = tch.mean(vec_alm[self.ind_delay-self.d_ind:self.ind_delay,:], axis=0)
        #self.sample_alm = tch.mean(vec_alm[self.ind_sample:self.ind_sample+self.d_ind,:], axis=0)

    def _delay_vectors(self, rates):
        y_alm = rates
        #calculating latent vectors
        vec_alm = y_alm[1,:, :] - y_alm[0, :, :]
        self.delay_alm = tch.mean(vec_alm[self.ind_go-self.d_ind:self.ind_go, :], axis=0)
    
    def _choice_vectors(self,rates):
        y_alm = rates
        #calculating latent vectors
        d_ind = int(0.4/self.dt)
        vec_alm = y_alm[1, :, :] - y_alm[0, :, :]
        self.choice_alm = tch.mean(vec_alm[self.ind_go:self.ind_go + d_ind, :], axis=0)
    


class SelectivitySingleTrialLoss:
    def __init__(self, rates, params_dict, indexes_neurons):
        self.dt = params_dict['dt']
        self.t_min_input = params_dict['t_min_input']
        self.t_max_input = params_dict['t_max_input']
        self.t_start = params_dict['t_start']
        self.t_go = params_dict['t_go']
        self.ind_delay = int((self.t_max_input- self.t_start)/self.dt)
        self.ind_sample = int((self.t_min_input - self.t_start)/self.dt)
        self.ind_go = int((self.t_go - self.t_start)/self.dt)
        self.d_ind = int(0.6/self.dt)
        self.compute_factors(rates)
        self.gram_schmidt(rates)
        self.mode_sample = 0
        self.mode_delay = 1
        self.mode_choice = 2
        self.indexes = indexes_neurons

    def __call__(self, net, rates_data, latents_trials):

        proj_sample_data, proj_delay_data, proj_choice_data = self.project_data(rates_data)
  

        #print(tch.mean(proj_delay_data), tch.mean(proj_delay_model))
        loss_sample = tch.mean(tch.square(proj_sample_data - latents_trials[:,:,self.mode_sample]))
        loss_delay = tch.mean(tch.square(proj_delay_data - latents_trials[:,:,self.mode_delay]))
        loss_choice = tch.mean(tch.square(proj_choice_data - latents_trials[:,:,self.mode_choice]))
        total_loss = (loss_sample + loss_delay + loss_choice )/3.
        return total_loss

    def compute_factors(self, rates):
        self._sample_vectors(rates)
        self._delay_vectors(rates)
        self._choice_vectors(rates)
    
    def project_data(self, rates_data):
        #losses
        proj_sample_data = rates_data @ self.sample_alm[self.indexes] 
        proj_delay_data = rates_data @ self.delay_alm[self.indexes]
        proj_choice_data = rates_data @ self.choice_alm[self.indexes] 
        return proj_sample_data, proj_delay_data, proj_choice_data

    def gram_schmidt(self, rates):
        self._sample_vectors(rates)
        self._delay_vectors(rates)
        self._choice_vectors(rates)
        vectors = tch.stack([self.sample_alm, self.delay_alm, self.choice_alm], dim=1) 
        # Perform QR decomposition for orthonormalization
        Q, R = tch.linalg.qr(vectors)

        # Q now contains the orthonormalized vectors
        orthonormal_vectors = Q.T  # Transpose to get them as a list

        # If you need them separately
        orthonormal_sample_alm, orthonormal_delay_alm, orthonormal_choice_alm = orthonormal_vectors
        self.sample_alm = tch.sign(R[0,0]) *  orthonormal_sample_alm # right increases
        self.delay_alm = tch.sign(R[1,1]) * orthonormal_delay_alm
        self.choice_alm = tch.sign(R[2,2]) * orthonormal_choice_alm

    def _sample_vectors(self, rates):
        y_alm = rates
        #calculating latent vectors
        vec_alm = y_alm[1,:, :] - y_alm[0, :, :]
        self.sample_alm = tch.mean(vec_alm[self.ind_delay-self.d_ind:self.ind_delay,:], axis=0)

    def _delay_vectors(self, rates):
        y_alm = rates
        #calculating latent vectors
        vec_alm = y_alm[1,:, :] - y_alm[0, :, :]
        self.delay_alm = tch.mean(vec_alm[self.ind_go-self.d_ind:self.ind_go, :], axis=0)
    
    def _choice_vectors(self,rates):
        y_alm = rates
        #calculating latent vectors
        d_ind = int(0.4/self.dt)
        vec_alm = y_alm[1, :, :] - y_alm[0, :, :]
        self.choice_alm = tch.mean(vec_alm[self.ind_go:self.ind_go + d_ind, :], axis=0)
    

class LossAverageTrials:
    def __init__(self):
        self.alpha = 0.1
        
    def __call__(self, av_trials_data, rates_alm):
        #calculating losses
        total_loss = tch.mean(tch.square(av_trials_data- rates_alm))
        return total_loss

class LossAverageTime:
    def __init__(self, params_dict):
        self.t_min_input = params_dict['t_min_input']
        self.t_max_input = params_dict['t_max_input']
        self.t_start = params_dict['t_start']
        self.t_go = params_dict['t_go']
        self.dt = params_dict['dt']

        self.t_after_go = 0.4
        t_sample_s = self.t_min_input - self.t_start 
        t_sample_e = self.t_max_input - self.t_start
        t_delay_e = self.t_go - self.t_start
        t_response = self.t_after_go - self.t_start

        self.ind_sample_s =  int(t_sample_s/self.dt)
        self.ind_sample_e = int(t_sample_e/self.dt)
        self.ind_delay_e1 = int(t_delay_e/(2 * self.dt))
        self.ind_delay_e2 = int(t_delay_e/self.dt)
        self.ind_response = int(t_response/self.dt)

    def __call__(self, rates_data, rates_model):
        # mean spikes across neurons
        av_time_model = self.compute_time_averages_4background(rates_model)
        av_time_data = self.compute_time_averages_4background(rates_data)
        #calculating losses
        total_loss = tch.mean(tch.square(av_time_data - av_time_model))
        return total_loss

    def compute_time_averages_4(self, rates):
        average_sample = tch.mean(rates[:, self.ind_sample_s:self.ind_sample_e, :], axis = 1)  
        average_delay1 = tch.mean(rates[:, self.ind_sample_e:self.ind_delay_e1, :], axis = 1) 
        average_delay2 = tch.mean(rates[:, self.ind_delay_e1:self.ind_delay_e2,:], axis = 1) 
        average_response = tch.mean(rates[:, self.ind_delay_e2:self.ind_response, :], axis = 1) 
        av_time_model = tch.stack((average_sample, average_delay1, average_delay2, average_response)) #condition, trials, neurons
        return av_time_model
    def compute_time_averages_3(self, rates):
        average_sample = tch.mean(rates[:, self.ind_sample_s:self.ind_sample_e, :], axis = 1)  
        average_delay = tch.mean(rates[:, self.ind_sample_e:self.ind_delay_e2, :], axis = 1) 
        average_response = tch.mean(rates[:, self.ind_delay_e2:self.ind_response, :], axis = 1) 
        av_time_model = tch.stack((average_sample, average_delay, average_response)) #condition, trials, neurons
        return av_time_model
    def compute_time_averages_4background(self, rates):
        average_background = tch.mean(rates[:, 0:self.ind_sample_s, :], axis = 1)  
        average_sample = tch.mean(rates[:, self.ind_sample_s:self.ind_sample_e, :], axis = 1)  
        average_delay = tch.mean(rates[:, self.ind_sample_e:self.ind_delay_e2, :], axis = 1) 
        average_response = tch.mean(rates[:, self.ind_delay_e2:self.ind_response, :], axis = 1) 
        av_time_model = tch.stack(( average_background, average_sample, average_delay, average_response)) #condition, trials, neurons
        return av_time_model

class LossAllSpikes:
    def __init__(self, indexes_neurons):
        self.indexes_neurons = indexes_neurons

    def __call__(self, spikes, rates):
        # mean spikes across neurons
        total_loss = tch.mean(tch.square(spikes- rates))
        return total_loss
    


class LossAverageNeurons:
    def __init__(self, indexes_neurons):
        self.indexes_neurons = indexes_neurons

    def __call__(self, av_neurons_data, rates):
        # mean spikes across neurons
        av_neurons_model = self.compute_average_neurons(rates)
        total_loss = tch.mean(tch.square(av_neurons_data - av_neurons_model))
        return total_loss
    
    def compute_average_neurons(self, rates):
        av_neurons_model = tch.mean(rates[:,:, self.indexes_neurons], axis = 2)#spikes per s
        return av_neurons_model

class LossOrthogonality:
    def __init__(self, device):
        self.device = device
        
    def __call__(self, cov_matrix):
        cov_alm = cov_matrix['cov_alm']
        eye_alm = tch.eye(cov_alm.shape[0]).to(self.device).float()
        total_loss = tch.mean(tch.square(cov_alm - eye_alm))
        return total_loss







================================================
FILE: main_train_alm_current.py
================================================
# current_rnn/main_train_alm_current.py
"""
Example (registry global, trial-level + process noise):
nohup python -u /home/jingyi.xu/code_rnn/current_rnn/main_train_alm_current.py \
  --registry_dir /home/jingyi.xu/ALM/results/registry/kd95 \
  --animal kd95 \
  --out_dir /home/jingyi.xu/code_rnn/results_current/20260102 \
  --max_epochs 400000 \
  --lr 1e-4 \
  --psth_bin_ms 200 \
  --use_trials \
  --trial_keys cell_trials \
  --trial_batch_per_cond 0 \
  --noise_std 0.03 \
  --noise_std_eval 0.00 \
  --n_exc_virtual 800 \
  --unit_sampling random \
  --dale \
  > train.log 2>&1 &

Notes:
- --use_trials: enable trial-level targets from stage1 npz (dict cond -> array)
- --noise_std: training-time process noise (build trial-to-trial dynamics variability)
- --noise_std_eval: recommend 0.0 for stable best-model selection
"""

import os
import argparse
import pandas as pd

from training_current import train_current_alm, train_current_alm_global


def _infer_n_obs_from_registry(registry_dir: str, animal: str) -> int:
    """
    Infer n_obs (number of observed inhibitory neurons globally) from registry CSV.
    Assumes registry has 'global_idx' column with 0..n_obs-1.
    """
    # Match train_current_alm_global's own search convention
    cand1 = os.path.join(registry_dir, f"{animal}_registry.csv")
    cand2 = os.path.join(registry_dir, "registry.csv")
    if os.path.isfile(cand1):
        csv_path = cand1
    elif os.path.isfile(cand2):
        csv_path = cand2
    else:
        raise FileNotFoundError(f"Cannot find registry csv in {registry_dir} (tried {cand1} and {cand2})")

    df = pd.read_csv(csv_path)
    if "global_idx" not in df.columns:
        raise KeyError(f"Registry missing 'global_idx'. Got columns={list(df.columns)}")

    g = df["global_idx"].to_numpy()
    if g.size == 0:
        raise ValueError("Registry csv is empty.")
    return int(g.max()) + 1


def parse_args():
    ap = argparse.ArgumentParser()

    # mode switch: either single session npz or registry global
    ap.add_argument("--npz", default=None, help="Stage1 npz path for single-session training.")
    ap.add_argument("--registry_dir", default=None, help="Directory containing <animal>_registry.csv or registry.csv")
    ap.add_argument("--animal", default=None, help="Animal name, e.g., kd95 (required for registry mode).")

    # output
    ap.add_argument("--out_dir", default=None, help="Output directory for models/figures.")

    # model/training hyperparams
    ap.add_argument("--device", default="cuda", choices=["cuda", "cpu"])
    ap.add_argument("--max_epochs", type=int, default=2000)
    ap.add_argument("--lr", type=float, default=1e-3)
    ap.add_argument("--weight_decay", type=float, default=0.0)
    ap.add_argument("--seed", type=int, default=0)
    ap.add_argument("--grad_clip", type=float, default=1.0)

    # dynamics / integrator
    ap.add_argument("--dt", type=float, default=0.03436)
    ap.add_argument("--tau", type=float, default=0.01)
    ap.add_argument("--substeps", type=int, default=4)
    ap.add_argument("--nonlinearity", type=str, default="tanh")

    # input / preprocessing
    ap.add_argument("--max_time", type=int, default=None)
    ap.add_argument("--psth_bin_ms", type=float, default=0.0)
    ap.add_argument("--sample_ignore_ms", type=float, default=0.0)
    ap.add_argument("--resp_sec", type=float, default=2.0)

    # Dale + stability
    ap.add_argument("--dale", action="store_true", help="Enable Dale constraint.")
    ap.add_argument("--no_dale", action="store_true", help="Disable Dale constraint.")
    ap.add_argument("--noise_std", type=float, default=0.0, help="Training-time process noise std.")
    ap.add_argument("--noise_std_eval", type=float, default=0.0, help="Eval-time process noise std (recommend 0).")

    # registry-global specific
    ap.add_argument("--n_exc_virtual", type=int, default=0, help="Number of pseudo excitatory units.")
    ap.add_argument("--exc_ratio", type=float, default=4.0,
                    help="If n_exc_virtual==0, set n_exc_virtual=exc_ratio*n_obs (n_obs inferred from registry).")
    ap.add_argument("--max_sessions", type=int, default=0, help="Use only top-K units after registry sorting (0=all).")
    ap.add_argument("--unit_sampling", default="random", choices=["random", "cycle"])

    # trial-level training knobs
    ap.add_argument("--use_trials", action="store_true",
                    help="Use trial-level targets stored in stage1 npz (dict cond->array).")
    ap.add_argument("--trial_batch_per_cond", type=int, default=0,
                    help="Per epoch, subsample this many trials per condition (0=use all).")
    ap.add_argument("--trial_keys", default="cell_trials",
                    help="Comma-separated candidate keys for trial dict in npz (default: cell_trials).")
    ap.add_argument("--trials_bin_ms", type=float, default=None,
                    help="Optional bin/smooth on trial traces (ms). If omitted, follow psth_bin_ms in loader.")

    # global eval / checkpoint policy
    ap.add_argument("--eval_every", type=int, default=1,
                    help="Run global eval every N epochs (0=disable).")
    ap.add_argument("--save_latest_every", type=int, default=100,
                    help="Save latest checkpoint every N epochs (0=disable).")
    ap.add_argument("--save_best_every", type=int, default=50,
                    help="Also re-write best checkpoint every N epochs (0=disable).")

    # optional cond filter
    ap.add_argument("--cond_filter", default=None,
                    help="Comma-separated condition names to load (must exist in stage1 npz).")

    args = ap.parse_args()
    return args


def main():
    args = parse_args()

    dale = True
    if args.no_dale:
        dale = False
    if args.dale:
        dale = True

    if args.out_dir is None:
        args.out_dir = os.path.join(os.getcwd(), "results_current")
    os.makedirs(args.out_dir, exist_ok=True)

    cond_filter = None
    if args.cond_filter is not None and str(args.cond_filter).strip() != "":
        cond_filter = [x.strip() for x in str(args.cond_filter).split(",") if x.strip()]

    trial_keys = tuple([x.strip() for x in str(args.trial_keys).split(",") if x.strip()])

    # ----------------------------
    # Registry global training
    # ----------------------------
    if args.registry_dir is not None:
        if args.animal is None:
            raise ValueError("--animal is required when --registry_dir is set.")

        n_exc_virtual = int(args.n_exc_virtual)
        if n_exc_virtual == 0:
            n_obs = _infer_n_obs_from_registry(args.registry_dir, args.animal)
            n_exc_virtual = int(round(float(args.exc_ratio) * float(n_obs)))
            print(f"[INFO] n_exc_virtual not set; inferred n_obs={n_obs}, set n_exc_virtual={n_exc_virtual} (exc_ratio={args.exc_ratio})")

        max_sessions = None
        if int(args.max_sessions) > 0:
            max_sessions = int(args.max_sessions)

        train_current_alm_global(
            animal=args.animal,
            registry_dir=args.registry_dir,
            out_dir=args.out_dir,

            # sizing
            n_exc_virtual=int(n_exc_virtual),
            max_sessions=max_sessions,
            unit_sampling=args.unit_sampling,

            # training
            max_epochs=int(args.max_epochs),
            lr=float(args.lr),
            weight_decay=float(args.weight_decay),
            seed=int(args.seed),
            grad_clip=float(args.grad_clip),

            # dynamics
            dt=float(args.dt),
            tau=float(args.tau),
            substeps=int(args.substeps),
            nonlinearity=str(args.nonlinearity),
            dale=bool(dale),

            # data shaping
            cond_filter=cond_filter,
            max_time=args.max_time,
            psth_bin_ms=float(args.psth_bin_ms),
            sample_ignore_ms=float(args.sample_ignore_ms),
            resp_sec=float(args.resp_sec),

            # noise
            noise_std=float(args.noise_std),
            noise_std_eval=float(args.noise_std_eval),

            # trial-level training (new)
            use_trials=bool(args.use_trials),
            trial_batch_per_cond=int(args.trial_batch_per_cond),
            trial_keys=trial_keys,
            trials_bin_ms=args.trials_bin_ms,

            # eval / ckpt policy (new)
            eval_every=int(args.eval_every),
            save_latest_every=int(args.save_latest_every),
            save_best_every=int(args.save_best_every),
        )
        return

    # ----------------------------
    # Single-session training
    # ----------------------------
    if args.npz is None:
        raise ValueError("Either --npz (single session) or --registry_dir (global) must be provided.")

    # NOTE: this keeps backward-compat behavior; if you later add single-session trial training,
    # you can thread the same flags through train_current_alm as well.
    train_current_alm(
        npz_path=args.npz,
        out_dir=args.out_dir,
        device=args.device,
        max_epochs=int(args.max_epochs),
        lr=float(args.lr),
        weight_decay=float(args.weight_decay),
        seed=int(args.seed),
        cond_filter=cond_filter,
        max_time=args.max_time,
        psth_bin_ms=float(args.psth_bin_ms),
        sample_ignore_ms=float(args.sample_ignore_ms),
        dale=bool(dale),
        substeps=int(args.substeps),
        noise_std=float(args.noise_std),
    )


if __name__ == "__main__":
    main()



================================================
FILE: model_current.py
================================================
# current_rnn/model_current.py

import math
from typing import Optional, Dict

import torch
import torch.nn as nn
import torch.nn.functional as F


class ALMCurrentRNN(nn.Module):
    """
    High-dimensional current-based RNN for ALM data.

    - State h_t ∈ R^N corresponds 1:1 to recorded neurons (after cell-type filtering).
    - Discrete-time dynamics (Euler):

        h_{t+1} = h_t + (dt / tau) * [ -h_t + J * phi(h_t) + W_in * u_t + b ]

      where:
        - J: NxN recurrent coupling
        - W_in: NxD_in input weight
        - u_t: external input at time t, shape [B, D_in]
        - phi: element-wise nonlinearity

    - Forward input u: shape [B, T, D_in]
    - Forward output: dict with
        - "h":    shape [B, T, N] (current / latent state)
        - "rate": shape [B, T, N] (phi(h))
    """

    def __init__(
        self,
        N: int,
        D_in: int,
        dt: float = 1.0,
        tau: float = 1.0,
        substeps: int = 1,
        nonlinearity: str = "tanh",
        device: Optional[torch.device] = None,
        dale_mask: Optional[torch.Tensor] = None,
    ) -> None:
        """
        Args:
            N:        number of neurons (after cell-type filtering)
            D_in:     dimension of external input u_t
            dt:       integration time step (in arbitrary units, typically 1 frame)
            tau:      effective time constant of the dynamics
            nonlinearity: 'tanh', 'relu', or 'softplus'
            device:   torch device; if None, inferred from parameters at runtime
            dale_mask: optional tensor of shape [N, N] with entries in {-1, 0, +1}
                       to encode Dale's law constraints (not enforced yet, but kept
                       for future use). For now we only store it.
        """
        super().__init__()

        self.N = N
        self.D_in = D_in
        self.dt = float(dt)
        self.tau = float(tau)
        self.substeps = int(substeps)
        assert self.substeps >= 1
        self.nonlinearity = nonlinearity.lower()

        # ---------------------------------------------------------------------
        # Recurrent matrix J ∈ R^{N×N}
        # ---------------------------------------------------------------------
        # Xavier-like initialization, scaled by 1/sqrt(N) to avoid instabilities.
        J = torch.empty(N, N)
        nn.init.kaiming_uniform_(J, a=math.sqrt(5))
        J = J / math.sqrt(N)
        self.J = nn.Parameter(J)

        # ---------------------------------------------------------------------
        # Input weights W_in ∈ R^{N×D_in}
        # ---------------------------------------------------------------------
        W_in = torch.empty(N, D_in)
        nn.init.kaiming_uniform_(W_in, a=math.sqrt(5))
        W_in = W_in / math.sqrt(D_in)
        self.W_in = nn.Parameter(W_in)

        # ---------------------------------------------------------------------
        # Bias term b ∈ R^N
        # ---------------------------------------------------------------------
        self.b = nn.Parameter(torch.zeros(N))

        # Optional Dale's law mask: stored but not enforced yet.
        # Expected shape: [N, N], entries in {-1, 0, +1}
        if dale_mask is not None:
            if dale_mask.shape != (N, N):
                raise ValueError(
                    f"dale_mask must have shape ({N}, {N}), "
                    f"got {tuple(dale_mask.shape)}"
                )
            self.register_buffer("dale_mask", dale_mask.clone())
        else:
            self.dale_mask = None

        # For consistent dtype/device handling later
        if device is not None:
            self.to(device)

    # -------------------------------------------------------------------------
    # Nonlinearity
    # -------------------------------------------------------------------------
    def _phi(self, x: torch.Tensor) -> torch.Tensor:
        if self.nonlinearity == "tanh":
            return torch.tanh(x)
        elif self.nonlinearity == "relu":
            return F.relu(x)
        elif self.nonlinearity == "softplus":
            return F.softplus(x)
        else:
            raise ValueError(f"Unsupported nonlinearity: {self.nonlinearity}")

    # -------------------------------------------------------------------------
    # Optional: apply Dale's law mask to J (for future use)
    # -------------------------------------------------------------------------
    @torch.no_grad()
    def apply_dale_mask(self) -> None:
        """
        Enforce Dale's law sign structure on J if a mask is provided.

        dale_mask[i, j] = +1  -> J[i, j] constrained to be ≥ 0
        dale_mask[i, j] = -1  -> J[i, j] constrained to be ≤ 0
        dale_mask[i, j] =  0  -> unconstrained

        For now, we simply project J onto the sign cone defined by dale_mask.
        This can be called manually after optimizer.step() in a training loop.
        """
        if self.dale_mask is None:
            return

        # Positive-constrained entries
        pos_mask = self.dale_mask > 0
        # Negative-constrained entries
        neg_mask = self.dale_mask < 0

        with torch.no_grad():
            self.J.data[pos_mask] = torch.clamp_min(self.J.data[pos_mask], 0.0)
            self.J.data[neg_mask] = torch.clamp_max(self.J.data[neg_mask], 0.0)

    # -------------------------------------------------------------------------
    # Forward dynamics
    # -------------------------------------------------------------------------
    def forward(
    self,
    u: torch.Tensor,
    h0: Optional[torch.Tensor] = None,
    noise_std: float = 0.0,
    return_rate: bool = True,
) -> Dict[str, torch.Tensor]:
        """
        Run the RNN forward for a batch of input trajectories.

     Args:
        u:  external input trajectories, shape [B, T, D_in]
        h0: optional initial state, shape [B, N]. If None, initialized to zeros.
        noise_std: standard deviation of additive Gaussian noise on h.
        return_rate: if True, also return phi(h) as 'rate'.

        Returns:
        A dict with:
            'h':    tensor [B, T, N], the current-based state
            'rate': tensor [B, T, N], phi(h)       (if return_rate=True)
        """
        if u.dim() != 3:
            raise ValueError(f"u must have shape [B, T, D_in], got {tuple(u.shape)}")

        B, T, D_in = u.shape
        if D_in != self.D_in:
            raise ValueError(f"Expected input dimension D_in={self.D_in}, got {D_in}")

        device = self.J.device
        u = u.to(device)

        # Initialize h_0
        if h0 is None:
            h_t = torch.zeros(B, self.N, device=device, dtype=self.J.dtype)
        else:
            if h0.shape != (B, self.N):
                raise ValueError(
                    f"h0 must have shape [B, N]=[{B}, {self.N}], got {tuple(h0.shape)}"
                )
            h_t = h0.to(device)
        # -------- sub-stepping setup --------
        substeps = int(getattr(self, "substeps", 1))
        if substeps < 1:
            raise ValueError(f"substeps must be >= 1, got {substeps}")

        dt_sub = self.dt / substeps
        dt_over_tau_sub = dt_sub / self.tau  # = (self.dt/self.tau)/substeps

        # If you want the total noise variance per *frame* to stay comparable
        # when using multiple substeps, scale per-substep noise by 1/sqrt(substeps).
        sqrt_dt_sub = math.sqrt(dt_sub)
        noise_scale = 1.0 / math.sqrt(substeps) if substeps > 1 else 1.0

        h_seq = []
        for t in range(T):
            # u_t: [B, D_in] (kept constant within substeps)
            u_t = u[:, t, :]

            # Integrate substeps times within this frame
            for _ in range(substeps):
                # rate_t = phi(h_t)  -> [B, N]
                rate_t = self._phi(h_t)

                # recurrent input: [B, N]
                rec_t = torch.matmul(rate_t, self.J.T)

                # external input: [B, N]
                inp_t = torch.matmul(u_t, self.W_in.T)

                # drift: dh/dt = -h + rec + inp + b
                drift = -h_t + rec_t + inp_t + self.b

                # Euler substep
                h_t = h_t + dt_over_tau_sub * drift

                # Noise (optional)
                if noise_std > 0.0:
                    # per-substep noise; noise_std interpreted as per-frame scale
                    noise = (noise_std * noise_scale) * sqrt_dt_sub * torch.randn_like(h_t)
                    h_t = h_t + noise
            # record state at frame boundary
            h_seq.append(h_t)

        # Stack over time: list of [B, N] -> [B, T, N]
        h_seq = torch.stack(h_seq, dim=1)  # [B, T, N]

        out = {"h": h_seq}
        if return_rate:
            out["rate"] = self._phi(h_seq)

        return out
    



================================================
FILE: plotting.py
================================================
import matplotlib.pyplot as plt
import torch as tch
import numpy as np

def plot_loss(epoch, losses, title, tag = ''):
    plt.figure()
    plt.semilogy(range(epoch), losses[:epoch])
    plt.title(title)
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.savefig(tag + '.png',  bbox_inches = 'tight')
    plt.close()


def plot_neurons(net, rates, default_parameters, t_del = -.03, tag = ''):    
    with tch.set_grad_enabled(False):
        y_alm_l = rates['ALM_l']
        y_alm_r = rates['ALM_r']
        input_net = {'ALM_l':y_alm_l}
        results, _ = net(input_net)
        rates_alm_l = results['rates_alm_l']
        rates_alm_r = results['rates_alm_r']
        rates_octx_l = results['rates_octx_l']
        rates_octx_r = results['rates_octx_r']
        rates_alm_l = rates_alm_l.detach().cpu().numpy()
        rates_alm_r = rates_alm_r.detach().cpu().numpy()
        rates_octx_l = rates_octx_l.detach().cpu().numpy()
        rates_octx_r = rates_octx_r.detach().cpu().numpy()
        y_alm_l = y_alm_l.detach().cpu().numpy()
        y_alm_r = y_alm_r.detach().cpu().numpy()
        t_start = default_parameters['t_start']
        dt = default_parameters['dt']
        n_time = y_alm_l.shape[1]
        x = np.linspace(0, n_time, n_time) * dt
        x = x + t_start
        n_neurons = 1000
        for j in range(0, n_neurons,10):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, rates_alm_l[0, :, j], 'r--',  lw =3) 
            plt.plot(x, y_alm_l[0, :, j], 'r-', lw =3) 
            plt.plot(x, rates_alm_l[1, :, j], 'b--',  lw =3) 
            plt.plot(x, y_alm_l[1, :, j], 'b-', lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title("ALM L")
            plt.savefig('out/neuronal_dynamics/neural_ALM_L_'+ tag + '{}.png'.format(j),  bbox_inches = 'tight')
            plt.close()
        for j in range(0, n_neurons,10):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, rates_alm_r[0, :, j], 'r--',  lw =3) 
            plt.plot(x, y_alm_r[0, :, j], 'r-', lw =3) 
            plt.plot(x, rates_alm_r[1, :, j], 'b--',  lw =3) 
            plt.plot(x, y_alm_r[1, :, j], 'b-', lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title('ALM R')
            plt.savefig('out/neuronal_dynamics/neural_ALM_R_'+ tag + '{}.png'.format(j),  bbox_inches = 'tight')
            plt.close()
        for j in range(0, 200,20):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, rates_octx_l[0, :, j], 'r-',  lw =3) 
            plt.plot(x, rates_octx_l[1, :, j], 'b-',  lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title("ALM L")
            plt.savefig('out/neuronal_dynamics/neural_octx_L_'+ tag + '{}.png'.format(j),  bbox_inches = 'tight')
            plt.close()
        for j in range(0, 200,20):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, rates_octx_r[0, :, j], 'r-',  lw =3) 
            plt.plot(x, rates_octx_r[1, :, j], 'b-',  lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title('ALM R')
            plt.savefig('out/neuronal_dynamics/neural_octx_R_'+ tag + '{}.png'.format(j),  bbox_inches = 'tight')
            plt.close()


def plot_latents(net,  rates, default_parameters, t_del = -.03, tag = ''):   
    with tch.set_grad_enabled(False):
        y_alm_l = rates['ALM_l']
        input_net = {'ALM_l':y_alm_l}
        results, _ = net(input_net)
        latents_alm_l = results['latents_alm_l']
        latents_alm_r = results['latents_alm_r']
        latents_alm_l = latents_alm_l.detach().cpu().numpy()
        latents_alm_r = latents_alm_r.detach().cpu().numpy()
     
   
        t_start = default_parameters['t_start']
        dt = default_parameters['dt']
        n_time = y_alm_l.shape[1]
        x = np.linspace(0, n_time, n_time) * dt
        x = x + t_start
        for j in range(latents_alm_l.shape[2]):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, latents_alm_l[0, :, j], 'r-',  lw =3) 
            plt.plot(x, latents_alm_l[1, :, j], 'b-',  lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title("ALM L")
            plt.savefig('out/latents/latents_ALM_L_'+tag + '{}.png'.format(j), bbox_inches = 'tight')
            plt.close()
        for j in range(latents_alm_r.shape[2]):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, latents_alm_r[0, :, j], 'r-',  lw =3) 
            plt.plot(x, latents_alm_r[1, :, j], 'b-',  lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title("ALM R")
            plt.savefig('out/latents/latents_ALM_R_'+tag + '{}.png'.format(j), bbox_inches = 'tight')
            plt.close()





================================================
FILE: training_current.py
================================================
# current_rnn/training_current.py

import os
import sys
import json
import time
from typing import Optional, List, Dict, Any

import numpy as np
import torch as tch
import torch.nn.functional as F

# ---------------------------------------------------------------------
# Make project root importable so we can reuse losses.py and plotting.py
# ---------------------------------------------------------------------
THIS_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(THIS_DIR)
if ROOT_DIR not in sys.path:
    sys.path.append(ROOT_DIR)

from losses import LossAverageTrials          # reuse existing loss
import plotting                               # reuse existing plotting helpers

from model_current import ALMCurrentRNN       # current_rnn/model_current.py
from data_alm_current import load_alm_psth_npz,build_dale_mask_from_types  # current_rnn/data_alm_current.py
from utils_celltype import load_is_excitatory_from_npz  # current_rnn/utils_celltype.py

from dataclasses import dataclass
from typing import Callable, Dict, Iterable, List, Tuple, Any, Optional

import torch as tch

# ===== add near imports in training_current.py =====
from typing import List, Tuple, Dict, Any, Optional

def _to_trials_time_neurons(arr: np.ndarray) -> np.ndarray:
    """
    Accept common layouts and convert to [R, T, N].
    Supported:
      - [N, T, R]
      - [R, T, N]
      - [N, R, T]
      - [T, N, R]
      - [T, R, N]
      - [R, N, T]
    """
    a = np.asarray(arr)
    if a.ndim != 3:
        raise ValueError(f"trial array must be 3D, got shape={a.shape}")

    dims = a.shape
    # Heuristic: T is the dimension that matches meta['T'] later; we will slice max_time anyway.
    # Here we just permute by trying all permutations and picking the one where middle dim is largest (typical T).
    # You can tighten this if you store T in meta and pass it in.
    perms = [
        (0, 1, 2), (0, 2, 1),
        (1, 0, 2), (1, 2, 0),
        (2, 0, 1), (2, 1, 0),
    ]
    best = None
    best_T = -1
    for p in perms:
        cand = a.transpose(p)  # [?, ?, ?]
        R, T, N = cand.shape
        if T > best_T:
            best_T = T
            best = cand
    # best is [R, T, N] but may be [N, T, R] -> then R is huge (neurons).
    # Fix by requiring R (trials) is not absurdly large vs N.
    # If you know K or N_kept, you can refine; this is robust enough for your ALM sizes.
    R, T, N = best.shape
    if R > 5000 and N < 2000:
        # likely [N, T, R], swap R<->N
        best = best.transpose(2, 1, 0)  # -> [R, T, N]
    return np.asarray(best)

def load_alm_trials_npz(
    npz_path: str,
    *,
    cond_filter: Optional[List[str]] = None,
    max_time: Optional[int] = None,
) -> Tuple[Dict[str, np.ndarray], Dict[str, Any]]:
    """
    Returns:
      trials_by_cond: dict[cond_name] -> np.ndarray [R, T, N_kept]
      meta: dict
    """
    data = np.load(npz_path, allow_pickle=True)
    meta = data["meta"].item() if "meta" in data.files else {}

    # ---- adapt this list to your actual key name(s) in the npz ----
    CANDIDATE_KEYS = ["cell_trials"]
    key = None
    for k in CANDIDATE_KEYS:
        if k in data.files:
            key = k
            break
    if key is None:
        raise KeyError(
            f"{npz_path}: cannot find trial-level key in {CANDIDATE_KEYS}. "
            f"Available keys: {list(data.files)[:30]}"
        )

    obj = data[key]
    # expect a dict-like object: cond_name -> array
    if isinstance(obj, np.ndarray) and obj.dtype == object:
        obj = obj.item()

    if not isinstance(obj, dict):
        raise TypeError(f"{npz_path}: expected dict for {key}, got {type(obj)}")

    cond_names = list(meta.get("cond_names", list(obj.keys())))
    if cond_filter is not None:
        cond_names = [c for c in cond_names if c in set(cond_filter)]

    trials_by_cond: Dict[str, np.ndarray] = {}
    for c in cond_names:
        if c not in obj:
            continue
        arr = _to_trials_time_neurons(np.asarray(obj[c]))
        if max_time is not None:
            arr = arr[:, : int(max_time), :]
        trials_by_cond[c] = arr  # [R, T, N_kept]
    return trials_by_cond, meta

@tch.no_grad()
def _global_eval_loss_neuron_weighted(
    net,
    units,
    *,
    noise_std_eval: float = 0.0,
) -> float:
    """
    Neuron-weighted global loss:
      For each unit_key/session (one entry in `units`):
        - forward on its u: rates_full [C,T,N_total]
        - select observed neurons: pred_sub [C,T,K]
        - compute diff on its time_mask
        - compute mse_per_neuron = mean_{cond,time}(diff) -> [K]
      Aggregate:
        global_loss = (sum over all neurons of mse_per_neuron) / (total #neurons)
    """
    net.eval()

    total_neurons = 0
    sum_mse_over_neurons = 0.0

    for batch in units:
        u = batch["u"]                 # [C,T,D]
        psth_sub = batch["psth_sub"]   # [C,T,K]
        idx_net = batch["idx_net"]     # [K]
        time_mask = batch["time_mask"] # [T] bool (or indices)

        # numeric sanitation consistent with training
        u = tch.nan_to_num(u, nan=0.0, posinf=0.0, neginf=0.0)
        psth_sub = tch.nan_to_num(psth_sub, nan=0.0, posinf=0.0, neginf=0.0)

        out = net(u, h0=None, noise_std=float(noise_std_eval), return_rate=True)
        rates_full = out["rate"]  # [C,T,N_total]

        pred_sub = rates_full.index_select(dim=2, index=idx_net)  # [C,T,K]

        if time_mask.dtype == tch.bool:
            pred_m = pred_sub[:, time_mask, :]
            targ_m = psth_sub[:, time_mask, :]
        else:
            pred_m = pred_sub.index_select(dim=1, index=time_mask)
            targ_m = psth_sub.index_select(dim=1, index=time_mask)

        diff = (pred_m - targ_m).pow(2)                # [C,Tm,K]
        mse_per_neuron = diff.mean(dim=(0, 1))         # [K]

        sum_mse_over_neurons += float(mse_per_neuron.sum().item())
        total_neurons += int(mse_per_neuron.numel())

    return sum_mse_over_neurons / max(total_neurons, 1)


def _load_default_parameters(params_path: Optional[str] = None) -> Dict[str, Any]:
    """
    Load global parameter dictionary from parameters_list.json.
    If params_path is None, uses <ROOT_DIR>/parameters_list.json.
    """
    if params_path is None:
        params_path = os.path.join(ROOT_DIR, "parameters_list.json")
    if not os.path.isfile(params_path):
        raise FileNotFoundError(f"parameters_list.json not found: {params_path}")
    with open(params_path, "r") as f:
        params = json.load(f)
    return params



def _maybe_attach_lick_reward_to_meta(
    meta: Dict[str, Any],
    npz_path: str,
    T: int,
) -> Dict[str, Any]:
    """Attach lick/reward traces (if present) from the stage1 npz into meta.

    This keeps training/eval code simple even if load_alm_psth_npz does not yet
    return these fields.

    Expected shapes in the stage1 npz:
      reward_trace:      [C_all, T_all]
      lick_rate_left:    [C_all, T_all]
      lick_rate_right:   [C_all, T_all]
      lick_rate_total:   [C_all, T_all]
      t_rel_go_sec:      [T_all]
      idx_2p_in_bpod:    [n_trials_2p]  (informational)

    We slice to the *currently loaded* conditions in meta['cond_names'] and the
    currently loaded time length T.
    """
    if meta is None:
        return meta

    try:
        z = np.load(npz_path, allow_pickle=True)
    except Exception:
        return meta

    if "cond_names" not in z or "reward_trace" not in z:
        return meta

    cond_all = [str(x) for x in z["cond_names"].tolist()]
    cond_cur = [str(x) for x in meta.get("cond_names", [])]

    name2i = {n: i for i, n in enumerate(cond_all)}
    try:
        idx = [name2i[n] for n in cond_cur]
    except KeyError:
        # If names do not match, fall back to prefix matching (rare but useful)
        idx = []
        for n in cond_cur:
            hit = None
            for i, na in enumerate(cond_all):
                if na == n or na.startswith(n) or n.startswith(na):
                    hit = i
                    break
            if hit is None:
                raise KeyError(
                    f"Cannot map cond '{n}' to stage1 npz cond_names.\n"
                    f"meta.cond_names={cond_cur}\n"
                    f"npz.cond_names={cond_all}"
                )
            idx.append(hit)

    def _slice_CT(arr: np.ndarray) -> np.ndarray:
        if arr.ndim != 2:
            raise ValueError(f"Expected [C,T] array, got shape {arr.shape}")
        arr = arr[idx, :]
        if arr.shape[1] >= T:
            arr = arr[:, :T]
        else:
            # If T is longer (shouldn't happen), pad with zeros
            pad = T - arr.shape[1]
            arr = np.pad(arr, ((0, 0), (0, pad)), mode="constant", constant_values=0.0)
        return arr.astype(np.float32, copy=False)

    for k in ["reward_trace", "lick_rate_left", "lick_rate_right", "lick_rate_total"]:
        if k in z:
            meta[k] = _slice_CT(np.asarray(z[k]))

    if "t_rel_go_sec" in z:
        t = np.asarray(z["t_rel_go_sec"]).astype(np.float32, copy=False)
        meta["t_rel_go_sec"] = t[:T] if t.shape[0] >= T else np.pad(t, (0, T - t.shape[0]))

    if "idx_2p_in_bpod" in z:
        meta["idx_2p_in_bpod"] = np.asarray(z["idx_2p_in_bpod"])

    return meta



def _build_sample_waveforms(
    T: int,
    fps: float,
    S_frame: int,
    sample_len_sec: float = 1.15,
    on_sec: float = 0.15,
    off_sec: float = 0.10,
    n_bursts: int = 5,
) -> np.ndarray:
    """Return tone_wave[T], noise_wave[T] as float32."""
    tone = np.zeros(T, dtype=np.float32)
    noise = np.zeros(T, dtype=np.float32)

    sample_frames = int(round(sample_len_sec * fps))
    start = int(S_frame)
    end = min(T, start + sample_frames)

    # noise: constant during sample
    noise[start:end] = 1.0

    # tone bursts: ON/OFF pattern
    on_f = int(round(on_sec * fps))
    off_f = int(round(off_sec * fps))

    t = start
    for k in range(n_bursts):
        if t >= end:
            break
        t_on_end = min(end, t + on_f)
        tone[t:t_on_end] = 1.0
        t = t_on_end
        if k < n_bursts - 1:
            t = min(end, t + off_f)

    return tone, noise


def _build_input_tensor(
    C: int,
    T: int,
    cond_names: List[str],
    device: tch.device,
    amp_input: float = 1.0,
    meta: Optional[Dict[str, Any]] = None,
    amp_stim: Optional[float] = None,
    sample_len_sec: float = 1.15,
    on_sec: float = 0.15,
    off_sec: float = 0.10,
    n_bursts: int = 5,
    include_go_cue: bool = True,
    go_cue_sec: float = 0.10,
    amp_go_cue: Optional[float] = None,
    include_reward: bool = True,
    amp_reward: Optional[float] = None,
) -> tch.Tensor:
    """Build external input u for each condition.

    Output u has shape [C, T, D_in] where:

      u(t) = [cond_onehot] + [stim_left, stim_right] + [go_cue] + [reward]

    Notes on trainability:
      - The temporal traces (go_cue, reward_trace) are fixed functions of time
        (trial averages, aligned to the go cue).
      - The *mapping* from these traces into neuron currents is learned via W_in,
        i.e., each input channel corresponds to a trainable N-vector (one weight
        per neuron).
    """
    if amp_stim is None:
        amp_stim = amp_input
    if amp_go_cue is None:
        amp_go_cue = amp_input
    if amp_reward is None:
        amp_reward = 1.0

    # -----------------------------
    # (1) condition one-hot: [C,T,C]
    # -----------------------------
    u = tch.zeros((C, T, C), device=device, dtype=tch.float32)
    for i in range(C):
        u[i, :, i] = float(amp_input)

    # -----------------------------
    # (2) sample stimulus waveforms: [C,T,2]
    # -----------------------------
    stim = tch.zeros((C, T, 2), device=device, dtype=tch.float32)

    if meta is None:
        raise ValueError("meta is required to build stimulus/go/reward inputs (need event_frames, fps, etc.)")

    fps = float(meta.get("fps", 1.0))
    S_frame = int(meta.get("event_frames", {}).get("S", 0))

    tone, noise = _build_sample_waveforms(
    T=T,
    fps=fps,
    S_frame=S_frame,
    sample_len_sec=sample_len_sec,
    on_sec=on_sec,
    off_sec=off_sec,
    n_bursts=n_bursts,
    )

    # scale in numpy (or torch都行)，然后转 torch 到同一 device
    tone = (tone * float(amp_stim)).astype(np.float32, copy=False)
    noise = (noise * float(amp_stim)).astype(np.float32, copy=False)

    tone_t = tch.from_numpy(tone).to(device=device, dtype=tch.float32).view(T, 1)   # [T,1]
    noise_t = tch.from_numpy(noise).to(device=device, dtype=tch.float32).view(T, 1) # [T,1]
    # assign per condition
    for i, name in enumerate(cond_names):
        s = str(name).lower()

        is_lc = ("left_correct" in s) or (s.startswith("lc")) or ("_lc" in s)
        is_rc = ("right_correct" in s) or (s.startswith("rc")) or ("_rc" in s)
        if is_lc and not is_rc:
            stim[i, :, 0:1] = tone_t
            stim[i, :, 1:2] = noise_t
        elif is_rc and not is_lc:
            stim[i, :, 0:1] = noise_t
            stim[i, :, 1:2] = tone_t
        else:
            pass

    u = tch.cat([u, stim], dim=-1)  # [C,T,C+2]

    # -----------------------------
    # (3) go cue: [C,T,1] (0.1s pulse starting at R frame)
    # -----------------------------
    if include_go_cue:
        R = _get_event_frame(meta, ["R", "go", "go_cue", "go_cue_onset", "G"])
        if R is None:
            raise KeyError("Go cue frame not found in meta['event_frames'] (expected key 'R').")
        go_frames = int(round(float(go_cue_sec) * fps))
        go_frames = max(1, go_frames)
        go = tch.zeros((T, 1), device=device, dtype=tch.float32)
        a0 = max(0, int(R))
        a1 = min(T, int(R) + go_frames)
        if a1 > a0:
            go[a0:a1, 0] = float(amp_go_cue)
        go = go.unsqueeze(0).repeat(C, 1, 1)  # [C,T,1]
        u = tch.cat([u, go], dim=-1)  # +1

    # -----------------------------
    # (4) reward: [C,T,1] (per-cond trace, aligned to go cue)
    # -----------------------------
    if include_reward:
        if "reward_trace" not in meta:
            raise KeyError(
                "meta['reward_trace'] missing. Run build_lick_reward_trace.py --inplace "
                "to write reward_trace into the stage1 npz, then re-load, or call "
                "_maybe_attach_lick_reward_to_meta(meta, npz_path, T) before building u."
            )
        rew = np.asarray(meta["reward_trace"], dtype=np.float32)
        if rew.shape[0] != C:
            raise ValueError(f"reward_trace first dim must match C={C}, got {rew.shape}")
        if rew.shape[1] != T:
            # allow mild mismatch
            rew = rew[:, :T] if rew.shape[1] >= T else np.pad(rew, ((0, 0), (0, T - rew.shape[1])), mode="constant")

        reward = tch.from_numpy(rew).to(device=device, dtype=tch.float32).unsqueeze(-1)  # [C,T,1]
        reward = reward * float(amp_reward)
        u = tch.cat([u, reward], dim=-1)  # +1

    return u


def _kernel_size_from_bin_ms(fps: float, bin_ms: float) -> int:
    """Convert bin_ms to an odd kernel size in frames (>=1), so output length stays T."""
    if bin_ms is None or bin_ms <= 0:
        return 1
    k = int(round(float(bin_ms) / 1000.0 * float(fps)))
    k = max(1, k)
    if (k % 2) == 0:
        k += 1
    return k


def _time_bin_smooth_ctn(x: tch.Tensor, fps: float, bin_ms: float) -> tch.Tensor:
    """Boxcar smooth along time for x shaped [C, T, N] (or [C, T, D]). Length-preserving."""
    k = _kernel_size_from_bin_ms(fps=fps, bin_ms=bin_ms)
    if k <= 1:
        return x

    if x.ndim != 3:
        raise ValueError(f"Expected 3D tensor [C,T,*], got {tuple(x.shape)}")

    C, T, D = x.shape
    y = x.permute(0, 2, 1).contiguous().view(C * D, 1, T)   # [C*D,1,T]
    pad = k // 2
    y = F.pad(y, (pad, pad), mode="replicate")
    y = F.avg_pool1d(y, kernel_size=k, stride=1)            # [C*D,1,T]
    y = y.view(C, D, T).permute(0, 2, 1).contiguous()       # [C,T,D]
    return y

def _regularization_l2(
    net: ALMCurrentRNN, lam_J: float = 0.0, lam_W: float = 0.0
) -> tch.Tensor:
    """
    Simple L2 regularization on J and W_in.
    """
    reg = tch.zeros((), device=net.J.device)
    if lam_J > 0.0:
        reg = reg + lam_J * net.J.pow(2).mean()
    if lam_W > 0.0:
        reg = reg + lam_W * net.W_in.pow(2).mean()
    return reg

import numpy as np

def _get_event_frame(meta: Dict[str, Any], keys: List[str]) -> Optional[int]:
    """Try multiple keys in meta['event_frames'] and return the first found."""
    ev = meta.get("event_frames", None)
    if not isinstance(ev, dict):
        return None
    for k in keys:
        if k in ev:
            return int(ev[k])
    return None


def _build_time_mask_sample_delay_resp(
    T: int,
    fps: float,
    meta: dict,
    sample_ignore_ms: float = 50.0,
    resp_sec: float = 2.0,
) -> np.ndarray:
    """
    mask = [S+ignore, D) + [D, R) + [R, R+resp_sec]
      S = sample onset
      D = delay onset
      R = go cue
    """
    # 事件帧（按你现有 meta.event_frames 的习惯，优先用 'S','D','G'）
    S = _get_event_frame(meta, ["S", "sample", "sample_on", "sample_onset"])
    D = _get_event_frame(meta, ["D", "delay", "delay_on", "delay_onset"])
    G = _get_event_frame(meta, ["R", "go", "go_cue", "response", "response_onset"])

    if S is None:
        raise KeyError("Cannot find sample onset frame in meta['event_frames'] (expected key like 'S').")
    if G is None:
        raise KeyError("Cannot find go cue frame in meta['event_frames'] (expected key like 'G').")

    ignore_frames = int(round(sample_ignore_ms * fps / 1000.0))
    start = S + ignore_frames

    if D is None:
        D = start

    m = np.zeros(T, dtype=bool)

    # sample: [start, D)
    a0 = max(0, start)
    a1 = min(T, D)
    if a1 > a0:
        m[a0:a1] = True

    # delay: [D, G)
    b0 = max(0, D)
    b1 = min(T, G)
    if b1 > b0:
        m[b0:b1] = True

    # response: [G, G + resp_sec]
    resp_frames = int(round(resp_sec * fps))
    c0 = max(0, G)
    c1 = min(T, G + resp_frames)
    if c1 > c0:
        m[c0:c1] = True

    return m


def _build_time_mask_sample_phase(
    T: int,
    meta: Dict[str, Any],
    device: tch.device,
    ignore_ms: float = 0.0,
    sample_window_ms: Optional[float] = None,
) -> tch.Tensor:
    """
    """
    fps = float(meta["fps"])
    event_frames = meta["event_frames"]  # dict like {'S': ss, 'D': ld, 'R': go}

    if "S" not in event_frames:
        raise KeyError("event_frames does not contain key 'S' (sample onset).")

    S_frame = int(event_frames["S"])

    # Number of frames to ignore after sample onset
    ignore_frames = int(round(ignore_ms / 1000.0 * fps))

    start_frame = S_frame + ignore_frames

    # Decide end_frame
    if sample_window_ms is not None:
        window_frames = int(round(sample_window_ms / 1000.0 * fps))
        end_frame = start_frame + window_frames
    else:
        # If delay onset 'D' is available, use it as the end of sample phase; otherwise use T.
        if "D" in event_frames:
            end_frame = int(event_frames["D"])
        else:
            end_frame = T

    # Clip to valid range
    start_frame = max(0, min(start_frame, T))
    end_frame = max(0, min(end_frame, T))

    if end_frame <= start_frame:
        raise ValueError(
            f"Invalid time window for sample phase: "
            f"start_frame={start_frame}, end_frame={end_frame}, T={T}"
        )

    time_mask = tch.zeros(T, dtype=tch.bool, device=device)
    time_mask[start_frame:end_frame] = True

    return time_mask


def train_current_alm(
    npz_path: str,
    cond_filter=None,
    max_time=None,
    lr: float = 1e-3,
    max_epochs: int = 50000,
    seed: int = 42,
    noise_std: float = 0.0,
    psth_bin_ms: float = 200.0,
    lam_J: float = 0.0,
    lam_W: float = 0.0,
    params_path: Optional[str] = None,
    out_dir: Optional[str] = None,
    tag: str = "",
    # time masking options:
    use_time_mask: bool = True,
    sample_ignore_ms: float = 50.0,
    resp_sec: float = 2.0,
    # input channels:
    include_go_cue: bool = True,
    go_cue_sec: float = 0.10,
    include_reward: bool = True,
    amp_reward: Optional[float] = None,
    amp_go_cue: Optional[float] = None,
) -> None:
    """
    Train a single-session N-dimensional current-based RNN on trial-averaged ALM data.

    Args:
        npz_path:
            Path to the Stage 1 .npz file produced by 0.average.py.
        cond_filter:
            Optional list of condition names to use, e.g. ['left_correct', 'right_correct'].
            If None, load_alm_psth_npz will choose a reasonable default.
        max_time:
            Optional truncation of the time axis to max_time frames.
        lr:
            Learning rate for Adam.
        max_epochs:
            Number of training epochs.
        seed:
            Random seed for reproducibility.
        noise_std:
            Standard deviation of additive Gaussian noise on h in the RNN.
            For the first deterministic model, this can be kept at 0.0.
        lam_J:
            L2 regularization weight on J.
        lam_W:
            L2 regularization weight on W_in.
        params_path:
            Path to parameters_list.json. If None, uses <ROOT_DIR>/parameters_list.json.
        out_dir:
            Directory to save models and loss plots. If None, uses <ROOT_DIR>/results_current.
        tag:
            String tag appended to filenames for this training run.

        use_time_mask:
            If True, restrict the loss computation to a subset of time points
            specified by mask_mode and related parameters.
        mask_mode:
            Currently only "sample" is implemented: select the sample phase.
        sample_ignore_ms:
            When mask_mode == "sample": number of milliseconds after sample onset
            to exclude from the training window (e.g., 50.0 ms).
        sample_window_ms:
            When mask_mode == "sample": duration of the training window (in ms)
            after the ignored period. If None, the window extends until delay onset
            (event_frames['D']) if present, otherwise until the end of the trial.

    Returns:
        A dictionary with:
            - 'net':         trained model (ALMCurrentRNN)
            - 'psth':        ground-truth psth tensor [C, T, N]
            - 'meta':        metadata dict from load_alm_psth_npz
            - 'loss_history': numpy array of training loss values
            - 'time_mask':   torch.BoolTensor of shape [T] (or None if not used)
    """
    # -------------------------------------------------------------------------
    # Setup and configuration
    # -------------------------------------------------------------------------
    if out_dir is None:
        out_dir = os.path.join(ROOT_DIR, "results_current")
    os.makedirs(out_dir, exist_ok=True)

    default_parameters = _load_default_parameters(params_path)

    # Device selection
    device_str = default_parameters.get("device", "cpu")
    device = tch.device(device_str if tch.cuda.is_available() or device_str == "cpu" else "cpu")

    # Set random seeds
    np.random.seed(seed)
    tch.manual_seed(seed)
    if device.type == "cuda":
        tch.cuda.manual_seed_all(seed)

    # -------------------------------------------------------------------------
    # Load trial-averaged PSTH and metadata
    # -------------------------------------------------------------------------
    psth, meta = load_alm_psth_npz(
        npz_path=npz_path,
        cond_filter=cond_filter,
        max_time=max_time,
        device=device,
        dtype=tch.float32,
    )
    # psth: [C, T, N]
    C, T, N = psth.shape
    cond_names = meta["cond_names"]

    # Attach lick/reward traces (if present) so _build_input_tensor can add reward channel
    meta = _maybe_attach_lick_reward_to_meta(meta=meta, npz_path=npz_path, T=T)

    # -------------------------------------------------------------------------
    # Optional: boxcar time-binning (length-preserving smoothing) on PSTH
    # -------------------------------------------------------------------------
    fps = float(meta.get("fps", 1.0))
    if psth_bin_ms is not None and psth_bin_ms > 0:
        psth = _time_bin_smooth_ctn(psth, fps=fps, bin_ms=float(psth_bin_ms))
        print(f"[INFO] Applied PSTH boxcar smoothing: bin_ms={psth_bin_ms} (fps={fps})")
    else:
        print("[INFO] PSTH boxcar smoothing disabled (psth_bin_ms<=0).")

    # -------------------------------------------------------------------------
    # Build time mask (optional)
    # -------------------------------------------------------------------------
    time_mask = None
    if use_time_mask:
        time_mask = _build_time_mask_sample_delay_resp(
        T=T,
        fps=float(meta["fps"]),
        meta=meta,
        sample_ignore_ms=sample_ignore_ms,
        resp_sec=2.0,
        )
    else:
        time_mask = np.ones(T, dtype=bool)


    # -------------------------------------------------------------------------
    # Build external input tensor u: [C, T, D_in]
    # For now, D_in = C and u is condition one-hot.
    # -------------------------------------------------------------------------
    amp_input = float(default_parameters.get("amp_input", 1.0))
    u = _build_input_tensor(
    C=C,
    T=T,
    cond_names=cond_names,
    device=device,
    amp_input=amp_input,
    meta=meta,
    amp_stim=amp_input,
    sample_len_sec=1.15,
    on_sec=0.15,
    off_sec=0.10,
    n_bursts=5,
    include_go_cue=include_go_cue,
    go_cue_sec=go_cue_sec,
    amp_go_cue=amp_go_cue,
    include_reward=include_reward,
    amp_reward=amp_reward,
    )

    D_in = u.shape[-1]

    # -------------------------------------------------------------------------
    # Instantiate the RNN
    # -------------------------------------------------------------------------
    dt = float(default_parameters.get("dt", 1.0))
    tau = float(default_parameters.get("tau", 1.0))
    substeps = int(default_parameters.get("substeps", 1))

    is_exc = load_is_excitatory_from_npz(npz_path) 

    dale_mask = build_dale_mask_from_types(is_exc)

    net = ALMCurrentRNN(
        N=N,
        D_in=D_in,
        dt=dt,
        tau=tau,
        substeps=substeps,
        nonlinearity="tanh",
        device=device,
        dale_mask=dale_mask.to(device),
    )
    # -------------------------------------------------------------------------
    # Loss and optimizer
    # -------------------------------------------------------------------------
    loss_trials = LossAverageTrials()
    optimizer = tch.optim.Adam(net.parameters(), lr=lr)

    loss_history = np.zeros(max_epochs, dtype=np.float32)

    # Use session id and tag to build filenames
    session_id = meta.get("session_id", "session")
    plane = meta.get("plane", "plane")
    animal = meta.get("animal", "animal")

    if tag:
        run_tag = f"{animal}_{session_id}_{plane}_{tag}"
    else:
        run_tag = f"{animal}_{session_id}_{plane}"

    model_path = os.path.join(out_dir, f"rnn_current_{run_tag}.pt")
    loss_plot_path = os.path.join(out_dir, f"loss_{run_tag}")

    # -------------------------------------------------------------------------
    # Training loop
    # -------------------------------------------------------------------------
    print(f"[INFO] Training ALMCurrentRNN on {npz_path}")
    print(f"[INFO] Conditions: {cond_names}")
    print(f"[INFO] psth shape: C={C}, T={T}, N={N}, device={device}")
    print(f"[INFO] dt={dt}, tau={tau}, amp_input={amp_input}, lr={lr}")
    print(f"[INFO] Saving model to: {model_path}")
    print(f"[INFO] Training for {max_epochs} epochs...")

    start_time = time.time()
    best_loss = float("inf")
    best_state_dict = None

    for epoch in range(max_epochs):
        net.train()
        optimizer.zero_grad()

        # Forward: u has shape [C, T, D_in]
        out = net(u, h0=None, noise_std=noise_std, return_rate=True)
        rates_pred = out["rate"]  # shape [C, T, N]

        # Optionally apply time mask on the time dimension
        if time_mask is not None:
            psth_used = psth[:, time_mask, :]         # [C, T_mask, N]
            rates_used = rates_pred[:, time_mask, :]  # [C, T_mask, N]
        else:
            psth_used = psth
            rates_used = rates_pred

        # Loss: trial-averaged reconstruction + L2 regularization
        loss_fit = loss_trials(psth_used, rates_used)
        loss_reg = _regularization_l2(net, lam_J=lam_J, lam_W=lam_W)
        loss = loss_fit + loss_reg

        loss.backward()
        optimizer.step()

        # Optionally enforce Dale's law by projecting J if a mask is set
        net.apply_dale_mask()

        # Record loss
        loss_val = float(loss.item())
        loss_history[epoch] = loss_val

        # Track best model
        if loss_val < best_loss:
            best_loss = loss_val
            best_state_dict = {k: v.detach().cpu().clone() for k, v in net.state_dict().items()}

        # Logging
        if (epoch + 1) % 100 == 0 or epoch == 0:
            elapsed = time.time() - start_time
            print(
                f"Epoch {epoch+1}/{max_epochs} | "
                f"Loss = {loss_val:.6f} | "
                f"Fit = {float(loss_fit.item()):.6f} | "
                f"Reg = {float(loss_reg.item()):.6f} | "
                f"Elapsed = {elapsed/60:.1f} min"
            )

        # Optionally plot loss curve periodically
        if (epoch + 1) % 1000 == 0:
            plotting.plot_loss(epoch + 1, loss_history, title="Total loss", tag=loss_plot_path)

    total_time = time.time() - start_time
    print(f"[INFO] Training finished in {total_time/60:.1f} minutes.")
    print(f"[INFO] Best loss = {best_loss:.6f}")

    # -------------------------------------------------------------------------
    # Save best model and final loss curve
    # -------------------------------------------------------------------------
    if best_state_dict is not None:
        tch.save(best_state_dict, model_path)
        print(f"[OK] Best model saved to {model_path}")

    # Final loss plot
    plotting.plot_loss(max_epochs, loss_history, title="Total loss", tag=loss_plot_path)
    print(f"[OK] Loss curve saved to {loss_plot_path}.png")

    result = {
        "net": net,
        "psth": psth,
        "meta": meta,
        "loss_history": loss_history,
        "time_mask": time_mask,
    }
    return result

# ===========================
# Global-registry training
# ===========================
import csv
from collections import defaultdict

def _time_bin_smooth_psth(x: tch.Tensor, fps: float, bin_ms: float) -> tch.Tensor:
    return _time_bin_smooth_ctn(x, fps=fps, bin_ms=bin_ms)

def _read_registry_csv(registry_csv_path):
    rows = []
    with open(registry_csv_path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for r in reader:
            rows.append(r)
    if len(rows) == 0:
        raise ValueError("Empty registry csv: %s" % registry_csv_path)
    return rows

def _group_registry_rows(rows):
    """
    Group rows by unit_key. Minimal required keys:
      - unit_key, npz_path, global_idx, array_idx
    """
    by_unit = defaultdict(list)
    max_g = -1
    for r in rows:
        if "unit_key" not in r or "npz_path" not in r or "global_idx" not in r or "array_idx" not in r:
            raise KeyError("Registry row missing required columns. Need unit_key/npz_path/global_idx/array_idx.")
        g = int(r["global_idx"])
        aidx = int(r["array_idx"])
        max_g = max(max_g, g)
        by_unit[str(r["unit_key"])].append((g, aidx, r))
    n_obs = max_g + 1
    return by_unit, n_obs

def _build_keepidx_pos_map(keep_idx_arr):
    # keep_idx_arr: np.ndarray[int], length N_kept
    d = {}
    for i in range(int(keep_idx_arr.shape[0])):
        d[int(keep_idx_arr[i])] = i
    return d

def _preload_units_from_registry(
    by_unit,
    n_exc_virtual,
    device,
    cond_filter,
    max_time,
    psth_bin_ms,
    sample_ignore_ms,
    # ---- optional knobs (won't break existing call sites) ----
    amp_input: float = 1.0,
    include_go_cue: bool = True,
    go_cue_sec: float = 0.10,
    include_reward: bool = True,
    reward_mode: str = "correctport",
    resp_sec: float = 2.0,
    # ---- NEW: trial-level targets from separate trials_*.npz ----
    use_trials: bool = False,
    trial_keys: tuple = ("cell_trials",),     # keys inside trials_*.npz
    trials_bin_ms: float = None,              # if None: follow psth_bin_ms
    trials_roots: list = None,                # optional search roots for trials_*.npz
    require_trials: bool = True,              # if True: raise if a unit has no trials file
):
    """
    Returns:
      units: list[dict] with keys:
        - unit_key, npz_path
        - psth_sub:  [C,T,K]  (cond-avg target; inhibitory-only subset for this unit)
        - trials_sub: dict[str, Tensor] each [R,T,K]  (optional; trial-level targets per cond)
        - u:         [C,T,D]  (inputs; tone/go/reward)
        - idx_net:   [K] long (indices into full net of size N_total)
        - time_mask: [T] bool (torch)
        - meta: dict
      shared: dict with keys:
        - C, T, fps
        - N_inh_total, N_total
    """
    import os
    import re
    import glob
    import numpy as np
    import torch as tch

    def _get_smoother():
        if "_time_bin_smooth_psth" in globals() and callable(globals()["_time_bin_smooth_psth"]):
            return globals()["_time_bin_smooth_psth"]
        if "_time_bin_smooth_ctn" in globals() and callable(globals()["_time_bin_smooth_ctn"]):
            return globals()["_time_bin_smooth_ctn"]
        return None

    smoother = _get_smoother()

    if trials_bin_ms is None:
        trials_bin_ms = float(psth_bin_ms)

    # -----------------------------
    # helper: parse session_id + plane from stage1 name
    # stage1 example: psth_20221004_104619.0.npz
    # -----------------------------
    _re_stage1 = re.compile(r"psth_(?P<sid>.+?)\.(?P<plane>\d+)\.npz$")

    def _infer_animal_from_stage1_path(p: str) -> str:
        # common: .../stage1/<animal>/psth_....npz
        parts = os.path.normpath(p).split(os.sep)
        if "stage1" in parts:
            i = parts.index("stage1")
            if i + 1 < len(parts):
                return parts[i + 1]
        # fallback: unknown
        return ""

    def _expected_trials_basename(stage1_npz: str) -> str:
        b = os.path.basename(stage1_npz)
        m = _re_stage1.search(b)
        if not m:
            raise ValueError(f"Cannot parse session_id/plane from stage1 basename: {b}")
        sid = m.group("sid")
        plane = m.group("plane")
        return f"trials_{sid}.{plane}.npz"

    # -----------------------------
    # helper: load trials dict from trials_*.npz
    # -----------------------------
    def _load_trials_dict_from_trials_npz(trials_npz_path: str) -> dict:
        z = np.load(trials_npz_path, allow_pickle=True)
        for k in trial_keys:
            if k in z.files:
                obj = z[k]
                if isinstance(obj, np.ndarray) and obj.dtype == object:
                    obj = obj.item()
                if not isinstance(obj, dict):
                    raise TypeError(f"{trials_npz_path}: {k} must be a dict(cond->array), got {type(obj)}")
                return obj
        raise KeyError(
            f"{trials_npz_path}: no trial dict found in keys={trial_keys}. "
            f"Available keys={list(z.files)[:40]}"
        )

    # -----------------------------
    # helper: find trials_*.npz for a given stage1 npz
    # -----------------------------
    trials_index_by_basename = {}  # basename -> path (filled lazily per root)
    roots_indexed = set()

    def _index_root(root: str):
        if root in roots_indexed:
            return
        roots_indexed.add(root)
        if not root or (not os.path.isdir(root)):
            return
        # build a basename->path index (first hit wins)
        for p in glob.glob(os.path.join(root, "**", "trials_*.npz"), recursive=True):
            bn = os.path.basename(p)
            if bn not in trials_index_by_basename:
                trials_index_by_basename[bn] = p

    def _resolve_trials_npz(stage1_npz: str) -> str:
        bn = _expected_trials_basename(stage1_npz)

        # (1) same directory as stage1
        p1 = os.path.join(os.path.dirname(stage1_npz), bn)
        if os.path.isfile(p1):
            return p1

        # (2) user-provided roots
        if trials_roots is not None:
            for r in trials_roots:
                if not r:
                    continue
                p2 = os.path.join(r, bn)
                if os.path.isfile(p2):
                    return p2
            # if not found, build index for these roots and try by basename
            for r in trials_roots:
                _index_root(str(r))
            if bn in trials_index_by_basename and os.path.isfile(trials_index_by_basename[bn]):
                return trials_index_by_basename[bn]

        # (3) automatic roots (best-effort)
        animal_guess = _infer_animal_from_stage1_path(stage1_npz)
        auto_roots = []
        if animal_guess:
            auto_roots.append(f"/allen/aind/scratch/jingyi/2p/{animal_guess}")
        auto_roots.append("/allen/aind/scratch/jingyi/2p")

        for r in auto_roots:
            p3 = os.path.join(r, bn)
            if os.path.isfile(p3):
                return p3
        for r in auto_roots:
            _index_root(r)
        if bn in trials_index_by_basename and os.path.isfile(trials_index_by_basename[bn]):
            return trials_index_by_basename[bn]

        tried = [p1]
        if trials_roots is not None:
            tried += [os.path.join(str(r), bn) for r in trials_roots if r]
        tried += [os.path.join(r, bn) for r in auto_roots]
        raise FileNotFoundError(
            f"Cannot find trials file for stage1={stage1_npz}\n"
            f"Expected basename: {bn}\n"
            f"Tried (direct):\n  " + "\n  ".join(tried[:20]) + ("\n  ...(truncated)" if len(tried) > 20 else "") + "\n"
            f"Hint: pass trials_roots=[<dir containing trials_*.npz>] to train_current_alm_global, "
            f"or move/copy trials_*.npz into stage1 folder."
        )

    # -----------------------------
    # Pass 1: load each unit, build psth_sub (pre-clip), record (C,T,fps)
    # -----------------------------
    pre = []
    C_ref = None
    fps_ref = None
    g_max = -1
    T_min = None

    for unit_key, items in by_unit.items():
        if len(items) == 0:
            continue

        npz_path = str(items[0][2]["npz_path"])
        for (_, _, rr) in items[1:]:
            if str(rr["npz_path"]) != npz_path:
                raise ValueError(f"unit_key {unit_key} has inconsistent npz_path in registry.")

        psth, meta = load_alm_psth_npz(
            npz_path=npz_path,
            cond_filter=cond_filter,
            max_time=None,      # handle clipping ourselves
            device=device,
        )

        if max_time is not None:
            psth = psth[:, : int(max_time), :]

        keep_idx = meta.get("keep_idx", None)
        if keep_idx is None:
            raise KeyError(
                f"meta['keep_idx'] missing for {npz_path}. "
                "Stage1 npz must contain keep_idx for registry mapping."
            )
        keep_map = _build_keepidx_pos_map(np.asarray(keep_idx, dtype=int))

        g_list = []
        pos_list = []
        for (g, array_idx, _) in items:
            ai = int(array_idx)
            if ai not in keep_map:
                raise ValueError(
                    f"array_idx={ai} not found in keep_idx of {npz_path} (unit_key={unit_key}). "
                    "Check registry builder mapping."
                )
            pos_list.append(int(keep_map[ai]))
            g_list.append(int(g))

        if len(g_list) == 0:
            continue

        pos_t = tch.as_tensor(pos_list, dtype=tch.long, device=device)
        psth_sub = psth.index_select(dim=2, index=pos_t)  # [C,T,K]

        if psth_bin_ms is not None and float(psth_bin_ms) > 0:
            if smoother is None:
                raise NameError("No smoothing function found. Define _time_bin_smooth_psth or _time_bin_smooth_ctn.")
            fps = float(meta["fps"])
            psth_sub = smoother(psth_sub, fps=fps, bin_ms=float(psth_bin_ms))

        C = int(psth_sub.shape[0])
        T = int(psth_sub.shape[1])
        fps = float(meta["fps"])

        if C_ref is None:
            C_ref = C
        elif C != C_ref:
            raise ValueError(f"Inconsistent C across units: unit {unit_key} has C={C}, ref C={C_ref}")

        if fps_ref is None:
            fps_ref = fps
        else:
            if abs(fps - fps_ref) > 1e-3:
                raise ValueError(f"Inconsistent fps across units: unit {unit_key} fps={fps}, ref fps={fps_ref}")

        T_min = T if T_min is None else min(T_min, T)
        g_max = max(g_max, max(g_list))

        pre.append(
            dict(
                unit_key=unit_key,
                npz_path=npz_path,
                psth_sub=psth_sub,
                meta=meta,
                g_list=g_list,
                pos_list=pos_list,   # IMPORTANT: position in keep_idx for trial-cell selection
                T_ref=T,             # stage1 T (post max_time clip)
            )
        )

    if len(pre) == 0:
        raise ValueError("No units loaded from registry (by_unit is empty after filtering).")
    if T_min is None or C_ref is None or fps_ref is None:
        raise RuntimeError("Failed to determine shared (C,T,fps).")

    T_shared = int(T_min)
    N_inh_total = int(g_max + 1)
    N_total = int(n_exc_virtual) + N_inh_total

    # -----------------------------
    # Pass 2: clip, attach traces, build u/time_mask/idx_net (+ trials_sub if use_trials)
    # -----------------------------
    units = []
    trials_cache = {}  # stage1_npz -> loaded dict(cond->array)

    for item in pre:
        unit_key = item["unit_key"]
        npz_path = item["npz_path"]
        meta = item["meta"]
        g_list = item["g_list"]
        pos_list = item["pos_list"]
        T_ref = int(item["T_ref"])

        psth_sub = item["psth_sub"][:, :T_shared, :]  # [C,T,K]

        meta = _maybe_attach_lick_reward_to_meta(meta, npz_path=npz_path, T=T_shared)

        cond_names = list(meta["cond_names"])
        if len(cond_names) != int(psth_sub.shape[0]):
            raise ValueError(
                f"cond_names length mismatch for {unit_key}: "
                f"len(cond_names)={len(cond_names)} but C={int(psth_sub.shape[0])}"
            )

        u = _build_input_tensor(
            C=len(cond_names),
            T=T_shared,
            cond_names=cond_names,
            device=device,
            amp_input=float(amp_input),
            include_go_cue=bool(include_go_cue),
            go_cue_sec=float(go_cue_sec),
            include_reward=bool(include_reward),
            meta=meta,
        )

        time_mask_np = _build_time_mask_sample_delay_resp(
            T=T_shared,
            fps=float(meta["fps"]),
            meta=meta,
            sample_ignore_ms=float(sample_ignore_ms),
            resp_sec=float(resp_sec),
        )
        time_mask = tch.as_tensor(time_mask_np.astype(np.bool_), device=device)

        idx_net = tch.as_tensor(
            [int(g) + int(n_exc_virtual) for g in g_list],
            dtype=tch.long,
            device=device,
        )

        # ---- NEW: trial-level targets from separate trials_*.npz ----
        trials_sub = None
        if bool(use_trials):
            try:
                if npz_path not in trials_cache:
                    trials_npz = _resolve_trials_npz(npz_path)
                    trials_cache[npz_path] = _load_trials_dict_from_trials_npz(trials_npz)
                trials_dict = trials_cache[npz_path]
            except Exception as e:
                if bool(require_trials):
                    raise
                else:
                    print(f"[WARN] {npz_path}: cannot load trials; skip unit. err={e}")
                    continue

            trials_sub = {}
            for cname in cond_names:
                if cname not in trials_dict:
                    continue
                arr = np.asarray(trials_dict[cname])
                if arr.ndim != 3:
                    raise ValueError(f"{npz_path}: trials_dict[{cname}] must be 3D, got shape={arr.shape}")

                # exporter saves [C_keep, T, nTr] (cells,time,trials)
                # select kept cells for this unit via pos_list (positions in keep_idx)
                # clip to shared T, then convert to [R,T,K]
                Ck, Tk, Rk = arr.shape
                # sanity: time dim should match stage1 time (T_ref) or be close
                if Tk < T_shared:
                    raise ValueError(f"{npz_path}: trials time dim Tk={Tk} < T_shared={T_shared} for cond={cname}")
                arr_k = arr[pos_list, :T_shared, :]          # [K, T, R]
                arr_rtk = np.transpose(arr_k, (2, 1, 0))     # [R, T, K]

                xt = tch.as_tensor(arr_rtk, dtype=tch.float32, device=device)

                if trials_bin_ms is not None and float(trials_bin_ms) > 0:
                    if smoother is None:
                        raise NameError("No smoothing function found. Define _time_bin_smooth_psth or _time_bin_smooth_ctn.")
                    xt = smoother(xt, fps=float(meta["fps"]), bin_ms=float(trials_bin_ms))

                trials_sub[cname] = xt

            if len(trials_sub) == 0:
                msg = (
                    f"{npz_path}: trials loaded but no matching conditions found.\n"
                    f"cond_names={cond_names}\n"
                    f"trials_dict_keys(sample)={list(trials_dict.keys())[:20]}"
                )
                if bool(require_trials):
                    raise KeyError(msg)
                else:
                    print(f"[WARN] {msg}\n -> skip unit")
                    continue

        units.append(
            dict(
                unit_key=unit_key,
                npz_path=npz_path,
                psth_sub=psth_sub,
                trials_sub=trials_sub,   # NEW (None if use_trials=False)
                u=u,
                idx_net=idx_net,
                time_mask=time_mask,
                meta=meta,
            )
        )

    if len(units) == 0:
        raise RuntimeError("No units left after preload (possibly all missing trials files).")

    shared = dict(C=int(C_ref), T=int(T_shared), fps=float(fps_ref), N_inh_total=N_inh_total, N_total=N_total)
    return units, shared



def train_current_alm_global(
    registry_dir: str,
    animal: str,
    out_dir: str,
    *,
    # training
    max_epochs: int = 3000,
    lr: float = 1e-4,
    weight_decay: float = 0.0,
    seed: int = 0,
    noise_std: float = 0.0,
    grad_clip: float = 1.0,
    # model dynamics
    dt: float = 0.03436,
    tau: float = 0.01,
    substeps: int = 4,
    nonlinearity: str = "tanh",
    dale: bool = False,
    # global sizing
    n_exc_virtual: int = 800,
    # unit/session sampling
    unit_sampling: str = "random",   # "random" | "cycle"
    max_sessions: int = None,        # optional: only use top-K sessions from registry builder
    # data shaping
    cond_filter=None,
    max_time=None,
    psth_bin_ms: float = 0.0,
    sample_ignore_ms: float = 50.0,
    resp_sec: float = 2.0,
    # ---- NEW: trial-level training ----
    use_trials: bool = True,
    trial_batch_per_cond: int = 0,         # 0 => use all trials per cond per epoch
    trial_keys: tuple = ("cell_trials", "trials", "psth_trials", "F_trials"),
    trials_bin_ms: Optional[float] = None, # default: follow psth_bin_ms
    noise_std_eval: float = 0.0,           # eval with deterministic dynamics by default
    eval_every: int = 1,
    save_latest_every: int = 1,
    save_best_every: int = 50,             # also writes best periodically
):
    import os, time, json
    import numpy as np
    import pandas as pd
    import torch as tch

    os.makedirs(out_dir, exist_ok=True)

    dev = tch.device("cuda" if tch.cuda.is_available() else "cpu")
    rng = np.random.RandomState(int(seed))

    def _atomic_torch_save(obj, path: str):
        tmp = path + ".tmp"
        tch.save(obj, tmp)
        os.replace(tmp, path)

    def _build_trial_batch(
        u_cond: tch.Tensor,
        trials_sub: Dict[str, tch.Tensor],
        cond_names: List[str],
    ) -> tuple[tch.Tensor, tch.Tensor]:
        """
        u_cond: [C,T,D]
        trials_sub[cname]: [R,T,K]
        Returns:
          u_trials: [B,T,D]
          y_trials: [B,T,K]
        """
        u_list = []
        y_list = []
        C, T, D = u_cond.shape

        for ci, cname in enumerate(cond_names):
            if cname not in trials_sub:
                continue
            Y = trials_sub[cname]  # [R,T,K]
            R = int(Y.shape[0])
            if trial_batch_per_cond is not None and int(trial_batch_per_cond) > 0 and R > int(trial_batch_per_cond):
                idx = tch.randint(low=0, high=R, size=(int(trial_batch_per_cond),), device=Y.device)
                Yb = Y.index_select(dim=0, index=idx)
            else:
                Yb = Y

            Bc = int(Yb.shape[0])
            Ub = u_cond[ci : ci + 1, :, :].expand(Bc, T, D)  # [Bc,T,D]
            u_list.append(Ub)
            y_list.append(Yb)

        if len(u_list) == 0:
            raise RuntimeError("No trial data found for any condition in cond_names (after filtering).")

        u_trials = tch.cat(u_list, dim=0)
        y_trials = tch.cat(y_list, dim=0)
        return u_trials, y_trials

    # ----------------------------
    # 1) Load registry
    # ----------------------------
    registry_csv = os.path.join(registry_dir, f"{animal}_registry.csv")
    if not os.path.isfile(registry_csv):
        registry_csv = os.path.join(registry_dir, "registry.csv")
    if not os.path.isfile(registry_csv):
        raise FileNotFoundError(f"Cannot find registry csv in {registry_dir} (tried {animal}_registry.csv and registry.csv)")

    df = pd.read_csv(registry_csv)

    required_cols = ["unit_key", "global_idx", "array_idx", "npz_path"]
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        raise KeyError(f"Registry missing columns: {missing}. Got columns={list(df.columns)}")

    by_unit = {}
    for _, r in df.iterrows():
        uk = str(r["unit_key"])
        g = int(r["global_idx"])
        a = int(r["array_idx"])
        by_unit.setdefault(uk, []).append((g, a, dict(r)))

    unit_keys = sorted(by_unit.keys())
    if max_sessions is not None and int(max_sessions) > 0:
        unit_keys = unit_keys[: int(max_sessions)]
        by_unit = {k: by_unit[k] for k in unit_keys}

    # ----------------------------
    # 2) Preload unit tensors (+ trials_sub)
    # ----------------------------
    units, shared = _preload_units_from_registry(
        by_unit=by_unit,
        n_exc_virtual=int(n_exc_virtual),
        device=dev,
        cond_filter=cond_filter,
        max_time=max_time,
        psth_bin_ms=psth_bin_ms,
        sample_ignore_ms=sample_ignore_ms,
        resp_sec=float(resp_sec),
        use_trials=bool(use_trials),
        trial_keys=tuple(trial_keys),
        trials_bin_ms=trials_bin_ms,
    )

    if len(units) == 0:
        raise RuntimeError("No units loaded from registry. Check registry csv and filters.")

    # observed inhibitory count
    all_g = []
    for u0 in units:
        all_g.append((u0["idx_net"].detach().cpu().numpy() - int(n_exc_virtual)).astype(int))
    all_g = np.concatenate(all_g, axis=0)
    n_obs = int(all_g.max()) + 1
    n_total = int(n_exc_virtual) + int(n_obs)

    D_in = int(units[0]["u"].shape[-1])

    # ----------------------------
    # 3) Dale mask
    # ----------------------------
    dale_mask = None
    if bool(dale):
        dale_mask = tch.zeros((n_total, n_total), dtype=tch.int8, device=dev)
        dale_mask[:, : int(n_exc_virtual)] = 1
        dale_mask[:, int(n_exc_virtual) :] = -1

    # ----------------------------
    # 4) Build model
    # ----------------------------
    net = ALMCurrentRNN(
        N=int(n_total),
        D_in=int(D_in),
        dt=float(dt),
        tau=float(tau),
        substeps=int(substeps),
        nonlinearity=str(nonlinearity),
        device=dev,
        dale_mask=dale_mask,
    ).to(dev)

    opt = tch.optim.Adam(net.parameters(), lr=float(lr), weight_decay=float(weight_decay))

    # paths
    tag = f"{animal}_global_nobs{n_obs}_nexc{int(n_exc_virtual)}_ntotal{n_total}"
    best_path = os.path.join(out_dir, f"rnn_current_{tag}.best.pt")
    latest_path = os.path.join(out_dir, f"rnn_current_{tag}.latest.pt")
    meta_path = os.path.join(out_dir, f"rnn_current_{tag}.meta.json")

    # ----------------------------
    # 5) Training loop (MODE2)
    # ----------------------------
    best_global_eval = float("inf")
    best_state = None
    unit_order = list(range(len(units)))

    t0 = time.time()
    for ep in range(int(max_epochs)):
        net.train()
        opt.zero_grad(set_to_none=True)

        if unit_sampling == "random":
            rng.shuffle(unit_order)
        elif unit_sampling == "cycle":
            pass
        else:
            raise ValueError(f"unit_sampling must be 'random' or 'cycle', got {unit_sampling}")

        total_neurons = 0
        sum_mse_over_neurons_detached = 0.0

        for ui in unit_order:
            batch = units[ui]
            u_cond = batch["u"]                 # [C,T,D]
            idx_net = batch["idx_net"]          # [K]
            time_mask = batch["time_mask"]      # [T] bool/indices

            if bool(use_trials):
                trials_sub = batch.get("trials_sub", None)
                if trials_sub is None:
                    raise KeyError(f"unit_key={batch.get('unit_key','NA')}: use_trials=True but trials_sub missing in preload.")
                cond_names = list(batch["meta"]["cond_names"])
                u_trials, y_trials = _build_trial_batch(u_cond=u_cond, trials_sub=trials_sub, cond_names=cond_names)  # [B,T,D], [B,T,K]
            else:
                y_trials = batch["psth_sub"]     # [C,T,K]
                u_trials = u_cond                # [C,T,D]

            u_trials = tch.nan_to_num(u_trials, nan=0.0, posinf=0.0, neginf=0.0)
            y_trials = tch.nan_to_num(y_trials, nan=0.0, posinf=0.0, neginf=0.0)

            out = net(u_trials, h0=None, noise_std=float(noise_std), return_rate=True)
            rates_full = out["rate"]  # [B,T,N_total]

            pred_sub = rates_full.index_select(dim=2, index=idx_net)  # [B,T,K]

            if time_mask.dtype == tch.bool:
                pred_m = pred_sub[:, time_mask, :]
                targ_m = y_trials[:, time_mask, :]
            else:
                pred_m = pred_sub.index_select(dim=1, index=time_mask)
                targ_m = y_trials.index_select(dim=1, index=time_mask)

            diff = (pred_m - targ_m).pow(2)         # [B,Tm,K]
            mse_per_neuron = diff.mean(dim=(0, 1))  # [K]
            mse_sum_neurons = mse_per_neuron.sum()  # scalar

            if not tch.isfinite(mse_sum_neurons):
                with tch.no_grad():
                    msg = {
                        "ep": ep + 1,
                        "unit_key": batch.get("unit_key", "NA"),
                        "mse_sum_neurons": str(mse_sum_neurons.detach().cpu().item()),
                        "u_minmax": (float(u_trials.min().cpu()), float(u_trials.max().cpu())),
                        "targ_minmax": (float(y_trials.min().cpu()), float(y_trials.max().cpu())),
                        "rate_minmax": (float(rates_full.min().cpu()), float(rates_full.max().cpu())),
                        "J_norm": float(net.J.norm().detach().cpu()),
                        "W_norm": float(net.W_in.norm().detach().cpu()),
                        "dt_over_tau": float(net.dt / net.tau),
                        "substeps": int(getattr(net, "substeps", 1)),
                    }
                raise FloatingPointError(f"Non-finite loss detected:\n{json.dumps(msg, indent=2)}")

            mse_sum_neurons.backward()

            K_s = int(mse_per_neuron.numel())
            total_neurons += K_s
            sum_mse_over_neurons_detached += float(mse_sum_neurons.detach().cpu().item())

        denom = max(total_neurons, 1)
        for p in net.parameters():
            if p.grad is not None:
                p.grad.div_(float(denom))

        if grad_clip is not None and float(grad_clip) > 0:
            tch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=float(grad_clip))

        opt.step()

        if bool(dale):
            net.apply_dale_mask()

        global_train_loss = sum_mse_over_neurons_detached / float(denom)

        # ---- deterministic global eval for best selection ----
        global_eval_loss = None
        if int(eval_every) > 0 and ((ep + 1) % int(eval_every) == 0):
            net.eval()
            with tch.no_grad():
                total_neurons_eval = 0
                sum_mse_eval = 0.0

                for batch in units:
                    u_cond = batch["u"]
                    idx_net = batch["idx_net"]
                    time_mask = batch["time_mask"]

                    if bool(use_trials):
                        trials_sub = batch["trials_sub"]
                        cond_names = list(batch["meta"]["cond_names"])
                        u_list, y_list = [], []
                        C, T, D = u_cond.shape
                        for ci, cname in enumerate(cond_names):
                            if cname not in trials_sub:
                                continue
                            Y = trials_sub[cname]        # [R,T,K]
                            R = int(Y.shape[0])
                            U = u_cond[ci:ci+1].expand(R, T, D)
                            u_list.append(U)
                            y_list.append(Y)
                        if len(u_list) == 0:
                            continue
                        u_eval = tch.cat(u_list, dim=0)
                        y_eval = tch.cat(y_list, dim=0)
                    else:
                        u_eval = u_cond
                        y_eval = batch["psth_sub"]

                    u_eval = tch.nan_to_num(u_eval, nan=0.0, posinf=0.0, neginf=0.0)
                    y_eval = tch.nan_to_num(y_eval, nan=0.0, posinf=0.0, neginf=0.0)

                    out = net(u_eval, h0=None, noise_std=float(noise_std_eval), return_rate=True)
                    rates_full = out["rate"]
                    pred_sub = rates_full.index_select(dim=2, index=idx_net)

                    if time_mask.dtype == tch.bool:
                        pred_m = pred_sub[:, time_mask, :]
                        targ_m = y_eval[:, time_mask, :]
                    else:
                        pred_m = pred_sub.index_select(dim=1, index=time_mask)
                        targ_m = y_eval.index_select(dim=1, index=time_mask)

                    diff = (pred_m - targ_m).pow(2)
                    mse_per_neuron = diff.mean(dim=(0, 1))
                    mse_sum_neurons = mse_per_neuron.sum()

                    sum_mse_eval += float(mse_sum_neurons.cpu().item())
                    total_neurons_eval += int(mse_per_neuron.numel())

                global_eval_loss = sum_mse_eval / float(max(total_neurons_eval, 1))

            if global_eval_loss < best_global_eval:
                best_global_eval = float(global_eval_loss)
                best_state = {k: v.detach().cpu().clone() for k, v in net.state_dict().items()}
                _atomic_torch_save(best_state, best_path)

        # ---- checkpoint saving ----
        if int(save_latest_every) > 0 and ((ep + 1) % int(save_latest_every) == 0):
            _atomic_torch_save(net.state_dict(), latest_path)

        if int(save_best_every) > 0 and ((ep + 1) % int(save_best_every) == 0) and best_state is not None:
            _atomic_torch_save(best_state, best_path)

        # ---- logging ----
        if (ep == 0) or ((ep + 1) % 50 == 0):
            elapsed = time.time() - t0
            if global_eval_loss is None:
                print(
                    "[global-mode2-trials=%s] ep=%d/%d train_loss=%.6f best_eval=%.6f sessions=%d total_neurons=%d elapsed=%.1fs"
                    % (str(bool(use_trials)), ep + 1, int(max_epochs), float(global_train_loss), float(best_global_eval),
                       len(units), int(total_neurons), elapsed)
                )
            else:
                print(
                    "[global-mode2-trials=%s] ep=%d/%d train_loss=%.6f eval_loss=%.6f best_eval=%.6f sessions=%d total_neurons=%d elapsed=%.1fs"
                    % (str(bool(use_trials)), ep + 1, int(max_epochs), float(global_train_loss), float(global_eval_loss), float(best_global_eval),
                       len(units), int(total_neurons), elapsed)
                )

        meta_out = {
            "animal": animal,
            "registry_csv": registry_csv,
            "n_exc_virtual": int(n_exc_virtual),
            "n_obs_inh": int(n_obs),
            "n_total": int(n_total),
            "D_in": int(D_in),
            "dt": float(dt),
            "tau": float(tau),
            "substeps": int(substeps),
            "nonlinearity": str(nonlinearity),
            "dale": bool(dale),
            "psth_bin_ms": float(psth_bin_ms),
            "sample_ignore_ms": float(sample_ignore_ms),
            "resp_sec": float(resp_sec),
            "use_trials": bool(use_trials),
            "trial_batch_per_cond": int(trial_batch_per_cond),
            "trial_keys": list(trial_keys),
            "trials_bin_ms": None if trials_bin_ms is None else float(trials_bin_ms),
            "noise_std_train": float(noise_std),
            "noise_std_eval": float(noise_std_eval),
            "best_global_eval": float(best_global_eval),
            "unit_sampling": str(unit_sampling),
            "max_sessions": None if max_sessions is None else int(max_sessions),
        }
        with open(meta_path, "w") as f:
            json.dump(meta_out, f, indent=2)

    if best_state is None:
        best_state = {k: v.detach().cpu().clone() for k, v in net.state_dict().items()}
        _atomic_torch_save(best_state, best_path)

    print(f"[OK] Saved best   -> {best_path}")
    print(f"[OK] Saved latest -> {latest_path}")
    print(f"[OK] Saved meta   -> {meta_path}")





================================================
FILE: utils_celltype.py
================================================
# current_rnn/utils_celltype.py

from __future__ import annotations
import numpy as np
import pandas as pd
from typing import Sequence


EXC_KEYWORDS = (

)

INH_KEYWORDS = (
    "Vip",
    "Sst",
    "Pvalb",
    "Lamp5",
    "Sncg",
    "Serpinf1",
    "Meis2"        
)


def subclass_to_is_excitatory(subclass: str) -> bool:

    if subclass is None:
        return True

    s = str(subclass).lower().strip()
    if s in ("", "nan", "none"):
        return True

    has_exc = any(k in s for k in EXC_KEYWORDS)
    has_inh = any(k in s for k in INH_KEYWORDS)

    if has_exc and not has_inh:
        return True
    if has_inh and not has_exc:
        return False

    # 模糊情况默认 excitatory（通常是 IT-like）
    return True


def load_is_excitatory_from_npz(npz_path: str) -> np.ndarray:

    data = np.load(npz_path, allow_pickle=True)

    if "cell_types" not in data.files:
        raise KeyError(f"{npz_path} 中没有字段 'cell_types'")

    subclasses = data["cell_types"]  # dtype=object, len=N
    subclasses = np.asarray(subclasses).astype(str)

    is_exc = np.array(
        [subclass_to_is_excitatory(s) for s in subclasses],
        dtype=bool
    )
    return is_exc


