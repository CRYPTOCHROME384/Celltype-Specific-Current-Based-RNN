Directory structure:
└── code_rnn/
    ├── README.md
    ├── infer.py
    ├── main_train_alm.py
    ├── parameters_list.json
    ├── run
    ├── alm_data/
    │   ├── 0.average.py
    │   ├── bpod_parse.py
    │   ├── build_global_registry.py
    │   └── utils_alm.py
    ├── current_rnn/
    │   ├── build_lick_reward_trace.py
    │   ├── data_alm_current.py
    │   ├── debug.py
    │   ├── eval_current_alm.py
    │   ├── losses.py
    │   ├── main_train_alm_current.py
    │   ├── model_current.py
    │   ├── plotting.py
    │   ├── training_current.py
    │   └── utils_celltype.py
    ├── legacy_rnn/
    │   ├── cross_validating.py
    │   ├── losses.py
    │   ├── main_test.py
    │   ├── main_train.py
    │   ├── model.py
    │   ├── plotting.py
    │   ├── training.py
    │   └── utils.py
    ├── results_current/
    │   ├── rnn_current_kd95_20220823_205730_0.pt
    │   ├── rnn_current_kd95_global_nobs100_nexc400_ntotal500.meta.json
    │   └── rnn_current_kd95_global_nobs100_nexc400_ntotal500.pt
    ├── results_current(200ms)/
    │   └── rnn_current_kd95_20220823_205730_0.pt
    ├── results_current(no reward)/
    │   └── rnn_current_kd95_20220823_205730_0.pt
    ├── results_current1222/
    │   ├── rnn_current_kd95_global_nobs100_nexc400_ntotal500.meta.json
    │   └── rnn_current_kd95_global_nobs100_nexc400_ntotal500.pt
    └── results_global/
        └── eval_kd95/
            ├── eval_per_unit_rnn_current_kd95_global_nobs100_nexc400_ntotal500.csv
            └── eval_summary_rnn_current_kd95_global_nobs100_nexc400_ntotal500.json

================================================
FILE: README.md
================================================
code_rnn/
├─ parameters_list.json          
├─ rnn_digest.txt                

├─ alm_data/                     
│  ├─ 0.average.py               
│  ├─ bpod_parse.py              
│  ├─ utils_alm.py               

├─ legacy_rnn/                   # original SingleTrialLicks, for reference
│  ├─ model.py
│  ├─ training.py
│  ├─ main_train.py
│  ├─ main_test.py
│  ├─ cross_validating.py
│  ├─ utils.py
│  ├─ losses.py                  
│  ├─ plotting.py                

├─ current_rnn/                  # current-based RNN for ALM
│  ├─ model_current.py           
│  ├─ data_alm_current.py        
│  ├─ training_current.py        
│  ├─ losses.py                  # reused
│  ├─ plotting.py                # reused
│  ├─ main_train_alm_current.py  
│  ├─ eval_current_alm.py            
│  ├─ multi_session.py           # TODO



================================================
FILE: infer.py
================================================
import pickle as pkl
import numpy as np

from bpod_parse import keys, outcomes

FPS_FALLBACK = 29.1

def prelim_events_and_trials(all_data, fps):
    behavior = (all_data[keys('protocol')] == 5)
    freelick = (all_data[keys('protocol')] == 6)
    full_sample = (all_data[keys('earlysample')] == 0)
    full_delay  = (all_data[keys('earlydelay')]  == 0)
    trials_ok = behavior & full_sample & full_delay
    o  = all_data[keys('outcome')]
    tt = all_data[keys('trialtype')]
    CORR = np.isin(o, [outcomes('correct'), outcomes('droppednotlick')])
    INC  = (o == outcomes('incorrect'))
    IG   = (o == outcomes('ignore'))
    FT   = trials_ok | IG
    ss_sec = np.median(all_data[keys('samplestart')][FT])
    ld_sec = np.median(all_data[keys('lastdelay')][FT])
    go_sec = np.median(all_data[keys('go')][FT])
    ss = int(round(ss_sec * fps)); ld = int(round(ld_sec * fps)); go = int(round(go_sec * fps))
    vals = np.unique(tt)
    if set(vals.tolist()) >= {0,1}: L = (tt == 0); R = (tt == 1)
    elif set(vals.tolist()) >= {1,2}: L = (tt == 1); R = (tt == 2)
    else: mid = np.median(vals); L = (tt <= mid); R = (tt > mid)
    LC = np.where(trials_ok & L & CORR)[0]; RC = np.where(trials_ok & R & CORR)[0]
    LI = np.where(trials_ok & L & INC )[0]; RI = np.where(trials_ok & R & INC )[0]
    FL = np.where(full_sample & freelick)[0]; FLt = tt[FL]; FL_type = all_data[keys('freelicktype')][FL]
    FL_L = FL[(FLt == 0) & (FL_type == 1)]; FL_R = FL[(FLt == 1) & (FL_type == 1)]
    licks_needed = all_data[keys('licksneeded')]; puff = all_data[keys('puff')]
    LCo = LC[licks_needed[LC] == 1]; LCm = LC[licks_needed[LC] > 1]
    RCo = RC[licks_needed[RC] == 1]; RCm = RC[licks_needed[RC] > 1]
    LIp = LI[puff[LI] == 1];        LIn = LI[puff[LI] == 0]
    RIp = RI[puff[RI] == 1];        RIn = RI[puff[RI] == 0]
    agg_one   = np.concatenate((LCo, RCo)) if (LCo.size + RCo.size) else np.array([], int)
    agg_multi = np.concatenate((LCm, RCm)) if (LCm.size + RCm.size) else np.array([], int)
    agg_puff  = np.concatenate((LIp, RIp)) if (LIp.size + RIp.size) else np.array([], int)
    agg_nopf  = np.concatenate((LIn, RIn)) if (LIn.size + RIn.size) else np.array([], int)
    cond_idx = {
        'left_correct': LC, 'right_correct': RC, 'left_incorrect': LI, 'right_incorrect': RI,
        'free_left': FL_L, 'free_right': FL_R, 'correct_one_lick': agg_one, 'correct_multi_licks': agg_multi,
        'incorrect_puff': agg_puff, 'incorrect_no_puff': agg_nopf,
    }
    cond_idx = {k: v for k, v in cond_idx.items() if v.size > 0}
    return (ss, ld, go), cond_idx, FT, go_sec

def load_trial2p(trial_pkl_path):
    with open(trial_pkl_path, 'rb') as f:
        obj = pkl.load(f)
    all_data, F, Fbase = obj[0], obj[1], obj[2]
    return all_data, F, Fbase

def infer_time_params(trial_pkl_path, fps=FPS_FALLBACK):
    all_data, F, Fbase = load_trial2p(trial_pkl_path)
    (ss, ld, go), cond_idx, FT, go_sec = prelim_events_and_trials(all_data, fps)

    ss_sec = ss / fps
    ld_sec = ld / fps
    # go_sec 和 go/fps 理论上一样，你也可以打印出来 check 一下
    dt = 1.0 / fps

    t_go = 0.0
    t_min_input = ss_sec - go_sec
    t_max_input = ld_sec - go_sec
    t_start = -go_sec   # or -go_sec - 0.5

    max_time_index = F.shape[1]

    print(f"dt = {dt:.5f}")
    print(f"t_start = {t_start:.3f}")
    print(f"t_min_input = {t_min_input:.3f}")
    print(f"t_max_input = {t_max_input:.3f}")
    print(f"t_go = {t_go:.3f}")
    print(f"max_time_index = {max_time_index}")
    return dict(
        dt=dt,
        t_start=t_start,
        t_min_input=t_min_input,
        t_max_input=t_max_input,
        t_go=t_go,
        max_time_index=max_time_index,
    )

if __name__ == "__main__":
    trial_pkl = "/allen/aind/scratch/jingyi/2p/kd95/kd95_twNew_20220823_205730.0.trial_2p.pkl"
    infer_time_params(trial_pkl)



================================================
FILE: main_train_alm.py
================================================
# main_train_alm.py
from training import train
import os
import json
import torch as tch

from utils_alm import load_trial2p   # 其实只需要拿到 F.shape[1] 做 max_time_index


if __name__ == "__main__":
    # 1. 指定你想训练的这个 session 的 trial_2p.pkl 路径
    trial_pkl = "/allen/aind/scratch/jingyi/2p/kd95/kd95_twNew_20220823_205730.0.trial_2p.pkl"

    # 2. files_list / session_names 简单统一用这个路径（或者用 basename，当 key 用）
    files_list   = [trial_pkl]
    session_names = [os.path.basename(trial_pkl)]

    # 3. 设定超参数
    with open("parameters_list.json") as f:
        default_parameters = json.load(f)

    device = "cuda" if tch.cuda.is_available() else "cpu"
    default_parameters["device"] = device

    # 根据这个 session 的长度设置 max_time_index
    _, F, _ = load_trial2p(trial_pkl)
    _, T, _ = F.shape
    max_time_index = T   # 或者你想裁掉尾巴，就设一个 < T 的值

    # 4. 调整 training.py 里的 train 调用：
    #    确保 training.py 里 `from utils import *` 改成 `from utils_alm import *`
    hemi = "left"     # 这里不再真的分 hemis，可以随便填一个
    net_params = None # 不加载已有网络
    max_epochs = 50000
    random_seed = 42

    train(files_list,
          session_names=session_names,
          net_params=net_params,
          n_pop=20,             # 看你 json 里的设置
          hemi=hemi,
          max_time_index=max_time_index,
          max_epochs=max_epochs,
          test_every=50,
          optimize_every=1,
          random_seed=random_seed,
          info="ALM_single_session")



================================================
FILE: parameters_list.json
================================================
{   "device": "cuda",


    "_comment1": "These are the parameters for the network",

    "tau": 0.01,
    "dt": 0.03436,
    "substeps": 4,
    "input_noise": 0.0,
    "t_start": -4.695,
    "t_min_input":-3.149,
    "t_max_input":-2.015,
    "t_go": 0.0,
    "amp_input": 0.5,

    "_comment2": "These are parameters for the training",

    "batch_size": 16


}


================================================
FILE: run
================================================
#!/usr/bin/env bash
set -ex

# This is the master script for the capsule. When you click "Reproducible Run", the code in this file will execute.
python -u main_test.py "$@"

# The previous version of this file was commented-out and follows below:
#
# python -u main_train.py "$@"
# 
# # The previous version of this file was commented-out and follows below:
# #
# # python -u main_test.py "$@"
# # 
# # # The previous version of this file was commented-out and follows below:
# # #
# # # python -u main_train.py "$@"
# # # 
# # # # The previous version of this file was commented-out and follows below:
# # # #
# # # # python -u main_test.py "$@"
# # # # 
# # # # # The previous version of this file was commented-out and follows below:
# # # # #
# # # # # python -u main_train.py "$@"
# # # # # 
# # # # # # The previous version of this file was commented-out and follows below:
# # # # # #
# # # # # # python -u main_test.py "$@"
# # # # # # 
# # # # # # # The previous version of this file was commented-out and follows below:
# # # # # # #
# # # # # # # python -u main_train.py "$@"
# # # # # # # 
# # # # # # # # The previous version of this file was commented-out and follows below:
# # # # # # # #
# # # # # # # # python -u main_test.py "$@"
# # # # # # # # 
# # # # # # # # # The previous version of this file was commented-out and follows below:
# # # # # # # # #
# # # # # # # # # python -u main.py "$@"
# # # # # # # # # 
# # # # # # # # 
# # # # # # # 
# # # # # # 
# # # # # 
# # # # 
# # # 
# # 
# 



================================================
FILE: alm_data/0.average.py
================================================
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Stage 1 (v5): averaging with CSV default (cluster+subclass), PKL optional
-----------------------------------------------------------------------
Adds:
  (1) Save both per-cell Predicted_Cluster (fine) and Predicted_Subclass (coarse).
  (2) --dump-kept table.csv to export kept ROI mapping:
      ROI_1based, array_idx, ex_vivo_id, Predicted_Subclass, Predicted_Cluster, source_slice

Notes:
- CSV columns expected (case-insensitive): mRNA_ID, mRNA_Slice, Predicted_Subclass, Predicted_Cluster
- ROI id → array index conversion is 1-based → 0-based.
- Per-session match files are searched in match_ids/<animal>_s{1,2}/ and unioned.
"""

import os, sys, json, csv, argparse, pickle as pkl, glob, re
import numpy as np
import pandas as pd
from collections import Counter

ROOT        = os.path.expanduser('~/ALM')
MANIFEST    = os.path.join(ROOT, 'meta', 'manifest.json')
OUT_DIR     = os.path.join(ROOT, 'results', 'stage1')
SUMMARY_CSV = os.path.join(OUT_DIR, 'summary_stage1.csv')

FPS_FALLBACK   = 29.1
SMOOTH_DEFAULT = 1
TRIAL_STAT_DEF = 'mean'

sys.path.append(os.path.join(ROOT, 'scripts'))
from bpod_parse import keys, outcomes  # noqa: E402

def load_manifest():
    with open(MANIFEST, 'r', encoding='utf-8') as f:
        return json.load(f)

def first_or_none(d, key):
    v = d.get(key)
    return v[0] if v else None

def load_trial2p_pkl(path):
    with open(path, 'rb') as f:
        obj = pkl.load(f)
    all_data, F, Fbase = obj[0], obj[1], obj[2]
    assert all_data.ndim == 2 and F.ndim == 3 and Fbase.shape == F.shape
    return all_data, F, Fbase

def get_fps(rec):
    fps = FPS_FALLBACK
    print(f'[info] using fps={fps} for {rec["session_id"]}.{rec["plane"]}')
    return fps

def _smooth_time(CxT, win=1):
    if win <= 1: return CxT
    k = np.ones(win, dtype=float) / win
    def _conv(v):
        v = np.asarray(v, float)
        m = np.isfinite(v)
        if not m.any(): return v
        vv = np.copy(v); vv[~m] = 0.0
        num = np.convolve(vv, k, mode='same')
        den = np.convolve(m.astype(float), k, mode='same')
        out = np.full_like(num, np.nan); ok = den > 0
        out[ok] = num[ok] / den[ok]
        return out
    return np.apply_along_axis(_conv, 1, CxT)

def _trial_reduce(dFoF, tidx, stat='mean'):
    if len(tidx) == 0: return None
    if stat == 'median': return np.nanmedian(dFoF[:, :, tidx], axis=2)
    return np.nanmean(dFoF[:, :, tidx], axis=2)

def zero_center_pre(cell_psth, fps, pre_frames):
    if pre_frames is None or pre_frames <= 0: return cell_psth
    out = {}
    for name, M in cell_psth.items():
        if M is None: continue
        pf = min(pre_frames, M.shape[1])
        base = np.nanmean(M[:, :pf], axis=1, keepdims=True)
        out[name] = M - base
    return out

def prelim_events_and_trials(all_data, fps):
    behavior = (all_data[keys('protocol')] == 5)
    freelick = (all_data[keys('protocol')] == 6)
    full_sample = (all_data[keys('earlysample')] == 0)
    full_delay  = (all_data[keys('earlydelay')]  == 0)
    trials_ok = behavior & full_sample & full_delay
    o  = all_data[keys('outcome')]
    tt = all_data[keys('trialtype')]
    CORR = np.isin(o, [outcomes('correct'), outcomes('droppednotlick')])
    INC  = (o == outcomes('incorrect'))
    IG   = (o == outcomes('ignore'))
    FT   = trials_ok | IG
    ss_sec = np.median(all_data[keys('samplestart')][FT])
    ld_sec = np.median(all_data[keys('lastdelay')][FT])
    go_sec = np.median(all_data[keys('go')][FT])
    ss = int(round(ss_sec * fps)); ld = int(round(ld_sec * fps)); go = int(round(go_sec * fps))
    vals = np.unique(tt)
    if set(vals.tolist()) >= {0,1}: L = (tt == 0); R = (tt == 1)
    elif set(vals.tolist()) >= {1,2}: L = (tt == 1); R = (tt == 2)
    else: mid = np.median(vals); L = (tt <= mid); R = (tt > mid)
    LC = np.where(trials_ok & L & CORR)[0]; RC = np.where(trials_ok & R & CORR)[0]
    LI = np.where(trials_ok & L & INC )[0]; RI = np.where(trials_ok & R & INC )[0]
    FL = np.where(full_sample & freelick)[0]; FLt = tt[FL]; FL_type = all_data[keys('freelicktype')][FL]
    FL_L = FL[(FLt == 0) & (FL_type == 1)]; FL_R = FL[(FLt == 1) & (FL_type == 1)]
    licks_needed = all_data[keys('licksneeded')]; puff = all_data[keys('puff')]
    LCo = LC[licks_needed[LC] == 1]; LCm = LC[licks_needed[LC] > 1]
    RCo = RC[licks_needed[RC] == 1]; RCm = RC[licks_needed[RC] > 1]
    LIp = LI[puff[LI] == 1];        LIn = LI[puff[LI] == 0]
    RIp = RI[puff[RI] == 1];        RIn = RI[puff[RI] == 0]
    agg_one   = np.concatenate((LCo, RCo)) if (LCo.size + RCo.size) else np.array([], int)
    agg_multi = np.concatenate((LCm, RCm)) if (LCm.size + RCm.size) else np.array([], int)
    agg_puff  = np.concatenate((LIp, RIp)) if (LIp.size + RIp.size) else np.array([], int)
    agg_nopf  = np.concatenate((LIn, RIn)) if (LIn.size + RIn.size) else np.array([], int)
    cond_idx = {
        'left_correct': LC, 'right_correct': RC, 'left_incorrect': LI, 'right_incorrect': RI,
        'free_left': FL_L, 'free_right': FL_R, 'correct_one_lick': agg_one, 'correct_multi_licks': agg_multi,
        'incorrect_puff': agg_puff, 'incorrect_no_puff': agg_nopf,
    }
    cond_idx = {k: v for k, v in cond_idx.items() if v.size > 0}
    return (ss, ld, go), cond_idx, FT, go_sec

def align_freelick_trials_inplace(F, all_data, fps, go_sec_median, freelick_indices):
    if freelick_indices.size == 0: return
    go_each = all_data[keys('go')][freelick_indices]
    offsets = np.round(fps * (go_each - go_sec_median)).astype(int)
    T = F.shape[1]
    for trial_num, offset in zip(freelick_indices, offsets):
        if offset < 0:
            off = abs(int(offset))
            F[:, 0:T-off, trial_num] = F[:, off:T, trial_num]
            F[:, T-off:T, trial_num] = 0
        elif offset > 0:
            nkeep = max(0, T - offset)
            F[:, 0:nkeep, trial_num] = F[:, offset:offset+nkeep, trial_num]
            F[:, nkeep:T, trial_num] = 0

def compute_dFoF_presample(F, fps, ss_frames):
    C, T, N = F.shape
    ss_frames = max(1, min(int(ss_frames), T))
    base = F[:, :ss_frames, :].mean(axis=1, keepdims=True)
    base = np.maximum(base, 1e-6)
    return (F - base) / base

# ---- PKL backend ----
def _load_cell2k_from_pkl(animal, session_id, plane):
    p_sess = os.path.join(ROOT, 'data', 'cell_type', f'out_{animal}', f'{animal}.sess_z_cell.pkl')
    if not os.path.exists(p_sess):
        return None, None
    try:
        with open(p_sess, 'rb') as f:
            obj = pkl.load(f)
        for key in (f'{animal}_twNew_{session_id}.{plane}', f'{animal}_{session_id}.{plane}'):
            if isinstance(obj, dict) and key in obj and isinstance(obj[key], dict):
                return obj[key], key
    except Exception:
        pass
    return None, None

def select_cells_by_pkl(cell2k, n_cells):
    keep_idx, clusters, subclasses, table = [], [], [], []
    for k_id, k_val in cell2k.items():
        try:
            roi_id = int(k_id)       # 1-based
            array_idx = roi_id - 1   # 0-based
        except Exception:
            continue
        if array_idx < 0 or array_idx >= n_cells: continue
        try: kv = int(k_val)
        except Exception: continue
        if kv < 0: continue
        keep_idx.append(array_idx)
        clusters.append(str(kv))     # cluster = K number (string)
        subclasses.append('NA')      # no subclass in PKL
        table.append({'ROI_1based': roi_id, 'array_idx': array_idx, 'ex_vivo_id': '', 'Predicted_Subclass': 'NA', 'Predicted_Cluster': str(kv), 'source_slice': ''})
    if not keep_idx: return [], [], [], []
    order = np.argsort(np.asarray(keep_idx))
    keep_idx_sorted = [int(np.asarray(keep_idx)[order][j]) for j in range(len(order))]
    clusters_sorted = [str(np.asarray(clusters)[order][j]) for j in range(len(order))]
    subclasses_sorted= [str(np.asarray(subclasses)[order][j]) for j in range(len(order))]
    table_sorted = [table[int(o)] for o in order]
    return keep_idx_sorted, clusters_sorted, subclasses_sorted, table_sorted

# ---- CSV backend ----
def _find_match_files(animal, session_id, plane, slices=(1,2)):
    hits = []
    for sl in slices:
        mdir = os.path.join(ROOT, 'data', 'match_ids', f'{animal}_s{sl}')
        pattern = os.path.join(mdir, f'{animal}_twNew_{session_id}.{plane}.tps.*.match.txt')
        fs = sorted(glob.glob(pattern))
        if fs:
            hits.append((sl, fs[0]))
    return hits

def _load_roi_to_exvivo(match_path):
    try:
        df = pd.read_csv(match_path, sep=None, engine='python')
        if df.shape[1] < 2:
            raise ValueError("match file must have >=2 columns")
        c0, c1 = df.columns[:2]
        rois = pd.to_numeric(df[c0], errors='coerce').astype('Int64').dropna().astype(int)
        exvs = pd.to_numeric(df[c1], errors='coerce').astype('Int64').dropna().astype(int)
        n = min(len(rois), len(exvs))
        return {int(rois.iloc[i]): int(exvs.iloc[i]) for i in range(n)}
    except Exception:
        mapping = {}
        with open(match_path, 'r', encoding='utf-8') as f:
            for line in f:
                s = line.strip()
                if not s or s.startswith('#'): continue
                parts = re.split(r'[\s,]+', s)
                if len(parts) < 2: continue
                try:
                    r = int(float(parts[0])); e = int(float(parts[1]))
                    mapping[r] = e
                except Exception:
                    continue
        return mapping

def _build_ex_maps(csv_path):
    df = pd.read_csv(csv_path, sep=None, engine='python')
    cols = {c.lower(): c for c in df.columns}
    need = ['mrna_id', 'predicted_cluster', 'predicted_subclass']
    for k in need:
        if k not in cols:
            raise KeyError(f'CSV must contain {k}. Got: {list(df.columns)}')
    col_id = cols['mrna_id']
    col_pc = cols['predicted_cluster']
    col_ps = cols['predicted_subclass']
    df_ok = df.loc[df[col_pc].notna()].copy()
    ex_ids  = pd.to_numeric(df_ok[col_id], errors='coerce').astype('Int64').dropna().astype(int).tolist()
    clusts  = df_ok[col_pc].astype(str).tolist()
    subcls  = df_ok[col_ps].astype(str).tolist()
    ex2cluster  = {int(e): c for e, c in zip(ex_ids, clusts)}
    ex2subclass = {int(e): s for e, s in zip(ex_ids, subcls)}
    return ex2cluster, ex2subclass

def select_cells_by_csv(animal, session_id, plane, n_cells, csv_path):
    hits = _find_match_files(animal, session_id, plane, slices=(1,2))
    if not hits:
        print(f'[WARN] no match files for {animal} {session_id}.{plane}')
        return [], [], [], []
    ex2cluster, ex2subclass = _build_ex_maps(csv_path)
    roi2info = {}  # array_idx -> (roi1b, ex_id, subclass, cluster, slice)
    for sl, mpath in hits:
        roi2ex = _load_roi_to_exvivo(mpath)
        for roi_1b, ex_id in roi2ex.items():
            idx = roi_1b - 1  # 1-based -> 0-based
            if 0 <= idx < n_cells and (ex_id in ex2cluster):
                roi2info[idx] = (roi_1b, ex_id, ex2subclass.get(ex_id, 'NA'), ex2cluster[ex_id], sl)
    if not roi2info: return [], [], [], []
    keep_idx_sorted = sorted(roi2info.keys())
    clusters = [roi2info[i][3] for i in keep_idx_sorted]
    subclasses = [roi2info[i][2] for i in keep_idx_sorted]
    table = [{
        'ROI_1based': roi2info[i][0],
        'array_idx': i,
        'ex_vivo_id': roi2info[i][1],
        'Predicted_Subclass': roi2info[i][2],
        'Predicted_Cluster': roi2info[i][3],
        'source_slice': roi2info[i][4],
    } for i in keep_idx_sorted]
    return keep_idx_sorted, clusters, subclasses, table

def aggregate_by_type(cell_psth, labels, group_map=None, n_boot=1000):
    if group_map is None:
        uniq = sorted(set(labels))
        group_map = {u: [u] for u in uniq}
    labels = np.asarray(labels)
    masks = {g: np.isin(labels, members) for g, members in group_map.items()}
    rng = np.random.default_rng(2025)
    def boot_mean(X, B=1000):
        if X.shape[0] == 0: return None
        mean = X.mean(axis=0)
        if X.shape[0] == 1: return mean, mean, mean, 1
        boots = np.empty((B, X.shape[1]), float)
        for b in range(B):
            idx = rng.integers(0, X.shape[0], size=X.shape[0])
            boots[b] = X[idx].mean(axis=0)
        lo = np.percentile(boots, 2.5, axis=0); hi = np.percentile(boots, 97.5, axis=0)
        return mean, lo, hi, X.shape[0]
    out = {}
    for name, CF in cell_psth.items():
        res = {}
        for g, mask in masks.items():
            X = CF[mask]
            if X.size == 0: continue
            r = boot_mean(X, B=n_boot)
            if r is None: continue
            m, lo, hi, n = r
            res[g] = {'mean': m, 'ci_low': lo, 'ci_high': hi, 'n_cells': int(n)}
        out[name] = res
    return out

def run(args):
    os.makedirs(OUT_DIR, exist_ok=True)
    with open(MANIFEST, 'r', encoding='utf-8') as f:
        man = json.load(f)

    rows = []
    for animal in man['animals']:
        aname = animal['animal']
        # 每只小鼠单独的子目录
        out_dir_animal = os.path.join(OUT_DIR, aname)
        os.makedirs(out_dir_animal, exist_ok=True)

        # 若未指定 --em-csv，则按 animal 自动推断
        auto_em_csv = os.path.join(
            ROOT, 'data', 'cell_type',
            f'cell_typing_em_results_{aname}_alm_visp_combined.csv'
        )
        use_em_csv = args.em_csv if (args.em_csv and os.path.exists(args.em_csv)) else auto_em_csv

        for rec in animal['sessions']:
            trial_pkl = rec['files'].get('trial_2p', [None])[0]
            if not trial_pkl or not os.path.exists(trial_pkl):
                continue

            sid, plane = rec['session_id'], str(rec['plane'])
            tag = f'{sid}.{plane}'
            out_npz = os.path.join(out_dir_animal, f'psth_{tag}.npz')

            try:
                all_data, F, Fbase = load_trial2p_pkl(trial_pkl)
            except Exception as e:
                print(f'[SKIP] {tag}: trial_2p load failed - {e}')
                continue

            fps = get_fps(rec)
            (ss, ld, go), cond_idx, FT_mask, go_sec_median = prelim_events_and_trials(all_data, fps)

            # align freelick
            freelick_all = np.array([], dtype=int)
            if 'free_left' in cond_idx:
                freelick_all = np.concatenate((freelick_all, cond_idx['free_left']))
            if 'free_right' in cond_idx:
                freelick_all = np.concatenate((freelick_all, cond_idx['free_right']))
            if freelick_all.size > 0:
                align_freelick_trials_inplace(F, all_data, fps, go_sec_median, freelick_all)

            # ΔF/F
            dFoF = compute_dFoF_presample(F, fps, ss_frames=ss)

            # trial reduce + smooth + zero-center
            cell_psth = {}
            for name, tidx in cond_idx.items():
                M = _trial_reduce(dFoF, tidx, stat=args.trial_stat)
                if M is None:
                    continue
                M = _smooth_time(M, win=args.smooth_win)
                cell_psth[name] = M
            if not cell_psth:
                print(f'[SKIP] {tag}: empty conditions')
                continue

            zc_frames = int(round(args.zero_center_pre * fps)) if args.zero_center_pre > 0 else ss
            cell_psth = zero_center_pre(cell_psth, fps, pre_frames=zc_frames)

            # --- cell selection ---
            C_full = F.shape[0]
            source_used = args.celltype_source
            keep_idx = []; cell_clusters = []; cell_subclasses = []; kept_table = []
            pkl_key_used = None

            if args.celltype_source == 'csv':
                if not os.path.exists(use_em_csv):
                    print(f'[WARN] {aname} {tag}: EM CSV missing at {use_em_csv}; fallback to pkl')
                    source_used = 'pkl'
                else:
                    keep_idx, cell_clusters, cell_subclasses, kept_table = \
                        select_cells_by_csv(aname, sid, plane, C_full, use_em_csv)
                    if len(keep_idx) == 0:
                        print(f'[WARN] {aname} {tag}: CSV selection empty; fallback to pkl')
                        source_used = 'pkl'

            if source_used == 'pkl':
                cell2k, key_used = _load_cell2k_from_pkl(aname, sid, plane)
                if not cell2k:
                    print(f'[SKIP] {aname} {tag}: no mapping in pkl')
                    continue
                keep_idx, cell_clusters, cell_subclasses, kept_table = \
                    select_cells_by_pkl(cell2k, n_cells=C_full)
                pkl_key_used = key_used

            if len(keep_idx) == 0:
                print(f'[SKIP] {aname} {tag}: no cells kept')
                continue
            if len(keep_idx) < args.min_cells:
                print(f'[SKIP] {aname} {tag}: only {len(keep_idx)} cells (<{args.min_cells}), skip saving npz')
                continue

            # 过滤细胞
            cell_psth = {name: M[keep_idx, :] for name, M in cell_psth.items()}

            # 聚合：cluster + subclass
            type_psth_cluster  = aggregate_by_type(cell_psth, cell_clusters,  n_boot=1000)
            type_psth_subclass = aggregate_by_type(cell_psth, cell_subclasses, n_boot=1000)

            # meta
            any_cond = next(iter(cell_psth.keys()))
            T = cell_psth[any_cond].shape[1]
            pre_sec  = ss / float(fps)
            post_sec = max(0.0, T / float(fps) - pre_sec)
            event_frames = {'S': ss, 'D': ld, 'R': go}
            cond_counts = {k: int(len(v)) for k, v in cond_idx.items()}

            # dump-kept：如果传入的是目录，则放在每只小鼠子目录下
            if args.dump_kept:
                dump_path = args.dump_kept
                if os.path.isdir(dump_path):
                    dump_path = os.path.join(out_dir_animal, f'kept_{tag}.csv')
                if source_used == 'csv':
                    kept_rows = []
                    by_idx = {row['array_idx']: row for row in kept_table}
                    for idx in keep_idx:
                        if idx in by_idx: kept_rows.append(by_idx[idx])
                    pd.DataFrame(
                        kept_rows,
                        columns=['ROI_1based','array_idx','ex_vivo_id',
                                 'Predicted_Subclass','Predicted_Cluster','source_slice']
                    ).to_csv(dump_path, index=False)
                    print(f'[dump] kept mapping -> {dump_path} ({len(kept_rows)} rows)')

            # 保存 npz 到 animal 子目录
            np.savez_compressed(
                out_npz,
                session_id=sid,
                plane=plane,
                animal=aname,
                cond_names=np.array(list(cell_psth.keys())),
                cell_types=np.asarray(cell_clusters),
                cell_clusters=np.asarray(cell_clusters),
                cell_subclasses=np.asarray(cell_subclasses),
                cell_psth=cell_psth,
                type_psth_cluster=type_psth_cluster,
                type_psth_subclass=type_psth_subclass,
                type_psth=type_psth_cluster,
                all_data=all_data,
                fps=float(fps),
                t0_frame=int(ss),
                event_frames=event_frames,
                align_to='pre-sample',
                pre_sec=float(pre_sec),
                post_sec=float(post_sec),
                pre_frames=int(round(pre_sec*fps)),
                post_frames=int(round(post_sec*fps)),
                cond_counts=cond_counts,
                keep_idx=np.asarray(keep_idx, dtype=int),
                n_cells_before=int(C_full),
                source_used=source_used,
                pkl_key_used=pkl_key_used if pkl_key_used else '',
                allow_pickle=True
            )

            # summary 行
            from collections import Counter
            type_counts = Counter(cell_clusters)
            sub_counts  = Counter(cell_subclasses)
            row = {
                'animal': aname, 'session_id': sid, 'plane': plane,
                'n_cells_before': C_full, 'n_cells_kept': len(keep_idx),
                'n_frames': F.shape[1],
                **{f'cond_{k}': int(v) for k, v in cond_counts.items()},
                **{f'ncluster_{t}': c for t, c in type_counts.items()},
                **{f'nsub_{t}': c for t, c in sub_counts.items()},
                'fps': float(fps), 'pre_sec': float(pre_sec), 'post_sec': float(post_sec),
                'trial_stat': args.trial_stat, 'smooth_win': int(args.smooth_win),
                'zero_center_pre': float(args.zero_center_pre if args.zero_center_pre > 0 else 0.0),
                'source_used': source_used, 'pkl_key_used': pkl_key_used if pkl_key_used else '',
                'out_npz': out_npz
            }
            rows.append(row)
            print(f'[OK] {aname} {tag}: kept {len(keep_idx)}/{C_full} by {source_used}; saved -> {out_npz}')

    # 写 summary（全局）
    if rows:
        all_keys = set().union(*[r.keys() for r in rows])
        header = ['animal','session_id','plane','n_cells_before','n_cells_kept','n_frames'] + \
                 sorted([k for k in all_keys if k.startswith('cond_')]) + \
                 sorted([k for k in all_keys if k.startswith('ncluster_')]) + \
                 sorted([k for k in all_keys if k.startswith('nsub_')]) + \
                 ['fps','pre_sec','post_sec','trial_stat','smooth_win','zero_center_pre','source_used','pkl_key_used','out_npz']
        with open(SUMMARY_CSV, 'w', newline='', encoding='utf-8') as f:
            w = csv.DictWriter(f, fieldnames=header)
            w.writeheader()
            for r in rows:
                w.writerow(r)
        print(f'\nSummary written: {SUMMARY_CSV}')
    else:
        print('\nNo record processed.')



def parse_args():
    ap = argparse.ArgumentParser(
        description="Stage-1 averaging with CSV/PKL, per-animal folders, dump-kept, and min-cells filter"
    )
    ap.add_argument('--trial-stat', choices=['mean','median'], default=TRIAL_STAT_DEF)
    ap.add_argument('--smooth-win', type=int, default=SMOOTH_DEFAULT)
    ap.add_argument('--zero-center-pre', type=float, default=0.0)

    # 默认优先用 CSV；若未找到则自动回退到 PKL
    ap.add_argument('--celltype-source', choices=['csv','pkl'], default='csv')

    # 若不传 --em-csv，将自动按 animal 选择：
    ap.add_argument('--em-csv', default=None,
                    help='Path to a specific EM CSV; if not provided, use per-animal default under data/cell_type/')

    # kept 映射表：可传目录或完整文件路径
    ap.add_argument('--dump-kept', default=None,
                    help='If set: if a directory is given, write kept_<sid>.<plane>.csv into per-animal folder; '
                         'if a file path is given, write exactly to that file (CSV mode only)')

    ap.add_argument('--min-cells', type=int, default=40,
                    help='Minimum cells required to save npz (default 40)')
    return ap.parse_args()



if __name__ == '__main__':
    args = parse_args()
    run(args)



================================================
FILE: alm_data/bpod_parse.py
================================================
# parses Bpod matlab file 

import sys, tifffile as tf, os, numpy as np, scipy.io as spio, csv, datetime
from time import sleep
from glob import glob

bsub = 'bsub -q gpu_tesla -gpu \"num=1\" '
bsub = 'bsub -q short -W 59 '
def output_keys(input=""): # structure of bpod.npy list
    d = {x:i for i,x in enumerate(['output', 'SI_files', 'vid_files', 'p1_licks', 'p2_licks', 'MATLABStartTimes'])}
    return d[input] if input else d

#0  outcome (1-5)
#1  trial type
#2  early sample binary
#3  early delay binary
#4  wrong puff binary
#5  AutoWater binary
#6  total WVT RECEIVED (in sec)
#7  recording length
#8  objective Z
#9  laser power
#10 mode
#11 licks needed
#12 protocoltype (5 or 6 or 7)
#13 reward first lick end (taste water)
#14 reaction time from go (rel)
#15 sample start
#16 last delay
#17 go cue (answer)
#18 reward
#19 freelick type
#20 reward1
def keys(input=""):
    d = {x:i for i,x in enumerate(['outcome','trialtype','earlysample','earlydelay','puff','autowater','totalwater','length','z','power','freelick_pos','licksneeded','protocol','rfl','rt','samplestart','lastdelay','go','reward','freelicktype','reward1'])}
    return d[input] if input else d

def outcomes(input=""):
    d = {x:i+1 for i,x in enumerate(['correct','incorrect','ignore','nofollow','droppednotlick','spont'])}
    return d[input] if input else d

def freelick_outcomes(input=""):
    d = {x:i+1 for i,x in enumerate(['lick','multi_lick','multi_ignore','ignore','omit','puff','laser','whisker'])}
    return d[input] if input else d

def waitForJob(job_name):
    from subprocess import check_output
    while True:
        try:
            out = check_output(['bjobs', '-J', job_name])
            if not out: break
            elif 'LSF_INVOKE_CMD' not in os.environ: print(job_name,'job(s) running')
        except: print('bpod_parse: exception while checking', job_name)
        sleep(3)

def numpy_nd_to_dict(arr):
    out = {}
    for i, x in enumerate(arr.dtype.names):
        if x.startswith('OffState') or x.startswith('OnState') or 'Bitcode' in x or x.startswith('Tup') or (len(arr[0][i])==1 and np.isnan(arr[0][i][0][0])): continue
        out[x] = arr[0][i][0] if len(arr[0][i])==1 else arr[0][i]
    return out

def npy_to_csv(npy): # not called?????
    input = np.load(npy, allow_pickle=True)
    output = [['date','time']+keys()+['si']+['vid']*len(input[2][0])+['p1lick','p2lick']]
    for i, x in enumerate(input[0].T):
        output.append([input[5][i].strftime("%d%b%Y"),input[5][i].strftime("%H:%M:%S")]+x.round(2).tolist()+[input[1][i]]+input[2][i]+[input[3][i]]+[input[1][4]])
    return output

if __name__ == "__main__":
    nchan = 2
    if len(sys.argv) == 1:
        unprocessed = []
        for d in glob('/nrs/svoboda/wangt/2pdata/*twNew*/'):
            cmd = bsub + ' -P svoboda -o '+d+'logs/parse.log python '+__file__+' '+d
            if not os.path.exists(d + 'bpod.npy'): unprocessed.append(cmd)
            else: print(cmd + ' PROCESSED')
        for p in unprocessed: print(p)
        quit()

    directory = sys.argv[1].replace('\\','/')
    if not directory.endswith('/'): directory += '/'
    os.makedirs(directory+'/bad/', exist_ok=True)
    os.makedirs(directory+'/info/', exist_ok=True)
    os.makedirs(directory+'/logs/', exist_ok=True)
    bpod_only = True if len(sys.argv)==3 else False
    print('bpod_parse: bpod only', bpod_only)
    m = glob(directory+'*.mat')
    if os.path.exists(directory+'combinedMat.mat'):
        m = directory+'combinedMat.mat'
        combined = True
    elif len(m) == 1:
        m = m[0] # assumes only 1 .mat (you place in there..) 
        combined = False
    else:
        print('bpod_parse:', len(m), 'bpod .mat files found:')
        if m: print('bpod_parse:', m)
        quit()

    ### OPEN BPOD file
    print('bpod_parse: opening', m)
    mat_f = spio.loadmat(m, chars_as_strings=True)['SessionData'][0][0] # alot of extra zeros because 2d arrays are returned

    job = directory.split('/')[-2]
    cmd = bsub + ' -P svoboda -J '+job+' -o '+directory+'logs/check_2p.log -n 4 python check_2p.py '+directory # only metadata reading
    print('bpod_parse:', cmd)
    if not bpod_only: os.system(cmd)

    vid_root = '/nrs/svoboda/wangt/videos/'
    angles = ['side', 'bottom', 'body']
    for angle in angles:
        cmd = bsub + ' -P svoboda -o '+directory+'logs/check_vid.log -n 10 python check_videos.py '+directory.replace('2pdata','videos')+angle+'/'
        print('bpod_parse:', cmd)
        if not bpod_only: os.system(cmd)

    ntrials = mat_f['nTrials'][0][0]
    output = np.zeros((21,ntrials), dtype=np.float32)

    recordings = 0
    videos = 0

    lick_timeout = 10 # could change!!!
    SI_files   = [''] * ntrials
    vid_files  = [[''] * len(angles)] * ntrials
    p1_licks   = [[]] * ntrials
    p2_licks   = [[]] * ntrials
    bpod_times = [0] * ntrials

    if combined:
        vid_idx, vid_counts = [], {}
        sessions = np.unique([x[0] for x in mat_f['OriginalMAT'][0]])
        for i, (a, b) in enumerate(np.array([[x for x in mat_f['OriginalTrial'][0]],[x[0].startswith('armed') for x in mat_f['ScanImageInfo'][0]]]).T.tolist()):
            if a not in vid_counts: vid_counts[a] = 0
            if b: vid_counts[a] += 1
            vid_idx.append(vid_counts[a])
    for i in range(ntrials):
        trial_events = [x[0] for x in mat_f['RawData'][0][0]['OriginalStateNamesByNumber'][0][i][0][mat_f['RawData'][0][0]['OriginalStateData'][0][i]-1][0]]
        trial_timings = mat_f['RawEvents'][0][0]['Trial'][0][i][0]
        trial_event_timings = numpy_nd_to_dict(trial_timings['Events'][0][0])
        trial_state_timings = numpy_nd_to_dict(trial_timings['States'][0][0])
        SI = mat_f['ScanImageInfo'][0][i][0]
        GUI = mat_f['TrialSettings'][0]['GUI'][i]
        if 'RewardFirstLick' in trial_events:
            output[keys('outcome'),i] = outcomes('correct')
            if trial_state_timings['RewardFirstLick'][-1] in trial_timings['Events'][0][0]['Tup'][0]:
                print('bpod_parse:', i, 'lick timed out', GUI['LicksNeeded'][0][0][0][0],'licks were needed autowater:', 1 if 'GiveDrop' in trial_events else 0)
                output[keys('outcome'),i] = outcomes('droppednotlick')# still don't know if touched water after this..
            if round(np.diff(trial_state_timings['RewardFirstLick'])[0]) >= lick_timeout: print(i,'lick timed out')
        elif 'Reward1' in trial_events:
            print('bpod_parse:', i, 'correct but didn\'t follow through', GUI['LicksNeeded'][0][0][0][0], 'licks were needed autowater:', 1 if 'GiveDrop' in trial_events else 0)
            output[keys('outcome'),i] = outcomes('nofollow') # pick correct but didn't follow through -- typically because of multi lick requirement
        elif 'NoResponse' in trial_events: output[keys('outcome'), i] = outcomes('ignore')
        elif 'TimeOut' in trial_events: output[keys('outcome'), i] = outcomes('incorrect')
        elif 'ProtocolType' not in GUI.dtype.fields: output[keys('outcome'), i] = outcomes('error') # why is this happening!!!
        elif GUI['ProtocolType'] == 7: output[keys('outcome'), i] = outcomes('spont')
        else: print('Error!!!!!!!!!!!!!!!!!!!!! ' + str(trial_events)) # still happens VERY rarely
        
        x = mat_f['MATLABStartTimes'][0][i]
        ix = int(x)
        dt = datetime.date.fromordinal(ix-366) #weird correction
        remainder = float(x) - ix
        hour, remainder = divmod(24 * remainder, 1)
        minute, remainder = divmod(60 * remainder, 1)
        second, remainder = divmod(60 * remainder, 1)
        microsecond = int(1e6 * remainder)
        bpod_times[i] = datetime.datetime(dt.year, dt.month, dt.day, int(hour), int(minute), int(second), microsecond) # is this substraction correct???
        output[keys('protocol'),i] = GUI['ProtocolType'][0][0][0][0] ## if 'ProtocolType' in GUI.dtype.names else 6 ## WEIRD CHANGE
        ####if i == 307: output[keys('protocol'),i] = 5
        output[keys('trialtype'),i] = mat_f['TrialTypes'][0][i]
        output[keys('earlysample'),i] = 1 if 'EarlyLickSample' in trial_events else 0 # usually aborted
        output[keys('earlysample'),i] = 1 if 'EarlyLick' in trial_events else output[2,i] # for Free Licking period
        output[keys('earlydelay'),i] = 1 if 'EarlyLickDelay'  in trial_events else 0
        output[keys('puff'),i] = 1 if 'TimeOut1' in trial_events else 0
        output[keys('autowater'),i] = 1 if 'GiveDrop' in trial_events else 0
        output[keys('totalwater'),i] = 0 if 'Reward' not in trial_state_timings else round(np.diff(trial_state_timings['Reward'])[0],4)
        output[keys('totalwater'),i] +=0 if 'GiveDrop' not in trial_state_timings else round(np.diff(trial_state_timings['GiveDrop'])[0],4)
        if 'GlobalTimer1_Start' in trial_event_timings:
            output[keys('length'),i] = trial_event_timings['GlobalTimer1_End'][0]-trial_event_timings['GlobalTimer1_Start'][0]
            if trial_event_timings['GlobalTimer1_Start'][0] != 0.0001: print('bpod_parse:', i, 'weird timer start!', trial_event_timings['GlobalTimer1_Start'])
        if SI.startswith('armed'): # not very robust...
            output[keys('z'),i] = int(float(SI.split('=')[1].split(',')[0]))
            output[keys('power'),i] = float(SI.split('=')[2].split(' ')[0])
            recording_fn = SI.split('=')[3].split(' ')[0].split('\\')[-1].strip()
            if os.path.exists(directory+recording_fn): rec_fn = directory+recording_fn
            elif len(glob(directory+'*/'+recording_fn)) == 1: rec_fn = glob(directory+'*/'+recording_fn)[0]
            elif len(glob(directory+'*/onechan/'+recording_fn)) == 1: rec_fn = glob(directory+'*/onechan/'+recording_fn)[0]
            elif recording_fn.startswith('spont_0000') and len(glob(directory+'spont_0000*.tif')): rec_fn = glob(directory+'spont_0000*.tif')[0]
            elif recording_fn.startswith('spont_0000') and len(glob(directory+'*/spont_0000*.tif')): rec_fn = glob(directory+'*/spont_0000*.tif')[0]
            else: quit('bpod_parse: 2p recording NOT FOUND: ' + recording_fn)
            if 'bad' not in rec_fn: SI_files[i] = os.path.basename(rec_fn)
            recordings += 1
            mat = mat_f['OriginalMAT'][0][0][0] if combined else os.path.basename(m) # assume first MAT has original files
            trial_num = mat_f['OriginalTrial'][0][i] if combined else i+1
            cam_files = [''] * len(angles)
            for cam_idx, angle in enumerate(angles):
                vid_base = vid_root+mat[:-4]+'/'+angle+'/'
                ## vid_wc = mat.split('_')[0]+'_'+angle+'_trial'+str(trial_num)+'_date*' # don't use this because maybe animal name is wrong...
                vid_wc = 'kd*_'+angle+'_trial'+str(trial_num)+'_date*'
                vid_fn = vid_base+'compressed/'+vid_wc+'mp4' if os.path.exists(vid_base+'compressed/') else vid_base+vid_wc+'avi'
                vid = glob(vid_fn)
                vid = sorted(vid, key = lambda fn: fn.split('_date_')[1]) # sort by DATE ecause maybe animal name is wrong...
                if combined:
                    if vid: vid = [vid[vid_idx[i]-1]]
                    else: vid = []
                if len(vid) != 1:
                    print('bpod_parse: VIDEO NOT FOUND: ' + vid_fn)
                    cam_files[cam_idx] = os.path.basename(vid_fn)
                else:
                    videos += 1               
                    cam_files[cam_idx] = os.path.basename(vid[0])
            vid_files[i] = cam_files
        output[keys('freelick_pos'),i] = GUI['RxCenter_motor_pos'][0][0][0][0] if 'RxCenter_motor_pos' in GUI else 0 # old free water
        output[keys('licksneeded'),i] = mat_f['LicksNeeded'][0][i]
        rt1, rt2 = 10, 10
        cue_event = 'AnswerPeriod' #cue_event = 'Reward1' if output[keys('protocol'),i] == 6 else 'AnswerPeriod' # old
        if 'Port1In' in trial_event_timings and cue_event in trial_state_timings:
            rt1 = trial_event_timings['Port1In'] - trial_state_timings[cue_event][0]
            rt1 = min(rt1[rt1>0]) if any(rt1>0) else 10
        if 'Port2In' in trial_event_timings and cue_event in trial_state_timings:
            rt2 = trial_event_timings['Port2In'] - trial_state_timings[cue_event][0]
            rt2 = min(rt2[rt2>0]) if any(rt2>0) else 10
        output[keys('rt'),i] = round(min(rt1, rt2), 5)
        output[keys('samplestart'),i] = trial_state_timings['SampleOn1'][0] if trial_state_timings['SampleOn1'].ndim == 1 else trial_state_timings['SampleOn1'][-1][0] # last sample start (should be only one)
        if 'DelayPeriod' in trial_state_timings: output[keys('lastdelay'),i] = trial_state_timings['DelayPeriod'][0] if trial_state_timings['DelayPeriod'].ndim == 1 else trial_state_timings['DelayPeriod'][-1][0]
        if 'AnswerPeriod' in trial_state_timings: output[keys('go'),i] = trial_state_timings['AnswerPeriod'][0]
        if 'Reward' in trial_state_timings: output[keys('reward'),i] = trial_state_timings['Reward'][0]
        if 'RewardFirstLick' in trial_state_timings: output[keys('rfl'),i] = trial_state_timings['RewardFirstLick'][1]
        if output[keys('protocol'),i] == 6:
            if 'Reward1' in trial_state_timings and 'Reward' not in trial_state_timings:
                output[keys('freelicktype'),i] = freelick_outcomes('multi_ignore')
            elif 'Reward1' in trial_state_timings and 'Reward' in trial_state_timings:
                output[keys('freelicktype'),i] = freelick_outcomes('multi_lick')
            elif 'Reward' in trial_state_timings and 'StopLicking' not in trial_state_timings:
                output[keys('freelicktype'),i] = freelick_outcomes('ignore')
            elif 'Reward' in trial_state_timings:
                output[keys('freelicktype'),i] = freelick_outcomes('lick')
            elif 'RewardOmit' in trial_state_timings:
                output[keys('freelicktype'),i] = freelick_outcomes('omit')
            elif 'RewardPuff' in trial_state_timings:
                output[keys('freelicktype'),i] = freelick_outcomes('puff')
            elif 'RewardLaser' in trial_state_timings:
                output[keys('freelicktype'),i] = freelick_outcomes('laser')
            elif 'RewardWhisker' in trial_state_timings:
                output[keys('freelicktype'),i] = freelick_outcomes('whisker')
            elif 'NoResponse' in trial_state_timings: #Early                
                output[keys('earlysample'),i] = 1
                print('bpod_parse:', i, 'no response!!!')
            else: quit('CASE UNCLEAR FOR FREE LICK!!!!!! ' + str(trial_state_timings) + ' ' + str(trial_event_timings))
        else: output[keys('freelicktype'),i] = 0
        if 'Reward1' in trial_state_timings: output[keys('reward1'),i] = trial_state_timings['Reward1'][1]
        if 'Port1In' in trial_event_timings: p1_licks[i] = np.round(trial_event_timings['Port1In'],3).tolist()
        if 'Port2In' in trial_event_timings: p2_licks[i] = np.round(trial_event_timings['Port2In'],3).tolist()

    print('bpod_parse:', recordings, '2p recordings found', videos, 'videos found')

    if recordings*len(angles) != videos:
        print('bpod_parse: MISMATCH!!!!!')
        print('bpod_parse: continuing because this is happening fairly regularly')
        print('bpod_parse: probably should figure this out...')
    
    a, b = np.unique([x for x in SI_files if x], return_counts=True)
    if np.any(b>1): 
        print('bpod_parse: duplicate 2p TIFFs found!', a[b>1], b[b>1])
        for x in np.where(SI_files == a[b>1])[0][:-1]: SI_files[x]= '' # remove all but last

    Zs = np.unique(output[keys('z')][np.where([x.startswith('trial_') for x in SI_files])[0]])
    
    np.save(directory+'bpod.npy', np.array([output, SI_files, vid_files, p1_licks, p2_licks, bpod_times]))
    
    if not bpod_only:
        if len(glob(directory+'*Motion*csv')):
            os.makedirs(directory+'Motion/', exist_ok=True)
            cmd = 'mv '+' '.join(glob(directory+'*Motion*csv'))+' '+directory+'Motion/'
            print('bpod_parse: moving motion CSVs and combining them')
            os.system(cmd)    
            out = []
            for fn in glob(directory+'Motion/*csv'):
                with open(fn, newline = '') as ww:
                    r = csv.reader(ww)
                    x = [y for y in r][1:]
                    for y in x:
                        row = [fn, int(float(y[3]))]
                        for z in y[4:7]:
                            z = z.replace('[','').replace(']','').split(' ')
                            row += list(np.array(z)[[bool(x) for x in z]].astype(float))
                        out.append(row)                
            g = open(directory+'info/motion.txt', 'w', newline='')
            w = csv.writer(g,dialect='excel-tab')
            w.writerows(out)
            g.close()
        for fn in glob(directory+'slice_00*tif'):
            if 'reshape' in fn: continue
            I = tf.imread(fn)
            I = I.reshape([int(I.shape[0]/nchan), nchan, I.shape[1], I.shape[2]])
            tf.imsave(fn[:-3]+'reshape.tif', I, imagej=True, metadata={'axes': 'ZCYX', 'Composite mode': 'composite'})
        waitForJob(job) # can't move TIFFs when doing tiff check
        
        if any([os.path.exists(directory+fn) for fn in SI_files if fn]):
            for Z in Zs:
                os.makedirs(directory+str(int(Z))+'/', exist_ok=True)
                cmd = 'mv '+' '.join([directory+x for x in np.array(SI_files)[output[keys('z')]==Z] if x!='spont_00001_00001.tif'])+' '+directory+str(int(Z))+'/'
                print('bpod_parse: moving TIFFs from planes into different folders')
                os.system(cmd)
                cmd = bsub + ' -P svoboda -J '+job+' -n 10 -o '+directory+'logs/bidi.log python bidi.py '+directory+str(int(Z))+'/'
                print('bpod_parse:', cmd)
                os.system(cmd)
            spont = glob(directory+'spont_00*_*.tif')
            if len(spont):
                os.makedirs(directory+'spont/', exist_ok=True)
                cmd = 'mv '+' '.join(spont)+' '+directory+'spont/'
                print('bpod_parse: moving TIFFs from planes into different folders')
                os.system(cmd)
                cmd = bsub + ' -P svoboda -J '+job+' -n 10 -o '+directory+'logs/bidi.log python bidi.py '+directory+'spont/'
                print('bpod_parse:', cmd)
                os.system(cmd)
            for Z in Zs:
                cmd = bsub + ' -P svoboda -J '+job+' -n 10 -o '+directory+'logs/avg.log python avg_trials.py '+directory+str(int(Z))+'/'
                print('bpod_parse:', cmd)
                os.system(cmd)
            if os.path.exists(directory+'spont/'):
                cmd = bsub + ' -P svoboda -J '+job+' -n 10 -o '+directory+'logs/avg.log python avg_trials.py '+directory+'spont/'
                print('bpod_parse:', cmd)
                os.system(cmd)
            waitForJob(job)
            print('bpod_parse: delete any unnecessary bidi images or move spont images before averaging. then RUN:')
            print('bpod_parse: bsub -P svoboda -o '+directory+'process.log python '+__file__+' '+directory)
            s2p_out = '<BR>'.join(['python run_suite2p.py '+directory+str(int(Z))+'/' for Z in Zs]+['python run_suite2p.py '+directory+'spont/','python session_analysis.py '+directory])
            try:
                print('emailing...')
                from mailjet_rest import Client
                mailjet = Client(auth=('78055a65c13ef638d5a8b5fe05c503f6', '4fee843e5bdba74c0c5bbebc3d35a1ba'), version='v3.1')
                data = {
                  'Messages': [ {
                      "From": { "Email": "timtimspim@gmail.com", "Name": "Light" },
                      "To": [ { "Email": "wangt@janelia.hhmi.org",  "Name": "Tim" } ],
                      "Subject": os.path.basename(directory[:-1])+' bidi and averaging done',
                      "HTMLPart": s2p_out,
                   } ]
                }
                result = mailjet.send.create(data=data)
            except: print('mail fail')
            # quit()
        else:
            for Z in Zs:
                cmd = bsub + ' -P svoboda -J '+job+' -n 10 -o '+directory+'logs/avg.log python avg_trials.py '+directory+str(int(Z))+'/'
                print('bpod_parse:', cmd)
                os.system(cmd)
            if os.path.exists(directory+'spont/'):
                cmd = bsub + ' -P svoboda -J '+job+' -n 10 -o '+directory+'logs/avg.log python avg_trials.py '+directory+'spont/'
                print('bpod_parse:', cmd)
                os.system(cmd)
    else: waitForJob(job) # we still need to wait for TIFF checks to complete

    cmd = bsub + ' -P svoboda -J '+job+' -o '+directory+'logs/check_mm.log python check_mismatches.py '+directory
    print('bpod_parse:', cmd)
    if not bpod_only: os.system(cmd)
    waitForJob(job)
    cmd = bsub + ' -P svoboda -J '+job+' -o '+directory+'logs/check_sess.log python session_analysis.py '+directory
    print('bpod_parse:', cmd)
    if not bpod_only: os.system(cmd)
    
    print('bpod_parse: check summaries. when ready, remove bad planes and run:')
    for Z in Zs: print('python run_suite2p.py '+directory+str(int(Z))+'/')
    if os.path.exists(directory+'spont/'): print('python run_suite2p.py '+directory+'spont/')
    # print('bpod_parse: or if suite2p is already done, run:')
    # for Z in Zs: print(bsub + ' -P svoboda -o /dev/null -n 25 python trial_analysis.Jan15.py '+directory+str(int(Z))+'/')
    # print('bpod_parse: or if suite2p is already done, run:')
    # for Z in Zs: print(bsub + ' -P svoboda -o /dev/null -n 25 python free_trial_analysis.py '+directory+str(int(Z))+'/')



================================================
FILE: alm_data/build_global_registry.py
================================================
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Build a mouse-level global registry (entity cells -> global indices) from Stage-1 NPZ files.

Key ideas:
- Each entity cell is uniquely identified by (animal, session_id, plane, array_idx).
- We choose top-K sessions by available neurons (n_cells_kept), and then sample cells into a
  global observed pool of size N_obs (or use all if insufficient).
- Output:
  1) registry.csv
  2) unit_to_obs_idx.json  (unit_key -> list of global_idx)
  3) stats.json

python build_global_registry.py \
  --animal kd95 \
  --stage1_dir /home/jingyi.xu/ALM/results/stage1 \
  --out_dir /home/jingyi.xu/ALM/results/registry/kd95 \
  --top_sessions 1 \
  --session_agg sum \
  --n_global_obs 100 \
  --n_min_per_unit 10 \
  --n_max_per_unit 100 \
  --cell_select random \
  --seed 42

Stage-1 NPZ is assumed to contain (at least):
  session_id, plane, animal, keep_idx, cell_subclasses, cell_clusters
"""

import os
import re
import json
import argparse
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional, Any
from collections import defaultdict, Counter

import numpy as np
import pandas as pd


# ---------------------------
# Helpers
# ---------------------------

NPZ_RE = re.compile(r"^psth_(\d{8}_\d{6})\.(\w+)\.npz$")


@dataclass
class UnitRec:
    animal: str
    session_id: str
    plane: str
    npz_path: str
    n_kept: int
    keep_idx: np.ndarray              # (n_kept,)
    cell_subclasses: np.ndarray       # (n_kept,) dtype=str/object
    cell_clusters: np.ndarray         # (n_kept,) dtype=str/object
    manifest_flags: Optional[Dict[str, Any]] = None
    manifest_match_summary: Optional[Dict[str, Any]] = None

    @property
    def unit_key(self) -> str:
        return f"{self.session_id}.{self.plane}"


def _as_str_array(x: Any, n: int) -> np.ndarray:
    """Convert npz-loaded arrays to a safe string array of length n."""
    if x is None:
        return np.array([""] * n, dtype=object)
    arr = np.asarray(x)
    if arr.shape[0] != n:
        # be tolerant: pad/truncate if needed
        out = np.array([""] * n, dtype=object)
        m = min(n, arr.shape[0])
        out[:m] = arr[:m]
        return out.astype(object)
    return arr.astype(object)


def load_manifest_optional(path: Optional[str]) -> Optional[dict]:
    if not path:
        return None
    if not os.path.exists(path):
        print(f"[WARN] manifest not found at: {path} (ignored)")
        return None
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def index_manifest(manifest: dict, animal: str) -> Dict[Tuple[str, str], Dict[str, Any]]:
    """
    Return dict keyed by (session_id, plane) -> record containing flags + match_summary.
    Manifest sessions are built per (session_id, plane). See build_manifest.py structure.
    """
    out: Dict[Tuple[str, str], Dict[str, Any]] = {}
    for a in manifest.get("animals", []):
        if str(a.get("animal")) != animal:
            continue
        for srec in a.get("sessions", []):
            sid = str(srec.get("session_id"))
            plane = str(srec.get("plane"))
            out[(sid, plane)] = {
                "flags": srec.get("flags", {}),
                "match_summary": srec.get("match_summary", {}),
            }
    return out


def scan_stage1_units(stage1_animal_dir: str,
                      animal: str,
                      manifest_idx: Optional[Dict[Tuple[str, str], Dict[str, Any]]] = None,
                      require_flags: bool = False,
                      require_has_bpod: bool = True,
                      require_has_check: bool = True) -> List[UnitRec]:
    """
    Scan psth_*.npz under stage1_animal_dir and build UnitRec list.
    Optionally filter by manifest flags.
    """
    units: List[UnitRec] = []
    if not os.path.isdir(stage1_animal_dir):
        raise FileNotFoundError(f"Stage1 dir not found: {stage1_animal_dir}")

    for fn in sorted(os.listdir(stage1_animal_dir)):
        m = NPZ_RE.match(fn)
        if not m:
            continue
        sid, plane = m.group(1), m.group(2)
        npz_path = os.path.join(stage1_animal_dir, fn)

        # Manifest filter (optional)
        flags = None
        match_summary = None
        if manifest_idx is not None and (sid, plane) in manifest_idx:
            flags = manifest_idx[(sid, plane)].get("flags", {}) or {}
            match_summary = manifest_idx[(sid, plane)].get("match_summary", {}) or {}
            if require_flags:
                if require_has_bpod and not bool(flags.get("has_bpod", False)):
                    continue
                if require_has_check and not bool(flags.get("has_check", False)):
                    continue

        try:
            data = np.load(npz_path, allow_pickle=True)
        except Exception as e:
            print(f"[WARN] failed to load {npz_path}: {e}")
            continue

        # Required fields in your stage1 outputs (see digest)
        keep_idx = np.asarray(data["keep_idx"], dtype=int)
        n_kept = int(keep_idx.shape[0])

        cell_subclasses = _as_str_array(data.get("cell_subclasses", None), n_kept)
        cell_clusters = _as_str_array(data.get("cell_clusters", None), n_kept)

        # sanity: stage1 also saved session_id/plane/animal; but trust filename first
        units.append(UnitRec(
            animal=animal,
            session_id=str(data.get("session_id", sid)),
            plane=str(data.get("plane", plane)),
            npz_path=npz_path,
            n_kept=n_kept,
            keep_idx=keep_idx,
            cell_subclasses=cell_subclasses,
            cell_clusters=cell_clusters,
            manifest_flags=flags,
            manifest_match_summary=match_summary
        ))

    return units


def rank_sessions_by_neurons(units: List[UnitRec],
                            session_agg: str = "sum") -> List[Tuple[str, int]]:
    """
    Compute per-session neuron counts (aggregated across planes) and return sorted list desc.
    session_agg: "sum" or "max"
    """
    by_sess: Dict[str, List[int]] = defaultdict(list)
    for u in units:
        by_sess[u.session_id].append(u.n_kept)

    sess_scores = []
    for sid, lst in by_sess.items():
        if session_agg == "max":
            score = int(max(lst))
        else:
            score = int(sum(lst))
        sess_scores.append((sid, score))

    sess_scores.sort(key=lambda x: (-x[1], x[0]))
    return sess_scores


def choose_top_sessions(units: List[UnitRec],
                        top_sessions: int,
                        session_agg: str = "sum") -> Tuple[List[UnitRec], List[Tuple[str, int]]]:
    """
    Keep only units whose session_id is in top-K sessions by neuron availability.
    """
    sess_scores = rank_sessions_by_neurons(units, session_agg=session_agg)
    if top_sessions <= 0 or top_sessions >= len(sess_scores):
        chosen = set([sid for sid, _ in sess_scores])
    else:
        chosen = set([sid for sid, _ in sess_scores[:top_sessions]])
    kept_units = [u for u in units if u.session_id in chosen]
    kept_scores = [(sid, sc) for sid, sc in sess_scores if sid in chosen]
    return kept_units, kept_scores


def sample_registry(units: List[UnitRec],
                    n_global_obs: int,
                    n_min_per_unit: int,
                    n_max_per_unit: int,
                    celltype_field: str = "subclass",
                    cell_select: str = "random",
                    seed: int = 0) -> Tuple[pd.DataFrame, Dict[str, List[int]], dict]:
    """
    Build registry by sampling entity cells from each unit.

    Strategy:
    - Phase 1: take at least n_min_per_unit from each unit (if available).
    - Phase 2: fill remaining quota with a round-robin across units up to n_max_per_unit.

    celltype_field: "subclass" or "cluster"
    cell_select: "random" | "first"
    """
    rng = np.random.default_rng(seed)

    # Prepare per-unit candidate indices (positions in kept array)
    per_unit_candidates: Dict[str, List[int]] = {}
    per_unit_taken: Dict[str, List[int]] = {}
    for u in units:
        key = u.unit_key
        idxs = list(range(u.n_kept))
        if cell_select == "random":
            rng.shuffle(idxs)
        # else "first": keep natural order
        per_unit_candidates[key] = idxs
        per_unit_taken[key] = []

    def _take_from_unit(u: UnitRec, k: int):
        key = u.unit_key
        cand = per_unit_candidates[key]
        take = cand[:k]
        per_unit_candidates[key] = cand[k:]
        per_unit_taken[key].extend(take)

    # Phase 1: minimum coverage
    for u in units:
        k = min(n_min_per_unit, u.n_kept, n_max_per_unit)
        if k > 0:
            _take_from_unit(u, k)

    # Total taken so far
    total_taken = sum(len(v) for v in per_unit_taken.values())

    # If user wants fewer than minimum total, truncate later
    # Phase 2: fill remaining quota with round-robin up to per-unit max
    target = n_global_obs if n_global_obs > 0 else total_taken
    if target < total_taken:
        # We'll truncate globally at the end; still keep per-unit mapping coherent
        pass
    else:
        remaining = target - total_taken
        # Units that still can contribute (respecting n_max_per_unit)
        unit_order = [u.unit_key for u in sorted(units, key=lambda x: (-x.n_kept, x.unit_key))]
        while remaining > 0:
            progressed = False
            for u in units:
                key = u.unit_key
                if remaining <= 0:
                    break
                if len(per_unit_taken[key]) >= min(n_max_per_unit, u.n_kept):
                    continue
                if len(per_unit_candidates[key]) == 0:
                    continue
                _take_from_unit(u, 1)
                remaining -= 1
                progressed = True
                if remaining <= 0:
                    break
            if not progressed:
                break  # no more candidates anywhere

    # Build registry rows
    rows = []
    global_idx = 0
    unit_to_obs: Dict[str, List[int]] = defaultdict(list)

    # Flatten chosen entities in a stable order (by session_id, plane) for reproducibility
    units_sorted = sorted(units, key=lambda u: (u.session_id, str(u.plane)))
    for u in units_sorted:
        key = u.unit_key
        chosen_pos = per_unit_taken[key]

        # If need to truncate globally (n_global_obs < min-coverage total), do it here
        if n_global_obs > 0 and global_idx >= n_global_obs:
            break

        # Determine celltype vector
        if celltype_field == "cluster":
            ctype_vec = u.cell_clusters
        else:
            ctype_vec = u.cell_subclasses

        for pos in chosen_pos:
            if n_global_obs > 0 and global_idx >= n_global_obs:
                break
            array_idx = int(u.keep_idx[pos])
            roi_1based = int(array_idx + 1)

            subclass = str(u.cell_subclasses[pos]) if pos < len(u.cell_subclasses) else ""
            cluster = str(u.cell_clusters[pos]) if pos < len(u.cell_clusters) else ""

            rows.append({
                "global_idx": global_idx,
                "animal": u.animal,
                "session_id": u.session_id,
                "plane": str(u.plane),
                "unit_key": key,
                "array_idx": array_idx,
                "ROI_1based": roi_1based,
                "cell_subclass": subclass,
                "cell_cluster": cluster,
                "npz_path": os.path.abspath(u.npz_path),
                # optional manifest annotations
                "has_bpod": (u.manifest_flags or {}).get("has_bpod", None),
                "has_check": (u.manifest_flags or {}).get("has_check", None),
                "n_pairs_total": (u.manifest_match_summary or {}).get("n_pairs_total", None),
                "ge40_s1": ((u.manifest_match_summary or {}).get("ge40", {}) or {}).get("s1", None),
                "ge40_s2": ((u.manifest_match_summary or {}).get("ge40", {}) or {}).get("s2", None),
            })
            unit_to_obs[key].append(global_idx)
            global_idx += 1

    df = pd.DataFrame(rows)

    # Stats
    stats = {
        "n_units": int(len(units)),
        "n_global_obs": int(df.shape[0]),
        "n_min_per_unit": int(n_min_per_unit),
        "n_max_per_unit": int(n_max_per_unit),
        "cell_select": cell_select,
        "celltype_field": celltype_field,
        "unit_sizes_kept": {u.unit_key: int(u.n_kept) for u in units},
        "unit_sampled": {k: int(len(v)) for k, v in unit_to_obs.items()},
        "cell_subclass_counts": dict(Counter(df["cell_subclass"].astype(str).tolist())),
        "cell_cluster_counts": dict(Counter(df["cell_cluster"].astype(str).tolist())),
    }
    return df, dict(unit_to_obs), stats


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--animal", required=True, help="e.g. kd95")
    ap.add_argument("--stage1_dir", required=True, help="e.g. /home/jingyi.xu/ALM/results/stage1")
    ap.add_argument("--out_dir", required=True, help="output directory for registry files")
    ap.add_argument("--manifest", default=None, help="optional: ~/ALM/meta/manifest.json")
    ap.add_argument("--require_manifest_flags", action="store_true",
                    help="if set, filter units by manifest flags (bpod/check).")
    ap.add_argument("--require_has_bpod", action="store_true", help="used with --require_manifest_flags")
    ap.add_argument("--require_has_check", action="store_true", help="used with --require_manifest_flags")

    # Session selection
    ap.add_argument("--top_sessions", type=int, default=0,
                    help="Keep only top-K sessions by available neurons (0 = keep all).")
    ap.add_argument("--session_agg", choices=["sum", "max"], default="sum",
                    help="How to aggregate neuron counts across planes for session ranking.")

    # Registry sampling
    ap.add_argument("--n_global_obs", type=int, default=800, help="Total observed (entity) neurons in registry.")
    ap.add_argument("--n_min_per_unit", type=int, default=10, help="Min sampled neurons per unit (session.plane).")
    ap.add_argument("--n_max_per_unit", type=int, default=40, help="Max sampled neurons per unit (session.plane).")
    ap.add_argument("--celltype_field", choices=["subclass", "cluster"], default="subclass")
    ap.add_argument("--cell_select", choices=["random", "first"], default="random")
    ap.add_argument("--seed", type=int, default=0)

    args = ap.parse_args()

    stage1_animal_dir = os.path.join(args.stage1_dir, args.animal)
    os.makedirs(args.out_dir, exist_ok=True)

    manifest = load_manifest_optional(args.manifest)
    manifest_idx = index_manifest(manifest, args.animal) if manifest is not None else None

    units = scan_stage1_units(
        stage1_animal_dir=stage1_animal_dir,
        animal=args.animal,
        manifest_idx=manifest_idx,
        require_flags=args.require_manifest_flags,
        require_has_bpod=args.require_has_bpod,
        require_has_check=args.require_has_check,
    )

    if len(units) == 0:
        raise RuntimeError(f"No stage1 units found under: {stage1_animal_dir}")

    # Choose top-K sessions (by total neurons across planes)
    units_kept, sess_scores = choose_top_sessions(
        units, top_sessions=args.top_sessions, session_agg=args.session_agg
    )

    # Print session ranking summary
    print(f"\n[INFO] Found {len(units)} units total. Keeping {len(units_kept)} units after session selection.")
    print("[INFO] Top sessions (session_id, score):")
    for sid, sc in sess_scores[:min(len(sess_scores), max(10, args.top_sessions or 10))]:
        print(f"  {sid}: {sc}")

    # Build registry
    df, unit_to_obs, stats = sample_registry(
        units=units_kept,
        n_global_obs=args.n_global_obs,
        n_min_per_unit=args.n_min_per_unit,
        n_max_per_unit=args.n_max_per_unit,
        celltype_field=args.celltype_field,
        cell_select=args.cell_select,
        seed=args.seed,
    )

    out_csv = os.path.join(args.out_dir, f"{args.animal}.registry.csv")
    out_map = os.path.join(args.out_dir, f"{args.animal}.unit_to_obs_idx.json")
    out_stats = os.path.join(args.out_dir, f"{args.animal}.registry.stats.json")

    df.to_csv(out_csv, index=False)
    with open(out_map, "w", encoding="utf-8") as f:
        json.dump(unit_to_obs, f, ensure_ascii=False, indent=2)
    with open(out_stats, "w", encoding="utf-8") as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)

    print("\n[OK] Registry written:")
    print("  ", out_csv)
    print("  ", out_map)
    print("  ", out_stats)

    # Quick report
    print("\n[REPORT] Sampled neurons per unit (top 15 by sampled):")
    sampled = sorted(stats["unit_sampled"].items(), key=lambda x: -x[1])[:15]
    for k, v in sampled:
        print(f"  {k}: {v} / {stats['unit_sizes_kept'].get(k, '?')}")

    print("\n[REPORT] Cell subclass counts (top 20):")
    c = Counter(df["cell_subclass"].astype(str).tolist())
    for name, cnt in c.most_common(20):
        print(f"  {name}: {cnt}")


if __name__ == "__main__":
    main()



================================================
FILE: alm_data/utils_alm.py
================================================
# utils_alm.py
import os
import pickle as pkl
import numpy as np
import torch as tch

from bpod_parse import keys, outcomes

FPS_FALLBACK = 29.1
SESSION_TO_PATH = {}


def load_trial2p(trial_pkl_path):
    """读取 ALM 的 trial_2p.pkl: 返回 all_data, F, Fbase"""
    with open(trial_pkl_path, 'rb') as f:
        obj = pkl.load(f)
    all_data, F, Fbase = obj[0], obj[1], obj[2]
    # F: (cells, time, trials)
    return all_data, F, Fbase

def compute_dFoF_presample(F, fps, ss_frames):
    C, T, N = F.shape
    ss_frames = max(1, min(int(ss_frames), T))
    base = F[:, :ss_frames, :].mean(axis=1, keepdims=True)
    base = np.maximum(base, 1e-6)
    return (F - base) / base

def prelim_events_and_trials(all_data, fps):
    behavior = (all_data[keys('protocol')] == 5)
    freelick = (all_data[keys('protocol')] == 6)
    full_sample = (all_data[keys('earlysample')] == 0)
    full_delay  = (all_data[keys('earlydelay')]  == 0)
    trials_ok = behavior & full_sample & full_delay
    o  = all_data[keys('outcome')]
    tt = all_data[keys('trialtype')]
    CORR = np.isin(o, [outcomes('correct'), outcomes('droppednotlick')])
    INC  = (o == outcomes('incorrect'))
    IG   = (o == outcomes('ignore'))
    FT   = trials_ok | IG
    ss_sec = np.median(all_data[keys('samplestart')][FT])
    ld_sec = np.median(all_data[keys('lastdelay')][FT])
    go_sec = np.median(all_data[keys('go')][FT])
    ss = int(round(ss_sec * fps)); ld = int(round(ld_sec * fps)); go = int(round(go_sec * fps))
    vals = np.unique(tt)
    if set(vals.tolist()) >= {0,1}: L = (tt == 0); R = (tt == 1)
    elif set(vals.tolist()) >= {1,2}: L = (tt == 1); R = (tt == 2)
    else: mid = np.median(vals); L = (tt <= mid); R = (tt > mid)
    LC = np.where(trials_ok & L & CORR)[0]; RC = np.where(trials_ok & R & CORR)[0]
    LI = np.where(trials_ok & L & INC )[0]; RI = np.where(trials_ok & R & INC )[0]
    FL = np.where(full_sample & freelick)[0]; FLt = tt[FL]; FL_type = all_data[keys('freelicktype')][FL]
    FL_L = FL[(FLt == 0) & (FL_type == 1)]; FL_R = FL[(FLt == 1) & (FL_type == 1)]
    licks_needed = all_data[keys('licksneeded')]; puff = all_data[keys('puff')]
    LCo = LC[licks_needed[LC] == 1]; LCm = LC[licks_needed[LC] > 1]
    RCo = RC[licks_needed[RC] == 1]; RCm = RC[licks_needed[RC] > 1]
    LIp = LI[puff[LI] == 1];        LIn = LI[puff[LI] == 0]
    RIp = RI[puff[RI] == 1];        RIn = RI[puff[RI] == 0]
    agg_one   = np.concatenate((LCo, RCo)) if (LCo.size + RCo.size) else np.array([], int)
    agg_multi = np.concatenate((LCm, RCm)) if (LCm.size + RCm.size) else np.array([], int)
    agg_puff  = np.concatenate((LIp, RIp)) if (LIp.size + RIp.size) else np.array([], int)
    agg_nopf  = np.concatenate((LIn, RIn)) if (LIn.size + RIn.size) else np.array([], int)
    cond_idx = {
        'left_correct': LC, 'right_correct': RC, 'left_incorrect': LI, 'right_incorrect': RI,
        'free_left': FL_L, 'free_right': FL_R, 'correct_one_lick': agg_one, 'correct_multi_licks': agg_multi,
        'incorrect_puff': agg_puff, 'incorrect_no_puff': agg_nopf,
    }
    cond_idx = {k: v for k, v in cond_idx.items() if v.size > 0}
    return (ss, ld, go), cond_idx, FT, go_sec

def trial_average_all_neurons(list_sessions, hemi='left', max_time_index=350, fps=FPS_FALLBACK):
    """
    生成 trial-average neural activity:
    返回 trial_average: (2, T, N_total_neurons), indexes_list: {session_name: range}
    这里不再区分左右半球，hemi 参数仅用于接口兼容。
    """
    mean_rates = []
    indexes_list = {}
    s = 0

    for trial_pkl in list_sessions:
        ses_name = os.path.basename(trial_pkl)
        SESSION_TO_PATH[ses_name] = trial_pkl
        all_data, F, Fbase = load_trial2p(trial_pkl)
        C, T, N = F.shape

        T_keep = min(max_time_index, T)

        # 事件 & 条件划分
        (ss, ld, go), cond_idx, FT, go_sec = prelim_events_and_trials(all_data, fps)

        # ΔF/F (baseline: sample 前)
        dFoF = compute_dFoF_presample(F, fps, ss_frames=ss)  # (C, T, N)
        dFoF = dFoF[:, :T_keep, :]

        left_trials  = cond_idx.get('left_correct',  np.array([], int))
        right_trials = cond_idx.get('right_correct', np.array([], int))
        if left_trials.size == 0 or right_trials.size == 0:
            print(f"[WARN] {ses_name} 没有 left/right correct trial，跳过")
            continue

        left_avg  = np.nanmean(dFoF[:, :, left_trials],  axis=2)  # (C, T_keep)
        right_avg = np.nanmean(dFoF[:, :, right_trials], axis=2)

        left_TN  = left_avg.T    # (T, C)
        right_TN = right_avg.T
        rates = np.stack([left_TN, right_TN], axis=0)  # (2, T, C)

        mean_rates.append(rates)
        indexes_list[ses_name] = np.arange(s, s + C)
        s += C

    if not mean_rates:
        raise RuntimeError("trial_average_all_neurons: 没有有效 session")

    trial_average = np.concatenate(mean_rates, axis=2)  # (2, T, N_total)
    return trial_average, indexes_list



def mean_licks_inputs(list_sessions, hemi='left', max_time_index=350, fps=FPS_FALLBACK, device='cuda'):
    """
    简化版：目前先不给真实 lick 输入，返回全 0。
    接口保持和原 utils.mean_licks_inputs 完全一致。
    """
    trial_average, indexes = trial_average_all_neurons(
        list_sessions, hemi=hemi, max_time_index=max_time_index, fps=fps
    )
    mean_licks = np.zeros_like(trial_average, dtype=np.float32)
    mean_licks = tch.tensor(mean_licks, dtype=tch.float32, device=device)
    return mean_licks




def licks_inputs(list_sessions, hemi='left', max_time_index=350, fps=FPS_FALLBACK, device='cuda'):
    """
    简化版：单 trial lick 输入全部设为 0。
    返回: {session_name: tensor(2, n_trials, T)}
    """
    licks_per_session = {}
    for trial_pkl in list_sessions:
        ses_name = os.path.basename(trial_pkl)
        all_data, F, Fbase = load_trial2p(trial_pkl)
        C, T, N = F.shape
        T_keep = min(max_time_index, T)

        # 2 通道(left/right)，这里先全 0 占位
        # 注意原 DANDI 版本 shape 是 (2, n_trials, T)
        sess_licks = tch.zeros((2, N, T_keep), dtype=tch.float32, device=device)
        licks_per_session[ses_name] = sess_licks
    return licks_per_session



def load_me_data(list_sessions, default_parameters, hemi='left', max_time_index=350, fps=FPS_FALLBACK):
    """
    封装成和原 DANDI 版本接口一致的字典：
    - rates: (2, T, N_total)
    - indexes: {session_name: np.arange(...)}
    - n_trials, trial_types, time_average, neurons_average, responses
    """
    device = default_parameters['device']
    trial_average, indexes = trial_average_all_neurons(
        list_sessions, hemi=hemi, max_time_index=max_time_index, fps=fps
    )

    ALM_data = {}
    ALM_data['rates']   = trial_average
    ALM_data['indexes'] = indexes

    trial_types = {}
    n_trials = {}
    responses = {}
    time_average = {}
    neurons_average = {}

    for trial_pkl in list_sessions:
        ses_name = os.path.basename(trial_pkl)
        all_data, F, Fbase = load_trial2p(trial_pkl)
        C, T, N = F.shape
        T_keep = min(max_time_index, T)

        tt = all_data[keys('trialtype')]
        vals = np.unique(tt)
        if set(vals.tolist()) >= {0, 1}:
            L = (tt == 0)
            R = (tt == 1)
        elif set(vals.tolist()) >= {1, 2}:
            L = (tt == 1)
            R = (tt == 2)
        else:
            mid = np.median(vals)
            L = (tt <= mid)
            R = (tt > mid)

        ttypes = np.full_like(tt, fill_value=-1, dtype=int)
        ttypes[L] = 0
        ttypes[R] = 1
        trial_types[ses_name] = ttypes
        n_trials[ses_name] = tt.shape[0]

        # time_average / neurons_average 先给一个安全占位
        # 后面如果要严格复现合作者的 Loss 再精细化
        dFoF = compute_dFoF_presample(F, fps, ss_frames=int(np.median(all_data[keys('samplestart')] * fps)))
        dFoF = dFoF[:, :T_keep, :]  # (C, T_keep, N)

        # time_average: 直接用 trial_average 中该 session 的部分
        time_average[ses_name] = tch.tensor(
            trial_average[:, :T_keep, indexes[ses_name]],
            dtype=tch.float32,
            device=device
        )

        # neurons_average: 这里先填零张量占位
        neurons_avg = np.zeros((2, n_trials[ses_name], T_keep), dtype=np.float32)
        neurons_average[ses_name] = tch.tensor(neurons_avg, dtype=tch.float32, device=device)

        responses[ses_name] = all_data[keys('outcome')]

    ALM_data['n_trials']        = n_trials
    ALM_data['trial_types']     = trial_types
    ALM_data['time_average']    = time_average
    ALM_data['neurons_average'] = neurons_average
    ALM_data['responses']       = responses
    return ALM_data


def toch_version_ratates_trial_types(ALM_hemi, default_parameters, session_names):
    """
    把 numpy 的 rates / trial_types 转成 torch tensor。
    """
    device = default_parameters['device']
    rates_np = ALM_hemi['rates']   # (2, T, N_total)
    rates = tch.tensor(rates_np, dtype=tch.float32, device=device)

    trial_types = {}
    for ses_name in session_names:
        t_types = ALM_hemi['trial_types'][ses_name]
        t_types = tch.tensor(t_types, dtype=tch.float32, device=device)
        trial_types[ses_name] = t_types
    return rates, trial_types


def toch_single_trials(session_names, default_parameters, max_time_index=350, fps=FPS_FALLBACK):
    """
    session_names: 训练脚本传进来的 session 名（字典 key），例如 'kd95_twNew_20220823_205730.0.trial_2p.pkl'
    我们通过 SESSION_TO_PATH 找到对应的完整 trial_2p.pkl 路径。
    """
    device = default_parameters['device']
    single_trials_activity = {}

    for ses_name in session_names:
        # 从全局映射里取出完整路径；如果取不到，就退回用 ses_name 当路径（以防万一）
        trial_pkl = SESSION_TO_PATH.get(ses_name, ses_name)

        # 这里 trial_pkl 应该就是 '/allen/.../kd95_twNew_20220823_205730.0.trial_2p.pkl'
        all_data, F, Fbase = load_trial2p(trial_pkl)
        C, T, N = F.shape
        T_keep = min(max_time_index, T)

        # 和前面 trial_average 一样，先做 dFoF
        ss_sec = np.median(all_data[keys('samplestart')])
        ss_frames = int(round(ss_sec * fps))
        dFoF = compute_dFoF_presample(F, fps, ss_frames=ss_frames)  # (cells, time, trials)
        dFoF = dFoF[:, :T_keep, :]

        # 转成 (n_trials, T, n_neurons)
        trials_TCN = np.transpose(dFoF, (2, 1, 0))   # (N_trials, T_keep, C)
        data_tensor = tch.tensor(trials_TCN, dtype=tch.float32, device=device)

        single_trials_activity[ses_name] = data_tensor

    return single_trials_activity




================================================
FILE: current_rnn/build_lick_reward_trace.py
================================================
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Batch version: scan and update lick/reward traces for ALL stage1 PSTH npz of a given animal.

- Reuses the same core logic as build_lick_reward_trace.py:
  * prefer Tim's fixed *.licks.npy
  * robust align stage1 all_data columns -> bpod output columns
  * infer left/right from trialtype like 0.average.py
  * optional swap_p1_p2 safety switch

- Adds:
  * --animal/--manifest/--stage1_root batch mode
  * --auto_swap: evaluate both swap and no-swap consistency and auto-pick
  * --skip_if_has_reward / --force

python /home/jingyi.xu/code_rnn/current_rnn/build_lick_reward_trace.py \
  --animal kd95 \
  --manifest /home/jingyi.xu/ALM/meta/manifest.json \
  --stage1_root /home/jingyi.xu/ALM/results/stage1 \
  --only_correct \
  --lick_smooth_ms 200 \
  --reward_mode correctport \
  --auto_swap \
  --inplace

"""

import argparse
import os
import re
import json
import glob
import shutil
import numpy as np
from typing import Dict, Tuple, Optional, List, Any


# -----------------------------
# Bpod key maps (must match bpod_parse.py)
# -----------------------------
def keys(name: str = ""):
    d = {
        "outcome": 0,
        "trialtype": 1,
        "earlysample": 2,
        "earlydelay": 3,
        "puff": 4,
        "autowater": 5,
        "totalwater": 6,
        "length": 7,
        "z": 8,
        "power": 9,
        "freelick_pos": 10,
        "licksneeded": 11,
        "protocol": 12,
        "rfl": 13,
        "rt": 14,
        "samplestart": 15,
        "lastdelay": 16,
        "go": 17,
        "reward": 18,
        "freelicktype": 19,
        "reward1": 20,
    }
    return d[name] if name else d


def outcomes(name: str = ""):
    d = {
        "correct": 1,
        "incorrect": 2,
        "ignore": 3,
        "nofollow": 4,
        "droppednotlick": 5,
        "spont": 6,
    }
    return d[name] if name else d


# -----------------------------
# Same logic as 0.average.py: prelim_events_and_trials
# -----------------------------
def _infer_left_right_from_trialtype(tt: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    vals = np.unique(tt[~np.isnan(tt)])
    vals_set = set(vals.tolist())

    if vals_set >= {0, 1}:
        is_left = (tt == 0)
        is_right = (tt == 1)
    elif vals_set >= {1, 2}:
        is_left = (tt == 1)
        is_right = (tt == 2)
    else:
        mid = np.median(vals)
        is_left = (tt <= mid)
        is_right = (tt > mid)
    return is_left, is_right


def prelim_events_and_trials(all_data: np.ndarray, fps: float):
    behavior = (all_data[keys("protocol")] == 5)
    freelick = (all_data[keys("protocol")] == 6)
    full_sample = (all_data[keys("earlysample")] == 0)
    full_delay = (all_data[keys("earlydelay")] == 0)
    trials_ok = behavior & full_sample & full_delay

    o = all_data[keys("outcome")]
    tt = all_data[keys("trialtype")]

    # keep same as your pipeline: correct + droppednotlick
    CORR = np.isin(o, [outcomes("correct"), outcomes("droppednotlick")])
    INC = (o == outcomes("incorrect"))
    IG = (o == outcomes("ignore"))
    FT = trials_ok | IG

    ss_sec = np.median(all_data[keys("samplestart")][FT])
    ld_sec = np.median(all_data[keys("lastdelay")][FT])
    go_sec = np.median(all_data[keys("go")][FT])

    ss = int(round(ss_sec * fps))
    ld = int(round(ld_sec * fps))
    go = int(round(go_sec * fps))

    L, R = _infer_left_right_from_trialtype(tt)

    LC = np.where(trials_ok & L & CORR)[0]
    RC = np.where(trials_ok & R & CORR)[0]
    LI = np.where(trials_ok & L & INC)[0]
    RI = np.where(trials_ok & R & INC)[0]

    # freelick subsets (kept for completeness)
    FL = np.where(full_sample & freelick)[0]
    FLt = tt[FL]
    FL_type = all_data[keys("freelicktype")][FL]
    FL_L = FL[(FLt == 0) & (FL_type == 1)]
    FL_R = FL[(FLt == 1) & (FL_type == 1)]

    licks_needed = all_data[keys("licksneeded")]
    puff = all_data[keys("puff")]

    LCo = LC[licks_needed[LC] == 1]
    LCm = LC[licks_needed[LC] > 1]
    RCo = RC[licks_needed[RC] == 1]
    RCm = RC[licks_needed[RC] > 1]

    LIp = LI[puff[LI] == 1]
    LIn = LI[puff[LI] == 0]
    RIp = RI[puff[RI] == 1]
    RIn = RI[puff[RI] == 0]

    agg_one = np.concatenate((LCo, RCo)) if (LCo.size + RCo.size) else np.array([], int)
    agg_multi = np.concatenate((LCm, RCm)) if (LCm.size + RCm.size) else np.array([], int)
    agg_puff = np.concatenate((LIp, RIp)) if (LIp.size + RIp.size) else np.array([], int)
    agg_nopf = np.concatenate((LIn, RIn)) if (LIn.size + RIn.size) else np.array([], int)

    cond_idx = {
        "left_correct": LC,
        "right_correct": RC,
        "left_incorrect": LI,
        "right_incorrect": RI,
        "free_left": FL_L,
        "free_right": FL_R,
        "correct_one_lick": agg_one,
        "correct_multi_licks": agg_multi,
        "incorrect_puff": agg_puff,
        "incorrect_no_puff": agg_nopf,
    }
    cond_idx = {k: v for k, v in cond_idx.items() if v.size > 0}
    return (ss, ld, go), cond_idx, FT, go_sec


# -----------------------------
# Robust alignment: stage1 all_data columns -> bpod output columns
# -----------------------------
def _cols_equal(a: np.ndarray, b: np.ndarray, atol: float = 1e-6) -> bool:
    a = np.asarray(a)
    b = np.asarray(b)
    nan_both = np.isnan(a) & np.isnan(b)
    close = np.isclose(a, b, rtol=0.0, atol=atol)
    return bool(np.all(nan_both | close))


def _align_stage1_trials_to_bpod(stage1_all_data: np.ndarray, bpod_output: np.ndarray, atol: float = 1e-6) -> np.ndarray:
    """
    stage1_all_data: [21, N2p]
    bpod_output:     [21, Ntotal]
    Return idx_2p_in_bpod: [N2p,]
    """
    if stage1_all_data.ndim != 2 or stage1_all_data.shape[0] != 21:
        raise ValueError(f"stage1 all_data must be [21, N2p], got {stage1_all_data.shape}")
    if bpod_output.ndim != 2 or bpod_output.shape[0] != 21:
        raise ValueError(f"bpod output must be [21, Ntotal], got {bpod_output.shape}")

    N2p = stage1_all_data.shape[1]
    Ntotal = bpod_output.shape[1]

    idx = []
    start = 0
    for j in range(N2p):
        target = stage1_all_data[:, j]
        found = False

        # ordered subsequence search (fast)
        for i in range(start, Ntotal):
            if _cols_equal(bpod_output[:, i], target, atol=atol):
                idx.append(i)
                start = i + 1
                found = True
                break

        # fallback: global search
        if not found:
            for i in range(Ntotal):
                if _cols_equal(bpod_output[:, i], target, atol=atol):
                    idx.append(i)
                    start = i + 1
                    found = True
                    break

        if not found:
            raise ValueError(
                f"Failed to align stage1 trial {j}/{N2p}. "
                f"Try increasing --align_atol (e.g. 1e-4) or verify stage1/bpod are same session."
            )

    return np.asarray(idx, dtype=int)


# -----------------------------
# Load stage1 npz
# -----------------------------
def _unwrap_obj(x: Any) -> Any:
    if isinstance(x, np.ndarray) and x.dtype == object and x.shape == ():
        return x.item()
    return x


def _load_stage1_meta(stage1_npz_path: str):
    z = np.load(stage1_npz_path, allow_pickle=True)

    cond_names = list(np.asarray(z["cond_names"]).tolist())
    fps = float(z["fps"])

    event_frames = _unwrap_obj(z["event_frames"])
    if not isinstance(event_frames, dict):
        raise ValueError(f"event_frames should be a dict, got {type(event_frames)}")

    all_data = np.asarray(z["all_data"])
    if all_data.ndim != 2 or all_data.shape[0] != 21:
        raise ValueError(f"Expected all_data to be [21, Ntrials_2p], got {all_data.shape}")

    cell_psth = _unwrap_obj(z["cell_psth"])
    if not isinstance(cell_psth, dict) or len(cell_psth) == 0:
        raise ValueError("cell_psth missing or empty in stage1 npz.")

    any_cond = cond_names[0]
    M = np.asarray(cell_psth[any_cond])
    if M.ndim != 2:
        raise ValueError(f"cell_psth['{any_cond}'] must be (cells,time), got {M.shape}")
    n_cells = int(M.shape[0])
    T = int(M.shape[1])

    R_frame = int(event_frames["R"]) if "R" in event_frames else None

    return z, cond_names, fps, event_frames, R_frame, T, n_cells, all_data


# -----------------------------
# Load bpod output + fixed licks
# -----------------------------
def _load_bpod_output(bpod_npy_path: str) -> Tuple[np.ndarray, int]:
    b = np.load(bpod_npy_path, allow_pickle=True)
    bpod_output = np.asarray(b[0])
    if bpod_output.ndim != 2 or bpod_output.shape[0] != 21:
        raise ValueError(f"Expected bpod_output to be [21, N], got {bpod_output.shape}")
    n_trials_total = int(bpod_output.shape[1])
    return bpod_output, n_trials_total


def _as_list(obj: Any) -> List:
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    if isinstance(obj, list):
        return obj
    return list(obj)


def _is_lick_list_candidate(x: Any, n_trials_total: int) -> bool:
    if isinstance(x, np.ndarray) and x.dtype == object:
        x = x.tolist()
    if not isinstance(x, list):
        return False
    if len(x) != n_trials_total:
        return False

    for el in x[:10]:
        if el is None:
            continue
        if isinstance(el, (list, np.ndarray)):
            return True
        return False
    return True


def _load_fixed_licks_from_licks_npy(licks_npy_path: str, n_trials_total: int) -> Tuple[List, List]:
    l = np.load(licks_npy_path, allow_pickle=True)

    if isinstance(l, np.ndarray) and l.ndim == 1 and l.dtype == object:
        items = l.tolist()
    elif isinstance(l, (list, tuple)):
        items = list(l)
    else:
        items = _as_list(l)

    candidates = []
    for i, it in enumerate(items):
        if _is_lick_list_candidate(it, n_trials_total):
            candidates.append((i, _as_list(it)))

    if len(candidates) < 2:
        raise ValueError(
            f"Cannot find two lick-list arrays of length {n_trials_total} in {licks_npy_path}. "
            f"Found {len(candidates)} candidates. Please inspect the file structure."
        )

    p1 = candidates[0][1]
    p2 = candidates[1][1]
    return p1, p2


def _load_licks(bpod_npy_path: str, licks_npy_path: Optional[str], n_trials_total: int) -> Tuple[List, List, str]:
    if licks_npy_path is not None and os.path.exists(licks_npy_path):
        p1, p2 = _load_fixed_licks_from_licks_npy(licks_npy_path, n_trials_total)
        return p1, p2, f"licks_npy:{licks_npy_path}"

    b = np.load(bpod_npy_path, allow_pickle=True)
    try:
        p1 = _as_list(b[3])
        p2 = _as_list(b[4])
    except Exception as e:
        raise ValueError(f"Failed to load legacy p1/p2 from bpod.npy {bpod_npy_path}: {e}")

    if len(p1) != n_trials_total or len(p2) != n_trials_total:
        raise ValueError(
            f"Legacy bpod.npy p1/p2 length mismatch: len(p1)={len(p1)}, len(p2)={len(p2)}, "
            f"expected n_trials_total={n_trials_total}."
        )

    return p1, p2, "bpod_npy_legacy_p1p2"


# -----------------------------
# Build lick/reward traces
# -----------------------------
def _smooth_1d(x: np.ndarray, win: int) -> np.ndarray:
    if win <= 1:
        return x
    k = np.ones(int(win), dtype=float) / float(win)
    return np.convolve(np.asarray(x, float), k, mode="same")


def _is_keep_cond_only_correct(cond_name: str) -> bool:
    name = cond_name.lower()
    if "incorrect" in name:
        return False
    if name.startswith("free"):
        return False
    return ("correct" in name)


def build_lick_and_reward(
    cond_names: List[str],
    cond_idx: Dict[str, np.ndarray],
    all_data: np.ndarray,
    p1_licks_2p: List,
    p2_licks_2p: List,
    fps: float,
    R_frame: int,
    T: int,
    only_correct: bool,
    lick_smooth_ms: float,
    reward_mode: str,
    swap_p1_p2: bool = False,
):
    """
    Convention:
      - p1_licks_2p: left lickport (after Tim's fix) by default
      - p2_licks_2p: right lickport (after Tim's fix) by default
    If needed, set swap_p1_p2 to flip.
    """
    if swap_p1_p2:
        p1_licks_2p, p2_licks_2p = p2_licks_2p, p1_licks_2p

    C = len(cond_names)
    dt = 1.0 / float(fps)
    go_each = np.asarray(all_data[keys("go")], float)

    tt = np.asarray(all_data[keys("trialtype")], float)
    is_left, is_right = _infer_left_right_from_trialtype(tt)

    lick_left = np.zeros((C, T), dtype=np.float32)
    lick_right = np.zeros((C, T), dtype=np.float32)
    reward = np.zeros((C, T), dtype=np.float32)

    win = int(round((lick_smooth_ms / 1000.0) * fps))
    win = max(1, win)

    for ci, cname in enumerate(cond_names):
        trials = cond_idx.get(cname, np.array([], dtype=int))

        if only_correct and (not _is_keep_cond_only_correct(cname)):
            continue
        if trials.size == 0:
            continue

        cnt_L = np.zeros(T, dtype=np.float64)
        cnt_R = np.zeros(T, dtype=np.float64)
        cnt_reward = np.zeros(T, dtype=np.float64)

        n_used = 0
        for tr in trials:
            g = go_each[tr]
            if not np.isfinite(g):
                continue

            pL = np.asarray(p1_licks_2p[tr], float) if p1_licks_2p[tr] is not None else np.array([], float)
            pR = np.asarray(p2_licks_2p[tr], float) if p2_licks_2p[tr] is not None else np.array([], float)

            if pL.size > 0:
                fr = R_frame + np.round((pL - g) * fps).astype(int)
                fr = fr[(fr >= 0) & (fr < T)]
                for f in fr:
                    cnt_L[f] += 1.0

            if pR.size > 0:
                fr = R_frame + np.round((pR - g) * fps).astype(int)
                fr = fr[(fr >= 0) & (fr < T)]
                for f in fr:
                    cnt_R[f] += 1.0

            if reward_mode == "correctport":
                if bool(is_left[tr]):
                    src = pL
                elif bool(is_right[tr]):
                    src = pR
                else:
                    src = np.array([], float)

                if src.size > 0:
                    fr = R_frame + np.round((src - g) * fps).astype(int)
                    fr = fr[(fr >= 0) & (fr < T)]
                    for f in fr:
                        cnt_reward[f] += 1.0

            n_used += 1

        if n_used <= 0:
            continue

        rate_L = cnt_L / (n_used * dt)
        rate_R = cnt_R / (n_used * dt)
        rate_reward = cnt_reward / (n_used * dt)

        rate_L = _smooth_1d(rate_L, win)
        rate_R = _smooth_1d(rate_R, win)
        rate_reward = _smooth_1d(rate_reward, win)

        lick_left[ci, :] = rate_L.astype(np.float32)
        lick_right[ci, :] = rate_R.astype(np.float32)
        reward[ci, :] = rate_reward.astype(np.float32)

    lick_total = lick_left + lick_right
    return lick_left, lick_right, lick_total, reward


# -----------------------------
# Save updated npz (optionally inplace)
# -----------------------------
def _save_npz_updated(stage1_npz_path: str, z: np.lib.npyio.NpzFile, extra_fields: Dict[str, Any], inplace: bool):
    base = {k: z[k] for k in z.files}
    base.update(extra_fields)

    if inplace:
        bak = stage1_npz_path + ".bak"
        if not os.path.exists(bak):
            shutil.copy2(stage1_npz_path, bak)

        tmp = stage1_npz_path + ".tmp.npz"
        np.savez_compressed(tmp, **base)
        os.replace(tmp, stage1_npz_path)
        return stage1_npz_path, bak

    out = stage1_npz_path.replace(".npz", "_lick_reward.npz")
    np.savez_compressed(out, **base)
    return out, None


# -----------------------------
# Batch helpers
# -----------------------------
def _parse_session_id_from_stage1_npz(path: str) -> Optional[str]:
    """
    Expect stage1 naming like: psth_YYYYMMDD_HHMMSS.0.npz  (or variants)
    """
    base = os.path.basename(path)
    m = re.search(r"psth_(\d{8}_\d{6})", base)
    if m:
        return m.group(1)
    return None


def _build_bpod_map_from_manifest(manifest_path: str, animal: str) -> Dict[str, str]:
    """
    Return: session_id -> bpod.npy path
    Uses shared_files['bpod'] if exists; otherwise files['bpod'][0] if present.
    """
    with open(manifest_path, "r", encoding="utf-8") as f:
        man = json.load(f)

    for a in man.get("animals", []):
        if a.get("animal") != animal:
            continue
        out: Dict[str, str] = {}
        for s in a.get("sessions", []):
            sid = s.get("session_id")
            if not sid:
                continue
            shared = s.get("shared_files", {}) or {}
            files = s.get("files", {}) or {}

            bpod = shared.get("bpod", None)
            if (not bpod) and ("bpod" in files) and isinstance(files["bpod"], list) and len(files["bpod"]) > 0:
                bpod = files["bpod"][0]

            if bpod and os.path.exists(bpod):
                # multiple planes may repeat; keep first valid
                out.setdefault(sid, bpod)
        return out

    raise ValueError(f"Animal {animal} not found in manifest: {manifest_path}")


def _cond_index(cond_names: List[str], pattern: str) -> Optional[int]:
    pat = pattern.lower()
    for i, n in enumerate(cond_names):
        if pat in n.lower():
            return i
    return None


def _swap_goodness(lick_L: np.ndarray, lick_R: np.ndarray, cond_names: List[str], fps: float, R_frame: int) -> Optional[float]:
    """
    Higher is better:
      left_correct: lick_L > lick_R
      right_correct: lick_R > lick_L
    Evaluate over [0, 0.5] sec after go (relative).
    """
    iLC = _cond_index(cond_names, "left_correct")
    iRC = _cond_index(cond_names, "right_correct")
    if iLC is None or iRC is None:
        return None

    w0 = R_frame
    w1 = min(lick_L.shape[1], R_frame + int(round(0.5 * fps)))
    if w1 <= w0:
        return None

    lc = float(np.sum(lick_L[iLC, w0:w1]) - np.sum(lick_R[iLC, w0:w1]))
    rc = float(np.sum(lick_R[iRC, w0:w1]) - np.sum(lick_L[iRC, w0:w1]))
    return lc + rc


def _process_one(
    stage1_npz: str,
    bpod_npy: str,
    licks_npy: Optional[str],
    only_correct: bool,
    lick_smooth_ms: float,
    reward_mode: str,
    inplace: bool,
    align_atol: float,
    swap_p1_p2: bool,
    auto_swap: bool,
    verbose: bool = True,
) -> Tuple[bool, str]:
    """
    Return (ok, message). Writes to npz if ok.
    """
    z, cond_names, fps, event_frames, R_frame, T, n_cells, stage1_all_data = _load_stage1_meta(stage1_npz)
    (S, D, R_from_all_data), cond_idx, FT_mask, go_sec_median = prelim_events_and_trials(stage1_all_data, fps)
    if R_frame is None:
        R_frame = int(R_from_all_data)

    bpod_output, n_trials_total = _load_bpod_output(bpod_npy)

    # licks
    if licks_npy is None:
        if bpod_npy.endswith(".bpod.npy"):
            licks_npy = bpod_npy.replace(".bpod.npy", ".licks.npy")
        else:
            root, _ = os.path.splitext(bpod_npy)
            licks_npy = root + ".licks.npy"

    p1_licks_all, p2_licks_all, licks_source = _load_licks(bpod_npy, licks_npy, n_trials_total)

    # align stage1 trials into bpod indexing
    idx_2p_in_bpod = _align_stage1_trials_to_bpod(stage1_all_data, bpod_output, atol=align_atol)
    p1_licks_2p = [p1_licks_all[i] for i in idx_2p_in_bpod]
    p2_licks_2p = [p2_licks_all[i] for i in idx_2p_in_bpod]

    # decide swap
    chosen_swap = bool(swap_p1_p2)
    auto_note = ""
    if auto_swap:
        # compute both and pick the better one (if score computable)
        L0, R0, T0, rew0 = build_lick_and_reward(
            cond_names, cond_idx, stage1_all_data, p1_licks_2p, p2_licks_2p,
            fps=fps, R_frame=R_frame, T=T,
            only_correct=only_correct, lick_smooth_ms=lick_smooth_ms,
            reward_mode=reward_mode, swap_p1_p2=False
        )
        g0 = _swap_goodness(L0, R0, cond_names, fps=fps, R_frame=R_frame)

        L1, R1, T1, rew1 = build_lick_and_reward(
            cond_names, cond_idx, stage1_all_data, p1_licks_2p, p2_licks_2p,
            fps=fps, R_frame=R_frame, T=T,
            only_correct=only_correct, lick_smooth_ms=lick_smooth_ms,
            reward_mode=reward_mode, swap_p1_p2=True
        )
        g1 = _swap_goodness(L1, R1, cond_names, fps=fps, R_frame=R_frame)

        if (g0 is not None) and (g1 is not None):
            chosen_swap = bool(g1 > g0)
            auto_note = f" auto_swap goodness: no-swap={g0:.3f}, swap={g1:.3f}, choose_swap={chosen_swap}"
        else:
            auto_note = " auto_swap skipped (missing left_correct/right_correct in cond_names)."

    # build final traces with chosen swap
    lick_L, lick_R, lick_tot, reward = build_lick_and_reward(
        cond_names=cond_names,
        cond_idx=cond_idx,
        all_data=stage1_all_data,
        p1_licks_2p=p1_licks_2p,
        p2_licks_2p=p2_licks_2p,
        fps=fps,
        R_frame=R_frame,
        T=T,
        only_correct=only_correct,
        lick_smooth_ms=lick_smooth_ms,
        reward_mode=reward_mode,
        swap_p1_p2=chosen_swap,
    )

    t_rel_go_sec = (np.arange(T) - int(R_frame)) / float(fps)

    extra = {
        "lick_rate_left": lick_L,
        "lick_rate_right": lick_R,
        "lick_rate_total": lick_tot,
        "reward_trace": reward,
        "t_rel_go_sec": t_rel_go_sec.astype(np.float32),
        "idx_2p_in_bpod": idx_2p_in_bpod.astype(np.int32),
        "lick_smooth_ms": float(lick_smooth_ms),
        "reward_mode": str(reward_mode),
        "only_correct_lickreward": bool(only_correct),
        "align_atol_used": float(align_atol),
        "licks_source": np.array([licks_source], dtype=object),
        "swap_p1_p2_used": bool(chosen_swap),
        "licks_npy_used": np.array([licks_npy], dtype=object),
        "auto_swap_used": bool(auto_swap),
    }

    out_path, bak = _save_npz_updated(stage1_npz, z, extra, inplace=inplace)
    msg = f"[OK] {os.path.basename(stage1_npz)} -> updated (swap={chosen_swap})."
    if bak:
        msg += f" backup={os.path.basename(bak)}."
    if verbose:
        msg += auto_note
    return True, msg


# -----------------------------
# CLI
# -----------------------------
def main():
    ap = argparse.ArgumentParser()

    # single mode (compatible with your current script)
    ap.add_argument("--stage1_npz", type=str, default=None)
    ap.add_argument("--bpod_npy", type=str, default=None)
    ap.add_argument("--licks_npy", type=str, default=None)

    # batch mode
    ap.add_argument("--animal", type=str, default=None, help="e.g., kd95")
    ap.add_argument("--manifest", type=str, default=os.path.expanduser("~/ALM/meta/manifest.json"))
    ap.add_argument("--stage1_root", type=str, default=os.path.expanduser("~/ALM/results/stage1"),
                    help="Root dir containing <animal>/psth_*.npz")
    ap.add_argument("--glob", type=str, default="psth_*.npz", help="Pattern within stage1 animal dir")

    # behavior
    ap.add_argument("--swap_p1_p2", action="store_true",
                    help="Force swap (manual). If --auto_swap is set, auto decision will override.")
    ap.add_argument("--auto_swap", action="store_true",
                    help="Try both swap/no-swap and pick the more consistent one per session.")
    ap.add_argument("--only_correct", action="store_true")
    ap.add_argument("--lick_smooth_ms", type=float, default=200.0)
    ap.add_argument("--reward_mode", type=str, default="correctport", choices=["correctport"])
    ap.add_argument("--inplace", action="store_true")
    ap.add_argument("--align_atol", type=float, default=1e-6)

    # batch controls
    ap.add_argument("--skip_if_has_reward", action="store_true",
                    help="If npz already has 'reward_trace', skip unless --force.")
    ap.add_argument("--force", action="store_true", help="Force update even if reward_trace exists.")
    ap.add_argument("--dry_run", action="store_true", help="Print what would be done, no writing.")
    args = ap.parse_args()

    # decide mode
    is_batch = (args.animal is not None)
    is_single = (args.stage1_npz is not None and args.bpod_npy is not None)

    if (not is_batch) and (not is_single):
        raise ValueError("Either provide --stage1_npz and --bpod_npy (single mode), or provide --animal (batch mode).")

    if is_single:
        if args.dry_run:
            print(f"[DRY] would process: stage1={args.stage1_npz} bpod={args.bpod_npy}")
            return
        ok, msg = _process_one(
            stage1_npz=args.stage1_npz,
            bpod_npy=args.bpod_npy,
            licks_npy=args.licks_npy,
            only_correct=args.only_correct,
            lick_smooth_ms=args.lick_smooth_ms,
            reward_mode=args.reward_mode,
            inplace=args.inplace,
            align_atol=args.align_atol,
            swap_p1_p2=args.swap_p1_p2,
            auto_swap=args.auto_swap,
            verbose=True,
        )
        print(msg)
        return

    # batch mode
    animal = args.animal
    stage1_dir = os.path.join(args.stage1_root, animal)
    if not os.path.isdir(stage1_dir):
        raise FileNotFoundError(f"stage1 dir not found: {stage1_dir}")

    bpod_map = _build_bpod_map_from_manifest(args.manifest, animal)

    npz_list = sorted(glob.glob(os.path.join(stage1_dir, args.glob)))
    npz_list = [p for p in npz_list if (not p.endswith(".bak")) and (".tmp." not in p)]
    print(f"[INFO] batch: animal={animal} stage1_dir={stage1_dir} npz={len(npz_list)} manifest_bpod={len(bpod_map)}")

    n_ok, n_skip, n_fail = 0, 0, 0
    for npz_path in npz_list:
        sid = _parse_session_id_from_stage1_npz(npz_path)
        if sid is None:
            n_skip += 1
            print(f"[SKIP] cannot parse session_id from: {os.path.basename(npz_path)}")
            continue
        if sid not in bpod_map:
            n_skip += 1
            print(f"[SKIP] no bpod in manifest for sid={sid} npz={os.path.basename(npz_path)}")
            continue

        # skip if already has reward_trace
        if args.skip_if_has_reward and (not args.force):
            try:
                z0 = np.load(npz_path, allow_pickle=True)
                if "reward_trace" in z0.files:
                    n_skip += 1
                    print(f"[SKIP] reward_trace exists (use --force): {os.path.basename(npz_path)}")
                    continue
            except Exception:
                pass

        bpod = bpod_map[sid]
        licks = (bpod.replace(".bpod.npy", ".licks.npy") if bpod.endswith(".bpod.npy") else None)

        if args.dry_run:
            print(f"[DRY] sid={sid} npz={os.path.basename(npz_path)} bpod={bpod} licks={licks}")
            continue

        try:
            ok, msg = _process_one(
                stage1_npz=npz_path,
                bpod_npy=bpod,
                licks_npy=licks,
                only_correct=args.only_correct,
                lick_smooth_ms=args.lick_smooth_ms,
                reward_mode=args.reward_mode,
                inplace=args.inplace,
                align_atol=args.align_atol,
                swap_p1_p2=args.swap_p1_p2,
                auto_swap=args.auto_swap,
                verbose=True,
            )
            n_ok += 1
            print(msg)
        except Exception as e:
            n_fail += 1
            print(f"[FAIL] sid={sid} npz={os.path.basename(npz_path)} err={repr(e)}")

    print(f"[DONE] ok={n_ok} skip={n_skip} fail={n_fail}")


if __name__ == "__main__":
    main()



================================================
FILE: current_rnn/data_alm_current.py
================================================
# current_rnn/data_alm_current.py

import os
from typing import List, Optional, Dict, Any, Tuple

import numpy as np
import torch


def build_tone_waveform(
    T: int,
    fps: float,
    S_frame: int,
    sample_len_sec: float = 1.15,
    on_sec: float = 0.15,
    off_sec: float = 0.10,
    n_bursts: int = 5,
) -> np.ndarray:
    
    x = np.zeros(T, dtype=np.float32)

    on_frames = int(round(on_sec * fps))
    off_frames = int(round(off_sec * fps))
    sample_frames = int(round(sample_len_sec * fps))

    start = int(S_frame)
    end = min(T, start + sample_frames)

    t = start
    for k in range(n_bursts):
        if t >= end:
            break
        # ON
        t_on_end = min(end, t + on_frames)
        x[t:t_on_end] = 1.0
        t = t_on_end
        # OFF (last burst can omit off)
        if k < n_bursts - 1:
            t_off_end = min(end, t + off_frames)
            # already zeros
            t = t_off_end

    return x

def _normalize_cond_names(arr) -> List[str]:
    """
    Ensure cond_names loaded from npz is a list of Python strings.
    """
    if isinstance(arr, np.ndarray):
        # Could be array of bytes/str/object
        return [str(x) for x in arr.tolist()]
    # Fallback
    return [str(x) for x in list(arr)]


def build_dale_mask_from_types(is_excitatory: np.ndarray) -> torch.Tensor:
    """
    return dale_mask: [N, N]：
        excitatory → J[:, j] >= 0  (mask = +1)
        inhibitory → J[:, j] <= 0  (mask = -1)
    """
    N = is_excitatory.shape[0]
    dale_mask = np.zeros((N, N), dtype=np.int8)

    exc_idx = np.where(is_excitatory)[0]
    inh_idx = np.where(~is_excitatory)[0]

    # excitatory columns
    dale_mask[:, exc_idx] = 1
    # inhibitory columns
    dale_mask[:, inh_idx] = -1

    # do not constrain self-connection
    np.fill_diagonal(dale_mask, 0)

    return torch.from_numpy(dale_mask)

def load_alm_psth_npz(
    npz_path: str,
    cond_filter: Optional[List[str]] = None,
    max_time: Optional[int] = None,
    device: Optional[torch.device] = None,
    dtype: torch.dtype = torch.float32,
) -> Tuple[torch.Tensor, Dict[str, Any]]:
    """
    Load trial-averaged PSTH and metadata from a Stage 1 .npz file
    produced by alm_data/0.average.py.

    The .npz is expected to contain (see 0.average.py):
        - session_id, plane, animal
        - cond_names: array of condition names (keys of cell_psth)
        - cell_psth: dict[name] -> ndarray (cells, time)
        - cell_clusters, cell_subclasses
        - fps, t0_frame, event_frames, pre_frames, post_frames
        - keep_idx, n_cells_before
        - cond_counts, source_used, pkl_key_used, ...

    This function:
        1) Selects conditions to use (e.g. ['left_correct', 'right_correct']).
        2) Builds a tensor psth of shape [C, T, N], where:
           - C = number of selected conditions
           - T = number of time points (optionally truncated by max_time)
           - N = number of neurons after cell-type filtering
        3) Returns (psth, meta), where psth is a torch.Tensor and meta is a dict.

    Args:
        npz_path:   path to the Stage 1 npz file.
        cond_filter:
            - If None: try to use ['left_correct', 'right_correct'] if present,
              otherwise use all available conditions found in cell_psth.
            - If list: use the intersection of this list with available keys.
              If nothing matches, raise ValueError.
        max_time:
            - If not None: truncate time dimension to [0:max_time] frames.
        device:
            - Optional torch device to move psth tensor onto.
        dtype:
            - torch dtype for the returned psth.

    Returns:
        psth: torch.Tensor of shape [C, T, N]
        meta: dict containing metadata and numpy arrays (celltype info, etc.)
    """
    if not os.path.isfile(npz_path):
        raise FileNotFoundError(f"npz file not found: {npz_path}")

    data = np.load(npz_path, allow_pickle=True)

    # -------------------------------------------------------------------------
    # Condition names & cell_psth
    # -------------------------------------------------------------------------
    cond_names_all = _normalize_cond_names(data["cond_names"])
    cell_psth_obj = data["cell_psth"]
    # cell_psth was saved as a dict (object array), need .item() to recover
    if isinstance(cell_psth_obj, np.ndarray):
        cell_psth: Dict[str, np.ndarray] = cell_psth_obj.item()
    else:
        cell_psth = cell_psth_obj

    # --- decide which conditions to use ---
    if cond_filter is None:
        preferred = ["left_correct", "right_correct"]
        cond_names = [c for c in preferred if c in cell_psth]
        if not cond_names:
            # fallback: use all conditions that actually exist in cell_psth
            cond_names = [c for c in cond_names_all if c in cell_psth]
    else:
        cond_names = [c for c in cond_filter if c in cell_psth]
        if not cond_names:
            raise ValueError(
                f"No requested conditions {cond_filter} found in cell_psth keys "
                f"({list(cell_psth.keys())})."
            )

    if not cond_names:
        raise ValueError(
            f"No valid conditions found in npz file {npz_path}. "
            "Check that 0.average.py produced non-empty cell_psth."
        )

    # -------------------------------------------------------------------------
    # Build PSTH array: [C, T, N]
    # Each cell_psth[name] has shape (cells, time)
    # We transpose to (T, N) and then stack -> (C, T, N)
    # -------------------------------------------------------------------------
    psth_list = []
    T_min = None
    N = None

    # First pass: ensure all conditions have consistent (cells, time)
    for name in cond_names:
        M = cell_psth[name]  # (cells, time)
        if M is None:
            raise ValueError(f"cell_psth['{name}'] is None in {npz_path}")

        if N is None:
            N = M.shape[0]
        elif M.shape[0] != N:
            raise ValueError(
                f"Inconsistent neuron count among conditions in {npz_path}: "
                f"condition '{name}' has {M.shape[0]} cells, expected {N}."
            )

        if T_min is None:
            T_min = M.shape[1]
        else:
            T_min = min(T_min, M.shape[1])

    # If max_time is specified, clip by max_time; otherwise use min length across conditions
    if max_time is not None:
        T = min(T_min, max_time)
    else:
        T = T_min

    for name in cond_names:
        M = cell_psth[name]  # (cells, time)
        M = M[:, :T]         # truncate time if needed -> (N, T)
        M = M.T              # (T, N)
        psth_list.append(M)

    # stack to get (C, T, N)
    psth_np = np.stack(psth_list, axis=0)
    psth = torch.as_tensor(psth_np, dtype=dtype)
    if device is not None:
        psth = psth.to(device)

    # -------------------------------------------------------------------------
    # Collect metadata for later analyses
    # -------------------------------------------------------------------------
    # Cell-type info
    cell_clusters = np.asarray(data["cell_clusters"])
    cell_subclasses = np.asarray(data["cell_subclasses"])
    # some npz also stores 'cell_types'; keep if present
    cell_types = np.asarray(data["cell_types"]) if "cell_types" in data else cell_clusters

    # Time / alignment info
    fps = float(data["fps"])
    t0_frame = int(data["t0_frame"])
    pre_frames = int(data["pre_frames"])
    post_frames = int(data["post_frames"])

    # event_frames saved as a dict -> unwrap
    event_frames_obj = data["event_frames"]
    if isinstance(event_frames_obj, np.ndarray):
        # usually a 0-d object array containing a dict
        event_frames = event_frames_obj.item()
    else:
        event_frames = event_frames_obj

    # Index mapping and counts
    keep_idx = np.asarray(data["keep_idx"], dtype=int)
    n_cells_before = int(data["n_cells_before"])
    cond_counts_obj = data["cond_counts"]
    if isinstance(cond_counts_obj, np.ndarray):
        cond_counts = cond_counts_obj.item()
    else:
        cond_counts = cond_counts_obj

    # Session-level info
    session_id = str(data["session_id"])
    plane = str(data["plane"])
    animal = str(data["animal"])
    align_to = str(data["align_to"])
    source_used = str(data["source_used"])
    pkl_key_used = str(data["pkl_key_used"])

    meta: Dict[str, Any] = {
        # Core dimensions
        "cond_names": cond_names,
        "all_cond_names": cond_names_all,
        "C": len(cond_names),
        "T": T,
        "N": N,

        # Time / alignment
        "fps": fps,
        "t0_frame": t0_frame,
        "pre_frames": pre_frames,
        "post_frames": post_frames,
        "event_frames": event_frames,  # dict like {'S': ss, 'D': ld, 'R': go}
        "align_to": align_to,

        # Cell-type / indexing
        "cell_clusters": cell_clusters,
        "cell_subclasses": cell_subclasses,
        "cell_types": cell_types,
        "keep_idx": keep_idx,
        "n_cells_before": n_cells_before,

        # Condition counts (per condition)
        "cond_counts": cond_counts,

        # Session identifiers
        "session_id": session_id,
        "plane": plane,
        "animal": animal,

        # Provenance
        "source_used": source_used,
        "pkl_key_used": pkl_key_used,
        "npz_path": os.path.abspath(npz_path),
    }

    return psth, meta



================================================
FILE: current_rnn/debug.py
================================================
#!/usr/bin/env python
'''
python debug.py --npz /home/jingyi.xu/ALM/results/stage1/kd95/psth_20220823_205730.0.npz --go_only

'''
import argparse
import numpy as np


def _find_cond_idx(cond_names, target):
    target = target.lower()
    for i, n in enumerate(cond_names):
        if str(n).lower() == target:
            return i
    raise ValueError(f"Condition '{target}' not found in cond_names: {cond_names}")


def _summarize_one(name, t, lickL, lickR, rew, go_only=True):
    if go_only:
        m = (t >= 0)
        tag = "post-go"
    else:
        m = slice(None)
        tag = "all"

    # peak and mean in post-go window
    peakL = float(np.max(lickL[m]))
    peakR = float(np.max(lickR[m]))
    meanL = float(np.mean(lickL[m]))
    meanR = float(np.mean(lickR[m]))
    peakRew = float(np.max(rew[m]))
    meanRew = float(np.mean(rew[m]))

    # dominance (use peak; mean is also printed)
    dom = "LEFT" if peakL > peakR else ("RIGHT" if peakR > peakL else "TIE")
    ratio = float((peakL + 1e-9) / (peakR + 1e-9))

    print(f"[{name}] ({tag}) "
          f"lick_peak L={peakL:.3f} R={peakR:.3f}  "
          f"lick_mean L={meanL:.3f} R={meanR:.3f}  "
          f"reward_peak={peakRew:.3f} reward_mean={meanRew:.3f}  "
          f"dominant={dom}  peak(L/R)={ratio:.3f}")

    return dom, peakL, peakR, peakRew


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--npz", required=True, help="stage1 psth npz (updated with lick/reward fields)")
    ap.add_argument("--go_only", action="store_true", help="Only evaluate t_rel_go_sec>=0 window (recommended)")
    ap.add_argument("--min_reward_peak", type=float, default=0.2,
                    help="Minimum expected reward peak (heuristic) to call it 'present'")
    args = ap.parse_args()

    z = np.load(args.npz, allow_pickle=True)

    # required fields
    cond_names = z["cond_names"].tolist()
    t = np.asarray(z["t_rel_go_sec"], float)
    lickL_all = np.asarray(z["lick_rate_left"], float)    # [C,T]
    lickR_all = np.asarray(z["lick_rate_right"], float)   # [C,T]
    rew_all = np.asarray(z["reward_trace"], float)        # [C,T]

    iLC = _find_cond_idx(cond_names, "left_correct")
    iRC = _find_cond_idx(cond_names, "right_correct")

    print(f"[INFO] npz={args.npz}")
    print(f"[INFO] C={len(cond_names)} T={lickL_all.shape[1]}  "
          f"LC idx={iLC}  RC idx={iRC}")
    print(f"[INFO] pre-go reward max = {float(np.max(rew_all[:, t < 0])):.6f}")
    print(f"[INFO] post-go reward max = {float(np.max(rew_all[:, t >= 0])):.6f}")
    print("")

    domLC, lcL, lcR, lcRew = _summarize_one(
        "left_correct", t, lickL_all[iLC], lickR_all[iLC], rew_all[iLC], go_only=args.go_only
    )
    domRC, rcL, rcR, rcRew = _summarize_one(
        "right_correct", t, lickL_all[iRC], lickR_all[iRC], rew_all[iRC], go_only=args.go_only
    )

    print("\n[CHECK] Expected symmetry:")
    print("  - left_correct: LEFT should dominate (lick_left > lick_right), reward should be present")
    print("  - right_correct: RIGHT should dominate (lick_right > lick_left), reward should be present\n")

    ok_LC = (domLC == "LEFT") and (lcRew >= args.min_reward_peak)
    ok_RC = (domRC == "RIGHT") and (rcRew >= args.min_reward_peak)

    if ok_LC and ok_RC:
        print("[OK] LC/RC symmetry looks consistent. No swap likely needed.")
        return

    # Heuristic suggestion: if dominance is flipped (LC looks RIGHT-dominant and RC looks LEFT-dominant),
    # then p1/p2 (or left/right assignment) is likely swapped.
    flipped = (domLC == "RIGHT") and (domRC == "LEFT")
    if flipped:
        print("[WARN] Dominance appears flipped (LC is RIGHT-dominant, RC is LEFT-dominant).")
        print("       This strongly suggests left/right channels are swapped.")
        print("       Recommended action: re-run build_lick_reward_trace.py with --swap_p1_p2 and overwrite npz.")
    else:
        print("[WARN] Symmetry check failed but not a clean flip.")
        if domLC != "LEFT":
            print(f"       LC dominant={domLC} (expected LEFT).")
        if domRC != "RIGHT":
            print(f"       RC dominant={domRC} (expected RIGHT).")
        if lcRew < args.min_reward_peak or rcRew < args.min_reward_peak:
            print("       Reward peak is low in at least one condition; check reward_mode, only_correct, and alignment.")
        print("       Next step: print trial-level lick counts (or inspect licks.npy structure) to confirm mapping.")

if __name__ == "__main__":
    main()



================================================
FILE: current_rnn/eval_current_alm.py
================================================
# current_rnn/eval_current_alm.py
# Supports:
#   (A) single-session eval: --npz <stage1_npz>
#   (B) batch eval across registry: --eval_all --registry_dir <dir> --animal <id>
#
# Plots:
#   - One mosaic figure containing all selected neurons (each neuron is one subplot),
#     and time axis restricted to the SAME time_mask used in training (sample+delay+resp).
#   - In batch mode, neurons are sampled uniformly from all sessions' inhibitory units.
'''
python eval_current_alm.py --eval_all --registry_dir /home/jingyi.xu/ALM/results/registry/kd95 --animal kd95 --n_exc_virtual 400 --model /home/jingyi.xu/code_rnn/results_current/rnn_current_kd95_global_nobs100_nexc400_ntotal500.pt --psth_bin_ms 200 --sample_ignore_ms 50 --resp_sec 2.0 --out_dir /home/jingyi.xu/code_rnn/results_global/eval_kd95

'''
from __future__ import annotations

import argparse
import csv
import json
import math
import os
import random
from collections import defaultdict
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Sequence, Tuple

import numpy as np
import torch as tch
import matplotlib.pyplot as plt
import heapq


from data_alm_current import load_alm_psth_npz  # returns psth [C,T,N] + meta dict
from model_current import ALMCurrentRNN
from training_current import (
    _load_default_parameters,
    _maybe_attach_lick_reward_to_meta,
    _build_input_tensor,
    _time_bin_smooth_ctn,
    _build_time_mask_sample_delay_resp,
)

# -----------------------------
# Plot utilities
# -----------------------------

def plot_psth_comparison(
    t_sec: np.ndarray,
    psth_used: tch.Tensor,          # [C, Tm, Nsel]
    rates_used: tch.Tensor,         # [C, Tm, Nsel]
    idx_neurons: Sequence[int],
    mse_per_neuron: Optional[np.ndarray],
    cond_names: Sequence[str],
    out_path: str,
    ncols: int = 6,
    title: Optional[str] = None,
) -> None:
    """
    A single large figure that tiles all selected neurons into a grid.
    Each subplot contains:
      - LC ground-truth vs prediction
      - RC ground-truth vs prediction
    Time axis is already restricted to the training time_mask.
    """
    idx_neurons = list(map(int, idx_neurons))
    n_sel = len(idx_neurons)
    if n_sel == 0:
        raise ValueError("idx_neurons is empty.")

    C = int(psth_used.shape[0])
    if C < 2:
        raise ValueError(f"Expected at least 2 conditions (LC/RC). Got C={C}.")

    ncols = max(1, int(ncols))
    nrows = int(math.ceil(n_sel / ncols))

    fig_w = 3.2 * ncols
    fig_h = 2.6 * nrows
    fig, axes = plt.subplots(nrows, ncols, figsize=(fig_w, fig_h), squeeze=False, sharex=False, sharey=False)

    cond0 = str(cond_names[0]) if len(cond_names) > 0 else "cond0"
    cond1 = str(cond_names[1]) if len(cond_names) > 1 else "cond1"

    for i, n in enumerate(idx_neurons):
        r = i // ncols
        c = i % ncols
        ax = axes[r][c]

        gt0 = psth_used[0, :, n].detach().cpu().numpy()
        pr0 = rates_used[0, :, n].detach().cpu().numpy()
        gt1 = psth_used[1, :, n].detach().cpu().numpy()
        pr1 = rates_used[1, :, n].detach().cpu().numpy()

        l0, = ax.plot(t_sec, gt0, label=f"{cond0} GT")                  # GT 实线
        ax.plot(t_sec, pr0, linestyle="--", color=l0.get_color(),       # Fit 虚线，同色
        label=f"{cond0} Fit")

        l1, = ax.plot(t_sec, gt1, label=f"{cond1} GT")
        ax.plot(t_sec, pr1, linestyle="--", color=l1.get_color(),
        label=f"{cond1} Fit")


        if mse_per_neuron is not None:
            ax.set_title(f"n={n}  mse={float(mse_per_neuron[n]):.2e}", fontsize=9)
        else:
            ax.set_title(f"n={n}", fontsize=9)

        ax.axhline(0.0, linewidth=0.5)
        if i == 0:
            ax.legend(fontsize=8, loc="best")

    # hide unused axes
    for j in range(n_sel, nrows * ncols):
        r = j // ncols
        c = j % ncols
        axes[r][c].axis("off")

    if title is not None:
        fig.suptitle(title, fontsize=12)

    fig.tight_layout()
    os.makedirs(os.path.dirname(out_path) or ".", exist_ok=True)
    fig.savefig(out_path, dpi=200)
    plt.close(fig)
    print(f"[OK] Saved mosaic figure -> {out_path}")


def _select_neurons_by_mse(
    psth_used: tch.Tensor,   # [C,Tm,N]
    rates_used: tch.Tensor,  # [C,Tm,N]
    num_neurons: int,
    mode: str,
    rng_seed: int,
) -> Tuple[tch.Tensor, np.ndarray]:
    """
    mode:
      - best:  choose neurons with smallest MSE
      - worst: choose neurons with largest MSE
      - random: random subset
    """
    with tch.no_grad():
        err = (psth_used - rates_used) ** 2
        mse = err.mean(dim=(0, 1)).detach().cpu().numpy()  # [N]

    N = int(mse.shape[0])
    k = min(int(num_neurons), N)
    if k <= 0:
        raise ValueError("num_neurons must be > 0.")

    if mode == "best":
        idx = np.argsort(mse)[:k]
    elif mode == "worst":
        idx = np.argsort(mse)[-k:][::-1]
    elif mode == "random":
        rng = np.random.default_rng(int(rng_seed))
        idx = rng.choice(N, size=k, replace=False)
    else:
        raise ValueError(f"Unknown mode={mode}")

    idx_t = tch.as_tensor(idx, dtype=tch.long)
    return idx_t, mse


# -----------------------------
# Registry helpers (batch eval)
# -----------------------------

@dataclass
class RegistryRow:
    unit_key: str
    global_idx: int
    array_idx: int
    npz_path: str

def _read_registry_csv(registry_dir: str, animal: str) -> List[RegistryRow]:
    """
    Expected columns include: unit_key, global_idx, array_idx, npz_path
    (others are ignored).
    """
    cand1 = os.path.join(registry_dir, f"{animal}_registry.csv")
    cand2 = os.path.join(registry_dir, "registry.csv")
    path = cand1 if os.path.exists(cand1) else cand2
    if not os.path.exists(path):
        raise FileNotFoundError(f"Registry CSV not found: {cand1} or {cand2}")

    rows: List[RegistryRow] = []
    with open(path, "r", newline="") as f:
        reader = csv.DictReader(f)
        for rr in reader:
            rows.append(
                RegistryRow(
                    unit_key=str(rr["unit_key"]),
                    global_idx=int(float(rr["global_idx"])),
                    array_idx=int(float(rr["array_idx"])),
                    npz_path=str(rr["npz_path"]),
                )
            )
    if len(rows) == 0:
        raise ValueError(f"Empty registry: {path}")
    print(f"[INFO] Loaded registry: {path} (rows={len(rows)})")
    return rows


def _build_keepidx_pos_map(keep_idx: np.ndarray) -> Dict[int, int]:
    keep_idx = np.asarray(keep_idx, dtype=int)
    return {int(a): int(i) for i, a in enumerate(keep_idx.tolist())}


def _group_rows_by_unit(rows: List[RegistryRow]) -> Dict[str, List[RegistryRow]]:
    by_unit: Dict[str, List[RegistryRow]] = defaultdict(list)
    for r in rows:
        by_unit[r.unit_key].append(r)
    return by_unit


# -----------------------------
# Eval core
# -----------------------------

def _infer_device(params_path: Optional[str]) -> tch.device:
    default_parameters = _load_default_parameters(params_path)
    device_str = default_parameters.get("device", "cpu")
    device = tch.device(device_str if tch.cuda.is_available() or device_str == "cpu" else "cpu")
    return device


def _build_model_for_eval(
    model_path: str,
    D_in: int,
    N_total: int,
    params_path: Optional[str],
    device: tch.device,
) -> ALMCurrentRNN:
    default_parameters = _load_default_parameters(params_path)
    dt = float(default_parameters.get("dt", 1.0))
    tau = float(default_parameters.get("tau", 1.0))
    substeps = int(default_parameters.get("substeps", 1))

    net = ALMCurrentRNN(
        N=int(N_total),
        D_in=int(D_in),
        dt=dt,
        tau=tau,
        substeps=substeps,
        nonlinearity="tanh",
        device=device,
        dale_mask=None,  # eval 不强制 Dale；即便训练用了，也不需要从 ckpt 里恢复这块
    ).to(device)

    ckpt = tch.load(model_path, map_location=device)

    # 兼容两种保存格式：
    # (A) 直接保存 state_dict
    # (B) 保存 {"model": state_dict, "opt": ..., ...}
    if isinstance(ckpt, dict) and ("model" in ckpt) and isinstance(ckpt["model"], dict):
        state_dict = ckpt["model"]
    else:
        state_dict = ckpt

    # 清理不应由 checkpoint 驱动的条目
    if isinstance(state_dict, dict) and "dale_mask" in state_dict:
        state_dict = dict(state_dict)  # copy
        state_dict.pop("dale_mask", None)

    # 更稳妥：如果还有其他多余 key，也不应让 eval 崩溃
    missing, unexpected = net.load_state_dict(state_dict, strict=False)
    if len(unexpected) > 0:
        print(f"[WARN] Unexpected keys ignored: {unexpected[:10]}{' ...' if len(unexpected) > 10 else ''}")
    if len(missing) > 0:
        print(f"[WARN] Missing keys (left default): {missing[:10]}{' ...' if len(missing) > 10 else ''}")

    net.eval()
    return net



def _compute_time_mask_and_tsec(
    meta: Dict[str, Any],
    T: int,
    sample_ignore_ms: float,
    resp_sec: float,
) -> Tuple[np.ndarray, np.ndarray]:
    fps = float(meta["fps"])
    m = _build_time_mask_sample_delay_resp(
        T=T,
        fps=fps,
        meta=meta,
        sample_ignore_ms=float(sample_ignore_ms),
        resp_sec=float(resp_sec),
    )
    idx = np.where(m)[0]
    ev = meta.get("event_frames", {})
    S = int(ev["S"]) if isinstance(ev, dict) and "S" in ev else 0
    t_sec = (idx - S) / fps
    return m, t_sec


def eval_single_session(
    npz_path: str,
    model_path: str,
    params_path: Optional[str],
    noise_std: float,
    psth_bin_ms: float,
    sample_ignore_ms: float,
    resp_sec: float,
    num_neurons: int,
    mode: str,
    rng_seed: int,
    out_dir: Optional[str],
    device: tch.device,
) -> None:
    default_parameters = _load_default_parameters(params_path)

    psth, meta = load_alm_psth_npz(
        npz_path=npz_path,
        cond_filter=None,
        max_time=None,
        device=device,
        dtype=tch.float32,
    )
    C, T, N = psth.shape
    meta = _maybe_attach_lick_reward_to_meta(meta=meta, npz_path=npz_path, T=T)

    fps = float(meta.get("fps", 1.0))
    if psth_bin_ms is not None and float(psth_bin_ms) > 0:
        psth = _time_bin_smooth_ctn(psth, fps=fps, bin_ms=float(psth_bin_ms))

    cond_names = list(meta["cond_names"])
    amp_input = float(default_parameters.get("amp_input", 1.0))
    include_go_cue = bool(default_parameters.get("include_go_cue", True))
    go_cue_sec = float(default_parameters.get("go_cue_sec", 0.10))
    amp_go_cue = float(default_parameters.get("amp_go_cue", 1.0))
    include_reward = bool(default_parameters.get("include_reward", True))
    amp_reward = float(default_parameters.get("amp_reward", 1.0))

    u = _build_input_tensor(
        C=C,
        T=T,
        cond_names=cond_names,
        device=device,
        amp_input=amp_input,
        meta=meta,
        amp_stim=amp_input,
        sample_len_sec=1.15,
        on_sec=0.15,
        off_sec=0.10,
        n_bursts=5,
        include_go_cue=include_go_cue,
        go_cue_sec=go_cue_sec,
        amp_go_cue=amp_go_cue,
        include_reward=include_reward,
        amp_reward=amp_reward,
    )
    D_in = int(u.shape[-1])

    # NOTE: single-session eval assumes the model's N_total == N in npz
    net = _build_model_for_eval(
        model_path=model_path,
        D_in=D_in,
        N_total=N,
        params_path=params_path,
        device=device,
    )

    with tch.no_grad():
        out = net(u, h0=None, noise_std=float(noise_std), return_rate=True)
        rates_pred = out["rate"]  # [C,T,N]
        if psth_bin_ms is not None and float(psth_bin_ms) > 0:
            rates_pred = _time_bin_smooth_ctn(rates_pred, fps=fps, bin_ms=float(psth_bin_ms))

    mask_np, t_sec = _compute_time_mask_and_tsec(meta=meta, T=T, sample_ignore_ms=sample_ignore_ms, resp_sec=resp_sec)
    psth_used = psth[:, mask_np, :]
    rates_used = rates_pred[:, mask_np, :]

    idx_sel, mse = _select_neurons_by_mse(
        psth_used=psth_used,
        rates_used=rates_used,
        num_neurons=int(num_neurons),
        mode=str(mode),
        rng_seed=int(rng_seed),
    )

    model_tag = os.path.splitext(os.path.basename(model_path))[0]
    save_dir = out_dir or os.path.dirname(model_path) or "."
    out_png = os.path.join(save_dir, f"psth_eval_loss_window_{model_tag}.png")

    plot_psth_comparison(
        t_sec=t_sec,
        psth_used=psth_used,
        rates_used=rates_used,
        idx_neurons=idx_sel.tolist(),
        mse_per_neuron=mse,
        cond_names=cond_names,
        out_path=out_png,
        ncols=6,
        title=f"{model_tag}  unit={os.path.basename(npz_path)}  window=loss",
    )


def eval_all_units_from_registry(
    registry_dir: str,
    animal: str,
    model_path: str,
    params_path: Optional[str],
    n_exc_virtual: int,
    noise_std: float,
    psth_bin_ms: float,
    sample_ignore_ms: float,
    resp_sec: float,
    plot_n: int,
    plot_seed: int,   # 保留参数兼容CLI；best策略下不会影响结果（除非出现完全相等的极少数tie）
    plot_cols: int,
    out_dir: str,
    device: tch.device,
) -> None:
    """
    Batch eval across all units in registry.

    - Computes per-unit loss (MSE on training loss window).
    - For plotting: selects global Top-K neurons with the smallest MSE across ALL sessions' inhibitory neurons,
      and saves ONE mosaic figure.
    - GT and Fit for the same condition share the same color (GT solid, Fit dashed).
    """

    import heapq  # ensure this exists at top-level if you prefer

    os.makedirs(out_dir, exist_ok=True)

    # -----------------------------
    # Load registry and group by unit
    # -----------------------------
    rows = _read_registry_csv(registry_dir=registry_dir, animal=animal)
    by_unit = _group_rows_by_unit(rows)

    # -----------------------------
    # Infer N_total and D_in directly from checkpoint (most reliable)
    # -----------------------------
    ckpt = tch.load(model_path, map_location=device)
    if isinstance(ckpt, dict) and ("model" in ckpt) and isinstance(ckpt["model"], dict):
        state_dict = ckpt["model"]
    else:
        state_dict = ckpt

    # remove training-only keys if present
    if isinstance(state_dict, dict) and "dale_mask" in state_dict:
        state_dict = dict(state_dict)
        state_dict.pop("dale_mask", None)

    if "J" not in state_dict or "W_in" not in state_dict:
        raise KeyError(
            "Cannot infer N_total / D_in from checkpoint. "
            "Expected keys 'J' and 'W_in' in state_dict."
        )

    N_total = int(state_dict["J"].shape[0])
    D_in_ckpt = int(state_dict["W_in"].shape[1])

    # Build model once
    net = _build_model_for_eval(
        model_path=model_path,
        D_in=D_in_ckpt,
        N_total=N_total,
        params_path=params_path,
        device=device,
    )
    print(f"[INFO] Loaded model: N_total={N_total}, D_in={D_in_ckpt}")

    # -----------------------------
    # Eval accumulators
    # -----------------------------
    per_unit_stats: List[Dict[str, Any]] = []

    # Global Top-K best neurons across all sessions:
    # store (-mse, counter, record)
    plot_k = int(plot_n)
    top_heap: List[Tuple[float, int, Dict[str, Any]]] = []
    counter = 0

    # -----------------------------
    # Iterate units
    # -----------------------------
    default_parameters = _load_default_parameters(params_path)
    amp_input = float(default_parameters.get("amp_input", 1.0))
    include_go_cue = bool(default_parameters.get("include_go_cue", True))
    go_cue_sec = float(default_parameters.get("go_cue_sec", 0.10))
    amp_go_cue = float(default_parameters.get("amp_go_cue", 1.0))
    include_reward = bool(default_parameters.get("include_reward", True))
    amp_reward = float(default_parameters.get("amp_reward", 1.0))

    for unit_key, items in by_unit.items():
        # all rows in a unit should share same npz_path
        npz_path = items[0].npz_path
        for rr in items[1:]:
            if rr.npz_path != npz_path:
                raise ValueError(f"unit_key={unit_key} has inconsistent npz_path in registry.")

        # load PSTH + meta
        psth, meta = load_alm_psth_npz(
            npz_path=npz_path,
            cond_filter=None,
            max_time=None,
            device=device,
            dtype=tch.float32,
        )
        C, T, N_kept = psth.shape
        meta = _maybe_attach_lick_reward_to_meta(meta=meta, npz_path=npz_path, T=T)

        fps = float(meta.get("fps", 1.0))

        # time bin / smooth (apply to both GT and prediction to match your training setting)
        if psth_bin_ms is not None and float(psth_bin_ms) > 0:
            psth = _time_bin_smooth_ctn(psth, fps=fps, bin_ms=float(psth_bin_ms))

        # map registry array_idx -> position in keep_idx
        keep_idx = meta.get("keep_idx", None)
        if keep_idx is None:
            raise KeyError(f"meta['keep_idx'] missing in stage1 npz: {npz_path}")
        keep_map = _build_keepidx_pos_map(np.asarray(keep_idx, dtype=int))

        pos_list: List[int] = []
        g_list: List[int] = []
        for rr in items:
            ai = int(rr.array_idx)
            if ai not in keep_map:
                raise ValueError(
                    f"array_idx={ai} not found in keep_idx of {npz_path} (unit_key={unit_key}). "
                    "Check registry builder mapping."
                )
            pos_list.append(int(keep_map[ai]))
            g_list.append(int(rr.global_idx))

        pos_t = tch.as_tensor(pos_list, dtype=tch.long, device=device)
        psth_sub = psth.index_select(dim=2, index=pos_t)  # [C,T,K]
        K = int(psth_sub.shape[2])

        # build input u with meta (must match training)
        cond_names = list(meta["cond_names"])
        u = _build_input_tensor(
            C=C,
            T=T,
            cond_names=cond_names,
            device=device,
            amp_input=amp_input,
            meta=meta,
            amp_stim=amp_input,
            sample_len_sec=1.15,
            on_sec=0.15,
            off_sec=0.10,
            n_bursts=5,
            include_go_cue=include_go_cue,
            go_cue_sec=go_cue_sec,
            amp_go_cue=amp_go_cue,
            include_reward=include_reward,
            amp_reward=amp_reward,
        )

        D_in = int(u.shape[-1])
        if D_in != D_in_ckpt:
            raise ValueError(
                f"D_in mismatch for unit_key={unit_key}: built u has D_in={D_in}, "
                f"but checkpoint expects D_in={D_in_ckpt}. "
                "This means your eval input construction differs from training."
            )

        # indices into the global net: offset inhibitory by n_exc_virtual
        idx_net = tch.as_tensor(
            [int(n_exc_virtual) + int(g) for g in g_list],
            dtype=tch.long,
            device=device,
        )

        # forward
        with tch.no_grad():
            out = net(u, h0=None, noise_std=float(noise_std), return_rate=True)
            rates_full = out["rate"]  # [C,T,N_total]
            if psth_bin_ms is not None and float(psth_bin_ms) > 0:
                rates_full = _time_bin_smooth_ctn(rates_full, fps=fps, bin_ms=float(psth_bin_ms))
            pred_sub = rates_full.index_select(dim=2, index=idx_net)  # [C,T,K]

        # time mask (same as training loss window)
        mask_np, t_sec = _compute_time_mask_and_tsec(
            meta=meta, T=T, sample_ignore_ms=sample_ignore_ms, resp_sec=resp_sec
        )
        mask_t = tch.as_tensor(mask_np.astype(np.bool_), device=device)

        # compute unit loss and per-neuron MSE (on loss window)
        with tch.no_grad():
            diff = (pred_sub[:, mask_t, :] - psth_sub[:, mask_t, :]) ** 2  # [C,Tm,K]
            unit_loss = float(diff.mean().detach().cpu().item())
            mse_neuron = diff.mean(dim=(0, 1)).detach().cpu().numpy()  # [K]

        per_unit_stats.append(
            {
                "unit_key": unit_key,
                "npz_path": npz_path,
                "K": int(K),
                "loss_mse": float(unit_loss),
                "mse_neuron_mean": float(np.mean(mse_neuron)),
                "mse_neuron_median": float(np.median(mse_neuron)),
            }
        )

        # -----------------------------
        # Update global Top-K best neurons for plotting
        # criterion: smallest mse_neuron (loss window)
        # Only materialize traces when the candidate can enter Top-K
        # -----------------------------
        if plot_k > 0:
            cond0 = str(cond_names[0]) if len(cond_names) > 0 else "cond0"
            cond1 = str(cond_names[1]) if len(cond_names) > 1 else "cond1"

            # current threshold: worst among kept "best" neurons
            # heap stores (-mse, ...), so -heap[0][0] is the largest mse inside Top-K
            thr = (-top_heap[0][0]) if len(top_heap) >= plot_k else float("inf")

            for local_i in range(K):
                mse_i = float(mse_neuron[local_i])
                if (len(top_heap) < plot_k) or (mse_i < thr):
                    # materialize traces (on loss window)
                    gt0 = psth_sub[0, mask_t, local_i].detach().cpu().numpy()
                    pr0 = pred_sub[0, mask_t, local_i].detach().cpu().numpy()
                    gt1 = psth_sub[1, mask_t, local_i].detach().cpu().numpy()
                    pr1 = pred_sub[1, mask_t, local_i].detach().cpu().numpy()

                    rec = {
                        "unit_key": unit_key,
                        "npz_base": os.path.basename(npz_path),
                        "local_i": int(local_i),
                        "mse": float(mse_i),
                        "t_sec": t_sec,
                        "cond0": cond0,
                        "cond1": cond1,
                        "gt0": gt0,
                        "pr0": pr0,
                        "gt1": gt1,
                        "pr1": pr1,
                    }

                    counter += 1
                    heapq.heappush(top_heap, (-mse_i, counter, rec))
                    if len(top_heap) > plot_k:
                        heapq.heappop(top_heap)

                    # update threshold after any change
                    thr = (-top_heap[0][0]) if len(top_heap) >= plot_k else float("inf")

    # -----------------------------
    # Save per-unit stats + summary
    # -----------------------------
    if len(per_unit_stats) == 0:
        raise ValueError("No units evaluated (empty registry?)")

    model_tag = os.path.splitext(os.path.basename(model_path))[0]

    csv_path = os.path.join(out_dir, f"eval_per_unit_{model_tag}.csv")
    with open(csv_path, "w", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=list(per_unit_stats[0].keys()))
        writer.writeheader()
        for r in per_unit_stats:
            writer.writerow(r)
    print(f"[OK] Saved per-unit stats -> {csv_path}")

    losses = np.array([r["loss_mse"] for r in per_unit_stats], dtype=float)
    summary = {
        "animal": animal,
        "model": model_path,
        "registry_dir": registry_dir,
        "n_units": int(len(per_unit_stats)),
        "n_exc_virtual": int(n_exc_virtual),
        "N_total": int(N_total),
        "D_in": int(D_in_ckpt),
        "psth_bin_ms": float(psth_bin_ms),
        "sample_ignore_ms": float(sample_ignore_ms),
        "resp_sec": float(resp_sec),
        "noise_std": float(noise_std),
        "loss_mean": float(np.mean(losses)),
        "loss_median": float(np.median(losses)),
        "loss_min": float(np.min(losses)),
        "loss_max": float(np.max(losses)),
        "plot_strategy": "best_global_topk",
        "plot_n": int(plot_k),
    }
    json_path = os.path.join(out_dir, f"eval_summary_{model_tag}.json")
    with open(json_path, "w") as f:
        json.dump(summary, f, indent=2)
    print(f"[OK] Saved summary -> {json_path}")

    # -----------------------------
    # Build and save ONE mosaic figure using Top-K best neurons
    # -----------------------------
    picked_records = [x[2] for x in top_heap]
    picked_records.sort(key=lambda r: float(r["mse"]))  # best first

    if len(picked_records) == 0:
        print("[WARN] plot_n=0 or no candidates selected; skip mosaic plotting.")
        return

    ncols = max(1, int(plot_cols))
    nrows = int(math.ceil(len(picked_records) / ncols))
    fig, axes = plt.subplots(nrows, ncols, figsize=(3.2 * ncols, 2.6 * nrows), squeeze=False)

    for i, rec in enumerate(picked_records):
        r = i // ncols
        c = i % ncols
        ax = axes[r][c]

        t = rec["t_sec"]

        # Same-condition same-color: draw GT first, reuse its color for Fit
        l0, = ax.plot(t, rec["gt0"], label=f"{rec['cond0']} GT")  # solid
        ax.plot(t, rec["pr0"], linestyle="--", color=l0.get_color(), label=f"{rec['cond0']} Fit")

        l1, = ax.plot(t, rec["gt1"], label=f"{rec['cond1']} GT")
        ax.plot(t, rec["pr1"], linestyle="--", color=l1.get_color(), label=f"{rec['cond1']} Fit")

        ax.axhline(0.0, linewidth=0.5)
        ax.set_title(
            f"{rec['unit_key']} i={rec['local_i']} mse={float(rec['mse']):.2e}",
            fontsize=8,
        )
        if i == 0:
            ax.legend(fontsize=8, loc="best")

    # hide unused axes
    for j in range(len(picked_records), nrows * ncols):
        rr = j // ncols
        cc = j % ncols
        axes[rr][cc].axis("off")

    fig.suptitle(f"{model_tag}  BEST neurons across all sessions (loss window)", fontsize=12)
    fig.tight_layout()

    png_path = os.path.join(out_dir, f"psth_eval_all_best_mosaic_{model_tag}.png")
    fig.savefig(png_path, dpi=200)
    plt.close(fig)
    print(f"[OK] Saved best-mosaic -> {png_path}")


# -----------------------------
# CLI
# -----------------------------

def main() -> None:
    ap = argparse.ArgumentParser()

    ap.add_argument("--model", type=str, required=True, help="Path to trained model .pt")
    ap.add_argument("--params", type=str, default=None, help="Path to params json/yaml used by training (optional)")

    g = ap.add_mutually_exclusive_group(required=True)
    g.add_argument("--npz", type=str, default=None, help="Stage1 psth_*.npz (single-session eval)")
    g.add_argument("--eval_all", action="store_true", help="Evaluate all units in registry (batch)")

    ap.add_argument("--registry_dir", type=str, default=None)
    ap.add_argument("--animal", type=str, default=None)
    ap.add_argument("--n_exc_virtual", type=int, default=0)

    ap.add_argument("--noise_std", type=float, default=0.05)
    ap.add_argument("--psth_bin_ms", type=float, default=200.0)
    ap.add_argument("--sample_ignore_ms", type=float, default=50.0)
    ap.add_argument("--resp_sec", type=float, default=2.0)

    ap.add_argument("--num_neurons", type=int, default=30)
    ap.add_argument("--mode", default="random", choices=["best", "worst", "random"])
    ap.add_argument("--rng_seed", type=int, default=42)

    ap.add_argument("--plot_n", type=int, default=16)
    ap.add_argument("--plot_seed", type=int, default=42)
    ap.add_argument("--plot_cols", type=int, default=4)

    ap.add_argument("--out_dir", type=str, default=None)

    args = ap.parse_args()

    device = _infer_device(args.params)
    print(f"[INFO] device={device}")

    save_dir = args.out_dir or (os.path.dirname(args.model) or ".")
    os.makedirs(save_dir, exist_ok=True)

    if args.eval_all:
        if args.registry_dir is None or args.animal is None:
            raise ValueError("--eval_all requires --registry_dir and --animal")
        eval_all_units_from_registry(
            registry_dir=args.registry_dir,
            animal=args.animal,
            model_path=args.model,
            params_path=args.params,
            n_exc_virtual=int(args.n_exc_virtual),
            noise_std=float(args.noise_std),
            psth_bin_ms=float(args.psth_bin_ms),
            sample_ignore_ms=float(args.sample_ignore_ms),
            resp_sec=float(args.resp_sec),
            plot_n=int(args.plot_n),
            plot_seed=int(args.plot_seed),
            plot_cols=int(args.plot_cols),
            out_dir=save_dir,
            device=device,
        )
    else:
        assert args.npz is not None
        eval_single_session(
            npz_path=args.npz,
            model_path=args.model,
            params_path=args.params,
            noise_std=float(args.noise_std),
            psth_bin_ms=float(args.psth_bin_ms),
            sample_ignore_ms=float(args.sample_ignore_ms),
            resp_sec=float(args.resp_sec),
            num_neurons=int(args.num_neurons),
            mode=str(args.mode),
            rng_seed=int(args.rng_seed),
            out_dir=save_dir,
            device=device,
        )


if __name__ == "__main__":
    main()



================================================
FILE: current_rnn/losses.py
================================================
import torch as tch 
import numpy as np




class LossSparsity:
    def __init__(self, device):
        self.device = device
        self.l1_loss = tch.nn.L1Loss()

    def __call__(self, net):
        J_rec = net.J_rec
        total_loss = self.l1_loss(J_rec, tch.zeros(J_rec.shape).to(self.device))
        return total_loss

class SelectivityLoss:
    def __init__(self, rates, params_dict):
        self.dt = params_dict['dt']
        self.t_min_input = params_dict['t_min_input']
        self.t_max_input = params_dict['t_max_input']
        self.t_start = params_dict['t_start']
        self.t_go = params_dict['t_go']
        self.ind_delay = int((self.t_max_input- self.t_start)/self.dt)
        self.ind_sample = int((self.t_min_input - self.t_start)/self.dt)
        self.ind_go = int((self.t_go - self.t_start)/self.dt)
        self.d_ind = int(0.6/self.dt)
        self.compute_factors(rates)
        self.gram_schmidt(rates)
        self.cos =  tch.nn.CosineSimilarity(dim=0)
        self.mode_sample = 0
        self.mode_delay = 1
        self.mode_choice = 2
        self.alpha_delay = 1.5
        
    def __call__(self, net):
        #sample vectors
        net_sample_alm = net.decoder_alm[self.mode_sample,:]
        #delay vectors
        net_delay_alm = net.decoder_alm[self.mode_delay,:]
        #choice vectors
        net_choice_alm = net.decoder_alm[self.mode_choice,:]

        #losses
        loss_sample = (1 - self.cos(net_sample_alm, self.sample_alm))
        loss_delay = (1 - self.cos(net_delay_alm, self.delay_alm))
        loss_choice = (1 - self.cos(net_choice_alm, self.choice_alm))

        total_loss = (loss_sample + self.alpha_delay * loss_delay + loss_choice )/3.
        return total_loss

    def compute_factors(self, rates):
        self._sample_vectors(rates)
        self._delay_vectors(rates)
        self._choice_vectors(rates)

    def gram_schmidt(self, rates):
        self._sample_vectors(rates)
        self._delay_vectors(rates)
        self._choice_vectors(rates)
        vectors = tch.stack([self.sample_alm, self.delay_alm, self.choice_alm], dim=1) 
        # Perform QR decomposition for orthonormalization
        Q, R = tch.linalg.qr(vectors)

        # Q now contains the orthonormalized vectors
        orthonormal_vectors = Q.T  # Transpose to get them as a list

        # If you need them separately
        orthonormal_sample_alm, orthonormal_delay_alm, orthonormal_choice_alm = orthonormal_vectors
        self.sample_alm = tch.sign(R[0,0]) *  orthonormal_sample_alm # right increases
        self.delay_alm = tch.sign(R[1,1]) * orthonormal_delay_alm
        self.choice_alm = tch.sign(R[2,2]) * orthonormal_choice_alm
    
    def _sample_vectors(self, rates):
        y_alm = rates
        #calculating latent vectors
        vec_alm = y_alm[1,:, :] - y_alm[0, :, :]
        self.sample_alm = tch.mean(vec_alm[self.ind_delay-self.d_ind:self.ind_delay,:], axis=0)
        #self.sample_alm = tch.mean(vec_alm[self.ind_sample:self.ind_sample+self.d_ind,:], axis=0)

    def _delay_vectors(self, rates):
        y_alm = rates
        #calculating latent vectors
        vec_alm = y_alm[1,:, :] - y_alm[0, :, :]
        self.delay_alm = tch.mean(vec_alm[self.ind_go-self.d_ind:self.ind_go, :], axis=0)
    
    def _choice_vectors(self,rates):
        y_alm = rates
        #calculating latent vectors
        d_ind = int(0.4/self.dt)
        vec_alm = y_alm[1, :, :] - y_alm[0, :, :]
        self.choice_alm = tch.mean(vec_alm[self.ind_go:self.ind_go + d_ind, :], axis=0)
    


class SelectivitySingleTrialLoss:
    def __init__(self, rates, params_dict, indexes_neurons):
        self.dt = params_dict['dt']
        self.t_min_input = params_dict['t_min_input']
        self.t_max_input = params_dict['t_max_input']
        self.t_start = params_dict['t_start']
        self.t_go = params_dict['t_go']
        self.ind_delay = int((self.t_max_input- self.t_start)/self.dt)
        self.ind_sample = int((self.t_min_input - self.t_start)/self.dt)
        self.ind_go = int((self.t_go - self.t_start)/self.dt)
        self.d_ind = int(0.6/self.dt)
        self.compute_factors(rates)
        self.gram_schmidt(rates)
        self.mode_sample = 0
        self.mode_delay = 1
        self.mode_choice = 2
        self.indexes = indexes_neurons

    def __call__(self, net, rates_data, latents_trials):

        proj_sample_data, proj_delay_data, proj_choice_data = self.project_data(rates_data)
  

        #print(tch.mean(proj_delay_data), tch.mean(proj_delay_model))
        loss_sample = tch.mean(tch.square(proj_sample_data - latents_trials[:,:,self.mode_sample]))
        loss_delay = tch.mean(tch.square(proj_delay_data - latents_trials[:,:,self.mode_delay]))
        loss_choice = tch.mean(tch.square(proj_choice_data - latents_trials[:,:,self.mode_choice]))
        total_loss = (loss_sample + loss_delay + loss_choice )/3.
        return total_loss

    def compute_factors(self, rates):
        self._sample_vectors(rates)
        self._delay_vectors(rates)
        self._choice_vectors(rates)
    
    def project_data(self, rates_data):
        #losses
        proj_sample_data = rates_data @ self.sample_alm[self.indexes] 
        proj_delay_data = rates_data @ self.delay_alm[self.indexes]
        proj_choice_data = rates_data @ self.choice_alm[self.indexes] 
        return proj_sample_data, proj_delay_data, proj_choice_data

    def gram_schmidt(self, rates):
        self._sample_vectors(rates)
        self._delay_vectors(rates)
        self._choice_vectors(rates)
        vectors = tch.stack([self.sample_alm, self.delay_alm, self.choice_alm], dim=1) 
        # Perform QR decomposition for orthonormalization
        Q, R = tch.linalg.qr(vectors)

        # Q now contains the orthonormalized vectors
        orthonormal_vectors = Q.T  # Transpose to get them as a list

        # If you need them separately
        orthonormal_sample_alm, orthonormal_delay_alm, orthonormal_choice_alm = orthonormal_vectors
        self.sample_alm = tch.sign(R[0,0]) *  orthonormal_sample_alm # right increases
        self.delay_alm = tch.sign(R[1,1]) * orthonormal_delay_alm
        self.choice_alm = tch.sign(R[2,2]) * orthonormal_choice_alm

    def _sample_vectors(self, rates):
        y_alm = rates
        #calculating latent vectors
        vec_alm = y_alm[1,:, :] - y_alm[0, :, :]
        self.sample_alm = tch.mean(vec_alm[self.ind_delay-self.d_ind:self.ind_delay,:], axis=0)

    def _delay_vectors(self, rates):
        y_alm = rates
        #calculating latent vectors
        vec_alm = y_alm[1,:, :] - y_alm[0, :, :]
        self.delay_alm = tch.mean(vec_alm[self.ind_go-self.d_ind:self.ind_go, :], axis=0)
    
    def _choice_vectors(self,rates):
        y_alm = rates
        #calculating latent vectors
        d_ind = int(0.4/self.dt)
        vec_alm = y_alm[1, :, :] - y_alm[0, :, :]
        self.choice_alm = tch.mean(vec_alm[self.ind_go:self.ind_go + d_ind, :], axis=0)
    

class LossAverageTrials:
    def __init__(self):
        self.alpha = 0.1
        
    def __call__(self, av_trials_data, rates_alm):
        #calculating losses
        total_loss = tch.mean(tch.square(av_trials_data- rates_alm))
        return total_loss

class LossAverageTime:
    def __init__(self, params_dict):
        self.t_min_input = params_dict['t_min_input']
        self.t_max_input = params_dict['t_max_input']
        self.t_start = params_dict['t_start']
        self.t_go = params_dict['t_go']
        self.dt = params_dict['dt']

        self.t_after_go = 0.4
        t_sample_s = self.t_min_input - self.t_start 
        t_sample_e = self.t_max_input - self.t_start
        t_delay_e = self.t_go - self.t_start
        t_response = self.t_after_go - self.t_start

        self.ind_sample_s =  int(t_sample_s/self.dt)
        self.ind_sample_e = int(t_sample_e/self.dt)
        self.ind_delay_e1 = int(t_delay_e/(2 * self.dt))
        self.ind_delay_e2 = int(t_delay_e/self.dt)
        self.ind_response = int(t_response/self.dt)

    def __call__(self, rates_data, rates_model):
        # mean spikes across neurons
        av_time_model = self.compute_time_averages_4background(rates_model)
        av_time_data = self.compute_time_averages_4background(rates_data)
        #calculating losses
        total_loss = tch.mean(tch.square(av_time_data - av_time_model))
        return total_loss

    def compute_time_averages_4(self, rates):
        average_sample = tch.mean(rates[:, self.ind_sample_s:self.ind_sample_e, :], axis = 1)  
        average_delay1 = tch.mean(rates[:, self.ind_sample_e:self.ind_delay_e1, :], axis = 1) 
        average_delay2 = tch.mean(rates[:, self.ind_delay_e1:self.ind_delay_e2,:], axis = 1) 
        average_response = tch.mean(rates[:, self.ind_delay_e2:self.ind_response, :], axis = 1) 
        av_time_model = tch.stack((average_sample, average_delay1, average_delay2, average_response)) #condition, trials, neurons
        return av_time_model
    def compute_time_averages_3(self, rates):
        average_sample = tch.mean(rates[:, self.ind_sample_s:self.ind_sample_e, :], axis = 1)  
        average_delay = tch.mean(rates[:, self.ind_sample_e:self.ind_delay_e2, :], axis = 1) 
        average_response = tch.mean(rates[:, self.ind_delay_e2:self.ind_response, :], axis = 1) 
        av_time_model = tch.stack((average_sample, average_delay, average_response)) #condition, trials, neurons
        return av_time_model
    def compute_time_averages_4background(self, rates):
        average_background = tch.mean(rates[:, 0:self.ind_sample_s, :], axis = 1)  
        average_sample = tch.mean(rates[:, self.ind_sample_s:self.ind_sample_e, :], axis = 1)  
        average_delay = tch.mean(rates[:, self.ind_sample_e:self.ind_delay_e2, :], axis = 1) 
        average_response = tch.mean(rates[:, self.ind_delay_e2:self.ind_response, :], axis = 1) 
        av_time_model = tch.stack(( average_background, average_sample, average_delay, average_response)) #condition, trials, neurons
        return av_time_model

class LossAllSpikes:
    def __init__(self, indexes_neurons):
        self.indexes_neurons = indexes_neurons

    def __call__(self, spikes, rates):
        # mean spikes across neurons
        total_loss = tch.mean(tch.square(spikes- rates))
        return total_loss
    


class LossAverageNeurons:
    def __init__(self, indexes_neurons):
        self.indexes_neurons = indexes_neurons

    def __call__(self, av_neurons_data, rates):
        # mean spikes across neurons
        av_neurons_model = self.compute_average_neurons(rates)
        total_loss = tch.mean(tch.square(av_neurons_data - av_neurons_model))
        return total_loss
    
    def compute_average_neurons(self, rates):
        av_neurons_model = tch.mean(rates[:,:, self.indexes_neurons], axis = 2)#spikes per s
        return av_neurons_model

class LossOrthogonality:
    def __init__(self, device):
        self.device = device
        
    def __call__(self, cov_matrix):
        cov_alm = cov_matrix['cov_alm']
        eye_alm = tch.eye(cov_alm.shape[0]).to(self.device).float()
        total_loss = tch.mean(tch.square(cov_alm - eye_alm))
        return total_loss







================================================
FILE: current_rnn/main_train_alm_current.py
================================================
# current_rnn/main_train_alm_current.py
'''
nohup python -u /home/jingyi.xu/code_rnn/current_rnn/main_train_alm_current.py --registry_dir /home/jingyi.xu/ALM/results/registry/kd95 --animal kd95 --out_dir /home/jingyi.xu/code_rnn/results_current1222 --max_epochs 20000 --lr 1e-4 --psth_bin_ms 200 --noise_std 0.00 --n_exc_virtual 400 --unit_sampling random --dale > train.log 2>&1 &


'''
import os
import argparse

from training_current import train_current_alm, train_current_alm_global

def parse_args():
    ap = argparse.ArgumentParser()

    # mode switch: either single session npz or registry global
    ap.add_argument("--npz", default=None, help="Stage1 npz path for single-session training.")
    ap.add_argument("--registry_dir", default=None, help="Directory containing <animal>.registry.csv")
    ap.add_argument("--animal", default=None, help="Animal name, e.g., kd95 (required for registry mode).")

    # output
    ap.add_argument("--out_dir", default=None, help="Output directory for models/figures.")

    # model/training hyperparams
    ap.add_argument("--device", default="cuda", choices=["cuda", "cpu"])
    ap.add_argument("--max_epochs", type=int, default=2000)
    ap.add_argument("--lr", type=float, default=1e-3)
    ap.add_argument("--weight_decay", type=float, default=0.0)
    ap.add_argument("--seed", type=int, default=0)

    # input / preprocessing
    ap.add_argument("--max_time", type=int, default=None)
    ap.add_argument("--psth_bin_ms", type=float, default=0.0)
    ap.add_argument("--sample_ignore_ms", type=float, default=0.0)

    # Dale + stability
    ap.add_argument("--dale", action="store_true", help="Enable Dale constraint.")
    ap.add_argument("--no_dale", action="store_true", help="Disable Dale constraint.")
    ap.add_argument("--substeps", type=int, default=4)
    ap.add_argument("--noise_std", type=float, default=0.0)

    # registry-global specific
    ap.add_argument("--n_exc_virtual", type=int, default=0, help="Number of pseudo excitatory units.")
    ap.add_argument("--exc_ratio", type=float, default=4.0, help="If n_exc_virtual==0, set n_exc_virtual=exc_ratio*n_obs.")
    ap.add_argument("--max_sessions", type=int, default=0, help="Use only top-K units after registry sorting (0=all).")
    ap.add_argument("--unit_sampling", default="random", choices=["random", "cycle"])

    # optional cond filter
    ap.add_argument("--cond_filter", default=None,
                    help="Comma-separated condition names to load (must exist in stage1 npz).")

    args = ap.parse_args()
    return args

def main():
    args = parse_args()

    dale = True
    if args.no_dale:
        dale = False
    if args.dale:
        dale = True

    if args.out_dir is None:
        # match your existing folder naming convention
        args.out_dir = os.path.join(os.getcwd(), "results_current")

    os.makedirs(args.out_dir, exist_ok=True)

    cond_filter = None
    if args.cond_filter is not None and str(args.cond_filter).strip() != "":
        cond_filter = [x.strip() for x in str(args.cond_filter).split(",") if x.strip()]

    # global registry training
    if args.registry_dir is not None:
        if args.animal is None:
            raise ValueError("--animal is required when --registry_dir is set.")
        train_current_alm_global(
            animal=args.animal,
            registry_dir=args.registry_dir,
            out_dir=args.out_dir,
            n_exc_virtual=int(args.n_exc_virtual),
            max_sessions=int(args.max_sessions),
            max_epochs=int(args.max_epochs),
            lr=float(args.lr),
            weight_decay=float(args.weight_decay),
            seed=int(args.seed),
            cond_filter=cond_filter,
            max_time=args.max_time,
            psth_bin_ms=float(args.psth_bin_ms),
            sample_ignore_ms=float(args.sample_ignore_ms),
            dale=bool(dale),
            substeps=int(args.substeps),
            noise_std=float(args.noise_std),
            unit_sampling=args.unit_sampling,
        )
        return

    # single-session training (backward compatible)
    if args.npz is None:
        raise ValueError("Either --npz (single session) or --registry_dir (global) must be provided.")

    train_current_alm(
        npz_path=args.npz,
        out_dir=args.out_dir,
        device=args.device,
        max_epochs=int(args.max_epochs),
        lr=float(args.lr),
        weight_decay=float(args.weight_decay),
        seed=int(args.seed),
        cond_filter=cond_filter,
        max_time=args.max_time,
        psth_bin_ms=float(args.psth_bin_ms),
        sample_ignore_ms=float(args.sample_ignore_ms),
        dale=bool(dale),
        substeps=int(args.substeps),
        noise_std=float(args.noise_std),
    )

if __name__ == "__main__":
    main()



================================================
FILE: current_rnn/model_current.py
================================================
# current_rnn/model_current.py

import math
from typing import Optional, Dict

import torch
import torch.nn as nn
import torch.nn.functional as F


class ALMCurrentRNN(nn.Module):
    """
    High-dimensional current-based RNN for ALM data.

    - State h_t ∈ R^N corresponds 1:1 to recorded neurons (after cell-type filtering).
    - Discrete-time dynamics (Euler):

        h_{t+1} = h_t + (dt / tau) * [ -h_t + J * phi(h_t) + W_in * u_t + b ]

      where:
        - J: NxN recurrent coupling
        - W_in: NxD_in input weight
        - u_t: external input at time t, shape [B, D_in]
        - phi: element-wise nonlinearity

    - Forward input u: shape [B, T, D_in]
    - Forward output: dict with
        - "h":    shape [B, T, N] (current / latent state)
        - "rate": shape [B, T, N] (phi(h))
    """

    def __init__(
        self,
        N: int,
        D_in: int,
        dt: float = 1.0,
        tau: float = 1.0,
        substeps: int = 1,
        nonlinearity: str = "tanh",
        device: Optional[torch.device] = None,
        dale_mask: Optional[torch.Tensor] = None,
    ) -> None:
        """
        Args:
            N:        number of neurons (after cell-type filtering)
            D_in:     dimension of external input u_t
            dt:       integration time step (in arbitrary units, typically 1 frame)
            tau:      effective time constant of the dynamics
            nonlinearity: 'tanh', 'relu', or 'softplus'
            device:   torch device; if None, inferred from parameters at runtime
            dale_mask: optional tensor of shape [N, N] with entries in {-1, 0, +1}
                       to encode Dale's law constraints (not enforced yet, but kept
                       for future use). For now we only store it.
        """
        super().__init__()

        self.N = N
        self.D_in = D_in
        self.dt = float(dt)
        self.tau = float(tau)
        self.substeps = int(substeps)
        assert self.substeps >= 1
        self.nonlinearity = nonlinearity.lower()

        # ---------------------------------------------------------------------
        # Recurrent matrix J ∈ R^{N×N}
        # ---------------------------------------------------------------------
        # Xavier-like initialization, scaled by 1/sqrt(N) to avoid instabilities.
        J = torch.empty(N, N)
        nn.init.kaiming_uniform_(J, a=math.sqrt(5))
        J = J / math.sqrt(N)
        self.J = nn.Parameter(J)

        # ---------------------------------------------------------------------
        # Input weights W_in ∈ R^{N×D_in}
        # ---------------------------------------------------------------------
        W_in = torch.empty(N, D_in)
        nn.init.kaiming_uniform_(W_in, a=math.sqrt(5))
        W_in = W_in / math.sqrt(D_in)
        self.W_in = nn.Parameter(W_in)

        # ---------------------------------------------------------------------
        # Bias term b ∈ R^N
        # ---------------------------------------------------------------------
        self.b = nn.Parameter(torch.zeros(N))

        # Optional Dale's law mask: stored but not enforced yet.
        # Expected shape: [N, N], entries in {-1, 0, +1}
        if dale_mask is not None:
            if dale_mask.shape != (N, N):
                raise ValueError(
                    f"dale_mask must have shape ({N}, {N}), "
                    f"got {tuple(dale_mask.shape)}"
                )
            self.register_buffer("dale_mask", dale_mask.clone())
        else:
            self.dale_mask = None

        # For consistent dtype/device handling later
        if device is not None:
            self.to(device)

    # -------------------------------------------------------------------------
    # Nonlinearity
    # -------------------------------------------------------------------------
    def _phi(self, x: torch.Tensor) -> torch.Tensor:
        if self.nonlinearity == "tanh":
            return torch.tanh(x)
        elif self.nonlinearity == "relu":
            return F.relu(x)
        elif self.nonlinearity == "softplus":
            return F.softplus(x)
        else:
            raise ValueError(f"Unsupported nonlinearity: {self.nonlinearity}")

    # -------------------------------------------------------------------------
    # Optional: apply Dale's law mask to J (for future use)
    # -------------------------------------------------------------------------
    @torch.no_grad()
    def apply_dale_mask(self) -> None:
        """
        Enforce Dale's law sign structure on J if a mask is provided.

        dale_mask[i, j] = +1  -> J[i, j] constrained to be ≥ 0
        dale_mask[i, j] = -1  -> J[i, j] constrained to be ≤ 0
        dale_mask[i, j] =  0  -> unconstrained

        For now, we simply project J onto the sign cone defined by dale_mask.
        This can be called manually after optimizer.step() in a training loop.
        """
        if self.dale_mask is None:
            return

        # Positive-constrained entries
        pos_mask = self.dale_mask > 0
        # Negative-constrained entries
        neg_mask = self.dale_mask < 0

        with torch.no_grad():
            self.J.data[pos_mask] = torch.clamp_min(self.J.data[pos_mask], 0.0)
            self.J.data[neg_mask] = torch.clamp_max(self.J.data[neg_mask], 0.0)

    # -------------------------------------------------------------------------
    # Forward dynamics
    # -------------------------------------------------------------------------
    def forward(
    self,
    u: torch.Tensor,
    h0: Optional[torch.Tensor] = None,
    noise_std: float = 0.0,
    return_rate: bool = True,
) -> Dict[str, torch.Tensor]:
        """
        Run the RNN forward for a batch of input trajectories.

     Args:
        u:  external input trajectories, shape [B, T, D_in]
        h0: optional initial state, shape [B, N]. If None, initialized to zeros.
        noise_std: standard deviation of additive Gaussian noise on h.
        return_rate: if True, also return phi(h) as 'rate'.

        Returns:
        A dict with:
            'h':    tensor [B, T, N], the current-based state
            'rate': tensor [B, T, N], phi(h)       (if return_rate=True)
        """
        if u.dim() != 3:
            raise ValueError(f"u must have shape [B, T, D_in], got {tuple(u.shape)}")

        B, T, D_in = u.shape
        if D_in != self.D_in:
            raise ValueError(f"Expected input dimension D_in={self.D_in}, got {D_in}")

        device = self.J.device
        u = u.to(device)

        # Initialize h_0
        if h0 is None:
            h_t = torch.zeros(B, self.N, device=device, dtype=self.J.dtype)
        else:
            if h0.shape != (B, self.N):
                raise ValueError(
                    f"h0 must have shape [B, N]=[{B}, {self.N}], got {tuple(h0.shape)}"
                )
            h_t = h0.to(device)
        # -------- sub-stepping setup --------
        substeps = int(getattr(self, "substeps", 1))
        if substeps < 1:
            raise ValueError(f"substeps must be >= 1, got {substeps}")

        dt_sub = self.dt / substeps
        dt_over_tau_sub = dt_sub / self.tau  # = (self.dt/self.tau)/substeps

        # If you want the total noise variance per *frame* to stay comparable
        # when using multiple substeps, scale per-substep noise by 1/sqrt(substeps).
        sqrt_dt_sub = math.sqrt(dt_sub)
        noise_scale = 1.0 / math.sqrt(substeps) if substeps > 1 else 1.0

        h_seq = []
        for t in range(T):
            # u_t: [B, D_in] (kept constant within substeps)
            u_t = u[:, t, :]

            # Integrate substeps times within this frame
            for _ in range(substeps):
                # rate_t = phi(h_t)  -> [B, N]
                rate_t = self._phi(h_t)

                # recurrent input: [B, N]
                rec_t = torch.matmul(rate_t, self.J.T)

                # external input: [B, N]
                inp_t = torch.matmul(u_t, self.W_in.T)

                # drift: dh/dt = -h + rec + inp + b
                drift = -h_t + rec_t + inp_t + self.b

                # Euler substep
                h_t = h_t + dt_over_tau_sub * drift

                # Noise (optional)
                if noise_std > 0.0:
                    # per-substep noise; noise_std interpreted as per-frame scale
                    noise = (noise_std * noise_scale) * sqrt_dt_sub * torch.randn_like(h_t)
                    h_t = h_t + noise
            # record state at frame boundary
            h_seq.append(h_t)

        # Stack over time: list of [B, N] -> [B, T, N]
        h_seq = torch.stack(h_seq, dim=1)  # [B, T, N]

        out = {"h": h_seq}
        if return_rate:
            out["rate"] = self._phi(h_seq)

        return out
    



================================================
FILE: current_rnn/plotting.py
================================================
import matplotlib.pyplot as plt
import torch as tch
import numpy as np

def plot_loss(epoch, losses, title, tag = ''):
    plt.figure()
    plt.semilogy(range(epoch), losses[:epoch])
    plt.title(title)
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.savefig(tag + '.png',  bbox_inches = 'tight')
    plt.close()


def plot_neurons(net, rates, default_parameters, t_del = -.03, tag = ''):    
    with tch.set_grad_enabled(False):
        y_alm_l = rates['ALM_l']
        y_alm_r = rates['ALM_r']
        input_net = {'ALM_l':y_alm_l}
        results, _ = net(input_net)
        rates_alm_l = results['rates_alm_l']
        rates_alm_r = results['rates_alm_r']
        rates_octx_l = results['rates_octx_l']
        rates_octx_r = results['rates_octx_r']
        rates_alm_l = rates_alm_l.detach().cpu().numpy()
        rates_alm_r = rates_alm_r.detach().cpu().numpy()
        rates_octx_l = rates_octx_l.detach().cpu().numpy()
        rates_octx_r = rates_octx_r.detach().cpu().numpy()
        y_alm_l = y_alm_l.detach().cpu().numpy()
        y_alm_r = y_alm_r.detach().cpu().numpy()
        t_start = default_parameters['t_start']
        dt = default_parameters['dt']
        n_time = y_alm_l.shape[1]
        x = np.linspace(0, n_time, n_time) * dt
        x = x + t_start
        n_neurons = 1000
        for j in range(0, n_neurons,10):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, rates_alm_l[0, :, j], 'r--',  lw =3) 
            plt.plot(x, y_alm_l[0, :, j], 'r-', lw =3) 
            plt.plot(x, rates_alm_l[1, :, j], 'b--',  lw =3) 
            plt.plot(x, y_alm_l[1, :, j], 'b-', lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title("ALM L")
            plt.savefig('out/neuronal_dynamics/neural_ALM_L_'+ tag + '{}.png'.format(j),  bbox_inches = 'tight')
            plt.close()
        for j in range(0, n_neurons,10):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, rates_alm_r[0, :, j], 'r--',  lw =3) 
            plt.plot(x, y_alm_r[0, :, j], 'r-', lw =3) 
            plt.plot(x, rates_alm_r[1, :, j], 'b--',  lw =3) 
            plt.plot(x, y_alm_r[1, :, j], 'b-', lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title('ALM R')
            plt.savefig('out/neuronal_dynamics/neural_ALM_R_'+ tag + '{}.png'.format(j),  bbox_inches = 'tight')
            plt.close()
        for j in range(0, 200,20):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, rates_octx_l[0, :, j], 'r-',  lw =3) 
            plt.plot(x, rates_octx_l[1, :, j], 'b-',  lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title("ALM L")
            plt.savefig('out/neuronal_dynamics/neural_octx_L_'+ tag + '{}.png'.format(j),  bbox_inches = 'tight')
            plt.close()
        for j in range(0, 200,20):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, rates_octx_r[0, :, j], 'r-',  lw =3) 
            plt.plot(x, rates_octx_r[1, :, j], 'b-',  lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title('ALM R')
            plt.savefig('out/neuronal_dynamics/neural_octx_R_'+ tag + '{}.png'.format(j),  bbox_inches = 'tight')
            plt.close()


def plot_latents(net,  rates, default_parameters, t_del = -.03, tag = ''):   
    with tch.set_grad_enabled(False):
        y_alm_l = rates['ALM_l']
        input_net = {'ALM_l':y_alm_l}
        results, _ = net(input_net)
        latents_alm_l = results['latents_alm_l']
        latents_alm_r = results['latents_alm_r']
        latents_alm_l = latents_alm_l.detach().cpu().numpy()
        latents_alm_r = latents_alm_r.detach().cpu().numpy()
     
   
        t_start = default_parameters['t_start']
        dt = default_parameters['dt']
        n_time = y_alm_l.shape[1]
        x = np.linspace(0, n_time, n_time) * dt
        x = x + t_start
        for j in range(latents_alm_l.shape[2]):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, latents_alm_l[0, :, j], 'r-',  lw =3) 
            plt.plot(x, latents_alm_l[1, :, j], 'b-',  lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title("ALM L")
            plt.savefig('out/latents/latents_ALM_L_'+tag + '{}.png'.format(j), bbox_inches = 'tight')
            plt.close()
        for j in range(latents_alm_r.shape[2]):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, latents_alm_r[0, :, j], 'r-',  lw =3) 
            plt.plot(x, latents_alm_r[1, :, j], 'b-',  lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title("ALM R")
            plt.savefig('out/latents/latents_ALM_R_'+tag + '{}.png'.format(j), bbox_inches = 'tight')
            plt.close()





================================================
FILE: current_rnn/training_current.py
================================================
# current_rnn/training_current.py

import os
import sys
import json
import time
from typing import Optional, List, Dict, Any

import numpy as np
import torch as tch
import torch.nn.functional as F

# ---------------------------------------------------------------------
# Make project root importable so we can reuse losses.py and plotting.py
# ---------------------------------------------------------------------
THIS_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(THIS_DIR)
if ROOT_DIR not in sys.path:
    sys.path.append(ROOT_DIR)

from losses import LossAverageTrials          # reuse existing loss
import plotting                               # reuse existing plotting helpers

from model_current import ALMCurrentRNN       # current_rnn/model_current.py
from data_alm_current import load_alm_psth_npz,build_dale_mask_from_types  # current_rnn/data_alm_current.py
from utils_celltype import load_is_excitatory_from_npz  # current_rnn/utils_celltype.py

def _load_default_parameters(params_path: Optional[str] = None) -> Dict[str, Any]:
    """
    Load global parameter dictionary from parameters_list.json.
    If params_path is None, uses <ROOT_DIR>/parameters_list.json.
    """
    if params_path is None:
        params_path = os.path.join(ROOT_DIR, "parameters_list.json")
    if not os.path.isfile(params_path):
        raise FileNotFoundError(f"parameters_list.json not found: {params_path}")
    with open(params_path, "r") as f:
        params = json.load(f)
    return params



def _maybe_attach_lick_reward_to_meta(
    meta: Dict[str, Any],
    npz_path: str,
    T: int,
) -> Dict[str, Any]:
    """Attach lick/reward traces (if present) from the stage1 npz into meta.

    This keeps training/eval code simple even if load_alm_psth_npz does not yet
    return these fields.

    Expected shapes in the stage1 npz:
      reward_trace:      [C_all, T_all]
      lick_rate_left:    [C_all, T_all]
      lick_rate_right:   [C_all, T_all]
      lick_rate_total:   [C_all, T_all]
      t_rel_go_sec:      [T_all]
      idx_2p_in_bpod:    [n_trials_2p]  (informational)

    We slice to the *currently loaded* conditions in meta['cond_names'] and the
    currently loaded time length T.
    """
    if meta is None:
        return meta

    try:
        z = np.load(npz_path, allow_pickle=True)
    except Exception:
        return meta

    if "cond_names" not in z or "reward_trace" not in z:
        return meta

    cond_all = [str(x) for x in z["cond_names"].tolist()]
    cond_cur = [str(x) for x in meta.get("cond_names", [])]

    name2i = {n: i for i, n in enumerate(cond_all)}
    try:
        idx = [name2i[n] for n in cond_cur]
    except KeyError:
        # If names do not match, fall back to prefix matching (rare but useful)
        idx = []
        for n in cond_cur:
            hit = None
            for i, na in enumerate(cond_all):
                if na == n or na.startswith(n) or n.startswith(na):
                    hit = i
                    break
            if hit is None:
                raise KeyError(
                    f"Cannot map cond '{n}' to stage1 npz cond_names.\n"
                    f"meta.cond_names={cond_cur}\n"
                    f"npz.cond_names={cond_all}"
                )
            idx.append(hit)

    def _slice_CT(arr: np.ndarray) -> np.ndarray:
        if arr.ndim != 2:
            raise ValueError(f"Expected [C,T] array, got shape {arr.shape}")
        arr = arr[idx, :]
        if arr.shape[1] >= T:
            arr = arr[:, :T]
        else:
            # If T is longer (shouldn't happen), pad with zeros
            pad = T - arr.shape[1]
            arr = np.pad(arr, ((0, 0), (0, pad)), mode="constant", constant_values=0.0)
        return arr.astype(np.float32, copy=False)

    for k in ["reward_trace", "lick_rate_left", "lick_rate_right", "lick_rate_total"]:
        if k in z:
            meta[k] = _slice_CT(np.asarray(z[k]))

    if "t_rel_go_sec" in z:
        t = np.asarray(z["t_rel_go_sec"]).astype(np.float32, copy=False)
        meta["t_rel_go_sec"] = t[:T] if t.shape[0] >= T else np.pad(t, (0, T - t.shape[0]))

    if "idx_2p_in_bpod" in z:
        meta["idx_2p_in_bpod"] = np.asarray(z["idx_2p_in_bpod"])

    return meta



def _build_sample_waveforms(
    T: int,
    fps: float,
    S_frame: int,
    sample_len_sec: float = 1.15,
    on_sec: float = 0.15,
    off_sec: float = 0.10,
    n_bursts: int = 5,
) -> np.ndarray:
    """Return tone_wave[T], noise_wave[T] as float32."""
    tone = np.zeros(T, dtype=np.float32)
    noise = np.zeros(T, dtype=np.float32)

    sample_frames = int(round(sample_len_sec * fps))
    start = int(S_frame)
    end = min(T, start + sample_frames)

    # noise: constant during sample
    noise[start:end] = 1.0

    # tone bursts: ON/OFF pattern
    on_f = int(round(on_sec * fps))
    off_f = int(round(off_sec * fps))

    t = start
    for k in range(n_bursts):
        if t >= end:
            break
        t_on_end = min(end, t + on_f)
        tone[t:t_on_end] = 1.0
        t = t_on_end
        if k < n_bursts - 1:
            t = min(end, t + off_f)

    return tone, noise


def _build_input_tensor(
    C: int,
    T: int,
    cond_names: List[str],
    device: tch.device,
    amp_input: float = 1.0,
    meta: Optional[Dict[str, Any]] = None,
    amp_stim: Optional[float] = None,
    sample_len_sec: float = 1.15,
    on_sec: float = 0.15,
    off_sec: float = 0.10,
    n_bursts: int = 5,
    include_go_cue: bool = True,
    go_cue_sec: float = 0.10,
    amp_go_cue: Optional[float] = None,
    include_reward: bool = True,
    amp_reward: Optional[float] = None,
) -> tch.Tensor:
    """Build external input u for each condition.

    Output u has shape [C, T, D_in] where:

      u(t) = [cond_onehot] + [stim_left, stim_right] + [go_cue] + [reward]

    Notes on trainability:
      - The temporal traces (go_cue, reward_trace) are fixed functions of time
        (trial averages, aligned to the go cue).
      - The *mapping* from these traces into neuron currents is learned via W_in,
        i.e., each input channel corresponds to a trainable N-vector (one weight
        per neuron).
    """
    if amp_stim is None:
        amp_stim = amp_input
    if amp_go_cue is None:
        amp_go_cue = amp_input
    if amp_reward is None:
        amp_reward = 1.0

    # -----------------------------
    # (1) condition one-hot: [C,T,C]
    # -----------------------------
    u = tch.zeros((C, T, C), device=device, dtype=tch.float32)
    for i in range(C):
        u[i, :, i] = float(amp_input)

    # -----------------------------
    # (2) sample stimulus waveforms: [C,T,2]
    # -----------------------------
    stim = tch.zeros((C, T, 2), device=device, dtype=tch.float32)

    if meta is None:
        raise ValueError("meta is required to build stimulus/go/reward inputs (need event_frames, fps, etc.)")

    fps = float(meta.get("fps", 1.0))
    S_frame = int(meta.get("event_frames", {}).get("S", 0))

    tone, noise = _build_sample_waveforms(
    T=T,
    fps=fps,
    S_frame=S_frame,
    sample_len_sec=sample_len_sec,
    on_sec=on_sec,
    off_sec=off_sec,
    n_bursts=n_bursts,
    )

    # scale in numpy (or torch都行)，然后转 torch 到同一 device
    tone = (tone * float(amp_stim)).astype(np.float32, copy=False)
    noise = (noise * float(amp_stim)).astype(np.float32, copy=False)

    tone_t = tch.from_numpy(tone).to(device=device, dtype=tch.float32).view(T, 1)   # [T,1]
    noise_t = tch.from_numpy(noise).to(device=device, dtype=tch.float32).view(T, 1) # [T,1]
    # assign per condition
    for i, name in enumerate(cond_names):
        s = str(name).lower()

        is_lc = ("left_correct" in s) or (s.startswith("lc")) or ("_lc" in s)
        is_rc = ("right_correct" in s) or (s.startswith("rc")) or ("_rc" in s)
        if is_lc and not is_rc:
            stim[i, :, 0:1] = tone_t
            stim[i, :, 1:2] = noise_t
        elif is_rc and not is_lc:
            stim[i, :, 0:1] = noise_t
            stim[i, :, 1:2] = tone_t
        else:
            pass

    u = tch.cat([u, stim], dim=-1)  # [C,T,C+2]

    # -----------------------------
    # (3) go cue: [C,T,1] (0.1s pulse starting at R frame)
    # -----------------------------
    if include_go_cue:
        R = _get_event_frame(meta, ["R", "go", "go_cue", "go_cue_onset", "G"])
        if R is None:
            raise KeyError("Go cue frame not found in meta['event_frames'] (expected key 'R').")
        go_frames = int(round(float(go_cue_sec) * fps))
        go_frames = max(1, go_frames)
        go = tch.zeros((T, 1), device=device, dtype=tch.float32)
        a0 = max(0, int(R))
        a1 = min(T, int(R) + go_frames)
        if a1 > a0:
            go[a0:a1, 0] = float(amp_go_cue)
        go = go.unsqueeze(0).repeat(C, 1, 1)  # [C,T,1]
        u = tch.cat([u, go], dim=-1)  # +1

    # -----------------------------
    # (4) reward: [C,T,1] (per-cond trace, aligned to go cue)
    # -----------------------------
    if include_reward:
        if "reward_trace" not in meta:
            raise KeyError(
                "meta['reward_trace'] missing. Run build_lick_reward_trace.py --inplace "
                "to write reward_trace into the stage1 npz, then re-load, or call "
                "_maybe_attach_lick_reward_to_meta(meta, npz_path, T) before building u."
            )
        rew = np.asarray(meta["reward_trace"], dtype=np.float32)
        if rew.shape[0] != C:
            raise ValueError(f"reward_trace first dim must match C={C}, got {rew.shape}")
        if rew.shape[1] != T:
            # allow mild mismatch
            rew = rew[:, :T] if rew.shape[1] >= T else np.pad(rew, ((0, 0), (0, T - rew.shape[1])), mode="constant")

        reward = tch.from_numpy(rew).to(device=device, dtype=tch.float32).unsqueeze(-1)  # [C,T,1]
        reward = reward * float(amp_reward)
        u = tch.cat([u, reward], dim=-1)  # +1

    return u


def _kernel_size_from_bin_ms(fps: float, bin_ms: float) -> int:
    """Convert bin_ms to an odd kernel size in frames (>=1), so output length stays T."""
    if bin_ms is None or bin_ms <= 0:
        return 1
    k = int(round(float(bin_ms) / 1000.0 * float(fps)))
    k = max(1, k)
    if (k % 2) == 0:
        k += 1
    return k


def _time_bin_smooth_ctn(x: tch.Tensor, fps: float, bin_ms: float) -> tch.Tensor:
    """Boxcar smooth along time for x shaped [C, T, N] (or [C, T, D]). Length-preserving."""
    k = _kernel_size_from_bin_ms(fps=fps, bin_ms=bin_ms)
    if k <= 1:
        return x

    if x.ndim != 3:
        raise ValueError(f"Expected 3D tensor [C,T,*], got {tuple(x.shape)}")

    C, T, D = x.shape
    y = x.permute(0, 2, 1).contiguous().view(C * D, 1, T)   # [C*D,1,T]
    pad = k // 2
    y = F.pad(y, (pad, pad), mode="replicate")
    y = F.avg_pool1d(y, kernel_size=k, stride=1)            # [C*D,1,T]
    y = y.view(C, D, T).permute(0, 2, 1).contiguous()       # [C,T,D]
    return y

def _regularization_l2(
    net: ALMCurrentRNN, lam_J: float = 0.0, lam_W: float = 0.0
) -> tch.Tensor:
    """
    Simple L2 regularization on J and W_in.
    """
    reg = tch.zeros((), device=net.J.device)
    if lam_J > 0.0:
        reg = reg + lam_J * net.J.pow(2).mean()
    if lam_W > 0.0:
        reg = reg + lam_W * net.W_in.pow(2).mean()
    return reg

import numpy as np

def _get_event_frame(meta: Dict[str, Any], keys: List[str]) -> Optional[int]:
    """Try multiple keys in meta['event_frames'] and return the first found."""
    ev = meta.get("event_frames", None)
    if not isinstance(ev, dict):
        return None
    for k in keys:
        if k in ev:
            return int(ev[k])
    return None


def _build_time_mask_sample_delay_resp(
    T: int,
    fps: float,
    meta: dict,
    sample_ignore_ms: float = 50.0,
    resp_sec: float = 2.0,
) -> np.ndarray:
    """
    mask = [S+ignore, D) + [D, R) + [R, R+resp_sec]
      S = sample onset
      D = delay onset
      R = go cue
    """
    # 事件帧（按你现有 meta.event_frames 的习惯，优先用 'S','D','G'）
    S = _get_event_frame(meta, ["S", "sample", "sample_on", "sample_onset"])
    D = _get_event_frame(meta, ["D", "delay", "delay_on", "delay_onset"])
    G = _get_event_frame(meta, ["R", "go", "go_cue", "response", "response_onset"])

    if S is None:
        raise KeyError("Cannot find sample onset frame in meta['event_frames'] (expected key like 'S').")
    if G is None:
        raise KeyError("Cannot find go cue frame in meta['event_frames'] (expected key like 'G').")

    ignore_frames = int(round(sample_ignore_ms * fps / 1000.0))
    start = S + ignore_frames

    if D is None:
        D = start

    m = np.zeros(T, dtype=bool)

    # sample: [start, D)
    a0 = max(0, start)
    a1 = min(T, D)
    if a1 > a0:
        m[a0:a1] = True

    # delay: [D, G)
    b0 = max(0, D)
    b1 = min(T, G)
    if b1 > b0:
        m[b0:b1] = True

    # response: [G, G + resp_sec]
    resp_frames = int(round(resp_sec * fps))
    c0 = max(0, G)
    c1 = min(T, G + resp_frames)
    if c1 > c0:
        m[c0:c1] = True

    return m


def _build_time_mask_sample_phase(
    T: int,
    meta: Dict[str, Any],
    device: tch.device,
    ignore_ms: float = 0.0,
    sample_window_ms: Optional[float] = None,
) -> tch.Tensor:
    """
    """
    fps = float(meta["fps"])
    event_frames = meta["event_frames"]  # dict like {'S': ss, 'D': ld, 'R': go}

    if "S" not in event_frames:
        raise KeyError("event_frames does not contain key 'S' (sample onset).")

    S_frame = int(event_frames["S"])

    # Number of frames to ignore after sample onset
    ignore_frames = int(round(ignore_ms / 1000.0 * fps))

    start_frame = S_frame + ignore_frames

    # Decide end_frame
    if sample_window_ms is not None:
        window_frames = int(round(sample_window_ms / 1000.0 * fps))
        end_frame = start_frame + window_frames
    else:
        # If delay onset 'D' is available, use it as the end of sample phase; otherwise use T.
        if "D" in event_frames:
            end_frame = int(event_frames["D"])
        else:
            end_frame = T

    # Clip to valid range
    start_frame = max(0, min(start_frame, T))
    end_frame = max(0, min(end_frame, T))

    if end_frame <= start_frame:
        raise ValueError(
            f"Invalid time window for sample phase: "
            f"start_frame={start_frame}, end_frame={end_frame}, T={T}"
        )

    time_mask = tch.zeros(T, dtype=tch.bool, device=device)
    time_mask[start_frame:end_frame] = True

    return time_mask


def train_current_alm(
    npz_path: str,
    cond_filter=None,
    max_time=None,
    lr: float = 1e-3,
    max_epochs: int = 50000,
    seed: int = 42,
    noise_std: float = 0.0,
    psth_bin_ms: float = 200.0,
    lam_J: float = 0.0,
    lam_W: float = 0.0,
    params_path: Optional[str] = None,
    out_dir: Optional[str] = None,
    tag: str = "",
    # time masking options:
    use_time_mask: bool = True,
    sample_ignore_ms: float = 50.0,
    resp_sec: float = 2.0,
    # input channels:
    include_go_cue: bool = True,
    go_cue_sec: float = 0.10,
    include_reward: bool = True,
    amp_reward: Optional[float] = None,
    amp_go_cue: Optional[float] = None,
) -> None:
    """
    Train a single-session N-dimensional current-based RNN on trial-averaged ALM data.

    Args:
        npz_path:
            Path to the Stage 1 .npz file produced by 0.average.py.
        cond_filter:
            Optional list of condition names to use, e.g. ['left_correct', 'right_correct'].
            If None, load_alm_psth_npz will choose a reasonable default.
        max_time:
            Optional truncation of the time axis to max_time frames.
        lr:
            Learning rate for Adam.
        max_epochs:
            Number of training epochs.
        seed:
            Random seed for reproducibility.
        noise_std:
            Standard deviation of additive Gaussian noise on h in the RNN.
            For the first deterministic model, this can be kept at 0.0.
        lam_J:
            L2 regularization weight on J.
        lam_W:
            L2 regularization weight on W_in.
        params_path:
            Path to parameters_list.json. If None, uses <ROOT_DIR>/parameters_list.json.
        out_dir:
            Directory to save models and loss plots. If None, uses <ROOT_DIR>/results_current.
        tag:
            String tag appended to filenames for this training run.

        use_time_mask:
            If True, restrict the loss computation to a subset of time points
            specified by mask_mode and related parameters.
        mask_mode:
            Currently only "sample" is implemented: select the sample phase.
        sample_ignore_ms:
            When mask_mode == "sample": number of milliseconds after sample onset
            to exclude from the training window (e.g., 50.0 ms).
        sample_window_ms:
            When mask_mode == "sample": duration of the training window (in ms)
            after the ignored period. If None, the window extends until delay onset
            (event_frames['D']) if present, otherwise until the end of the trial.

    Returns:
        A dictionary with:
            - 'net':         trained model (ALMCurrentRNN)
            - 'psth':        ground-truth psth tensor [C, T, N]
            - 'meta':        metadata dict from load_alm_psth_npz
            - 'loss_history': numpy array of training loss values
            - 'time_mask':   torch.BoolTensor of shape [T] (or None if not used)
    """
    # -------------------------------------------------------------------------
    # Setup and configuration
    # -------------------------------------------------------------------------
    if out_dir is None:
        out_dir = os.path.join(ROOT_DIR, "results_current")
    os.makedirs(out_dir, exist_ok=True)

    default_parameters = _load_default_parameters(params_path)

    # Device selection
    device_str = default_parameters.get("device", "cpu")
    device = tch.device(device_str if tch.cuda.is_available() or device_str == "cpu" else "cpu")

    # Set random seeds
    np.random.seed(seed)
    tch.manual_seed(seed)
    if device.type == "cuda":
        tch.cuda.manual_seed_all(seed)

    # -------------------------------------------------------------------------
    # Load trial-averaged PSTH and metadata
    # -------------------------------------------------------------------------
    psth, meta = load_alm_psth_npz(
        npz_path=npz_path,
        cond_filter=cond_filter,
        max_time=max_time,
        device=device,
        dtype=tch.float32,
    )
    # psth: [C, T, N]
    C, T, N = psth.shape
    cond_names = meta["cond_names"]

    # Attach lick/reward traces (if present) so _build_input_tensor can add reward channel
    meta = _maybe_attach_lick_reward_to_meta(meta=meta, npz_path=npz_path, T=T)

    # -------------------------------------------------------------------------
    # Optional: boxcar time-binning (length-preserving smoothing) on PSTH
    # -------------------------------------------------------------------------
    fps = float(meta.get("fps", 1.0))
    if psth_bin_ms is not None and psth_bin_ms > 0:
        psth = _time_bin_smooth_ctn(psth, fps=fps, bin_ms=float(psth_bin_ms))
        print(f"[INFO] Applied PSTH boxcar smoothing: bin_ms={psth_bin_ms} (fps={fps})")
    else:
        print("[INFO] PSTH boxcar smoothing disabled (psth_bin_ms<=0).")

    # -------------------------------------------------------------------------
    # Build time mask (optional)
    # -------------------------------------------------------------------------
    time_mask = None
    if use_time_mask:
        time_mask = _build_time_mask_sample_delay_resp(
        T=T,
        fps=float(meta["fps"]),
        meta=meta,
        sample_ignore_ms=sample_ignore_ms,
        resp_sec=2.0,
        )
    else:
        time_mask = np.ones(T, dtype=bool)


    # -------------------------------------------------------------------------
    # Build external input tensor u: [C, T, D_in]
    # For now, D_in = C and u is condition one-hot.
    # -------------------------------------------------------------------------
    amp_input = float(default_parameters.get("amp_input", 1.0))
    u = _build_input_tensor(
    C=C,
    T=T,
    cond_names=cond_names,
    device=device,
    amp_input=amp_input,
    meta=meta,
    amp_stim=amp_input,
    sample_len_sec=1.15,
    on_sec=0.15,
    off_sec=0.10,
    n_bursts=5,
    include_go_cue=include_go_cue,
    go_cue_sec=go_cue_sec,
    amp_go_cue=amp_go_cue,
    include_reward=include_reward,
    amp_reward=amp_reward,
    )

    D_in = u.shape[-1]

    # -------------------------------------------------------------------------
    # Instantiate the RNN
    # -------------------------------------------------------------------------
    dt = float(default_parameters.get("dt", 1.0))
    tau = float(default_parameters.get("tau", 1.0))
    substeps = int(default_parameters.get("substeps", 1))

    is_exc = load_is_excitatory_from_npz(npz_path) 

    dale_mask = build_dale_mask_from_types(is_exc)

    net = ALMCurrentRNN(
        N=N,
        D_in=D_in,
        dt=dt,
        tau=tau,
        substeps=substeps,
        nonlinearity="tanh",
        device=device,
        dale_mask=dale_mask.to(device),
    )
    # -------------------------------------------------------------------------
    # Loss and optimizer
    # -------------------------------------------------------------------------
    loss_trials = LossAverageTrials()
    optimizer = tch.optim.Adam(net.parameters(), lr=lr)

    loss_history = np.zeros(max_epochs, dtype=np.float32)

    # Use session id and tag to build filenames
    session_id = meta.get("session_id", "session")
    plane = meta.get("plane", "plane")
    animal = meta.get("animal", "animal")

    if tag:
        run_tag = f"{animal}_{session_id}_{plane}_{tag}"
    else:
        run_tag = f"{animal}_{session_id}_{plane}"

    model_path = os.path.join(out_dir, f"rnn_current_{run_tag}.pt")
    loss_plot_path = os.path.join(out_dir, f"loss_{run_tag}")

    # -------------------------------------------------------------------------
    # Training loop
    # -------------------------------------------------------------------------
    print(f"[INFO] Training ALMCurrentRNN on {npz_path}")
    print(f"[INFO] Conditions: {cond_names}")
    print(f"[INFO] psth shape: C={C}, T={T}, N={N}, device={device}")
    print(f"[INFO] dt={dt}, tau={tau}, amp_input={amp_input}, lr={lr}")
    print(f"[INFO] Saving model to: {model_path}")
    print(f"[INFO] Training for {max_epochs} epochs...")

    start_time = time.time()
    best_loss = float("inf")
    best_state_dict = None

    for epoch in range(max_epochs):
        net.train()
        optimizer.zero_grad()

        # Forward: u has shape [C, T, D_in]
        out = net(u, h0=None, noise_std=noise_std, return_rate=True)
        rates_pred = out["rate"]  # shape [C, T, N]

        # Optionally apply time mask on the time dimension
        if time_mask is not None:
            psth_used = psth[:, time_mask, :]         # [C, T_mask, N]
            rates_used = rates_pred[:, time_mask, :]  # [C, T_mask, N]
        else:
            psth_used = psth
            rates_used = rates_pred

        # Loss: trial-averaged reconstruction + L2 regularization
        loss_fit = loss_trials(psth_used, rates_used)
        loss_reg = _regularization_l2(net, lam_J=lam_J, lam_W=lam_W)
        loss = loss_fit + loss_reg

        loss.backward()
        optimizer.step()

        # Optionally enforce Dale's law by projecting J if a mask is set
        net.apply_dale_mask()

        # Record loss
        loss_val = float(loss.item())
        loss_history[epoch] = loss_val

        # Track best model
        if loss_val < best_loss:
            best_loss = loss_val
            best_state_dict = {k: v.detach().cpu().clone() for k, v in net.state_dict().items()}

        # Logging
        if (epoch + 1) % 100 == 0 or epoch == 0:
            elapsed = time.time() - start_time
            print(
                f"Epoch {epoch+1}/{max_epochs} | "
                f"Loss = {loss_val:.6f} | "
                f"Fit = {float(loss_fit.item()):.6f} | "
                f"Reg = {float(loss_reg.item()):.6f} | "
                f"Elapsed = {elapsed/60:.1f} min"
            )

        # Optionally plot loss curve periodically
        if (epoch + 1) % 1000 == 0:
            plotting.plot_loss(epoch + 1, loss_history, title="Total loss", tag=loss_plot_path)

    total_time = time.time() - start_time
    print(f"[INFO] Training finished in {total_time/60:.1f} minutes.")
    print(f"[INFO] Best loss = {best_loss:.6f}")

    # -------------------------------------------------------------------------
    # Save best model and final loss curve
    # -------------------------------------------------------------------------
    if best_state_dict is not None:
        tch.save(best_state_dict, model_path)
        print(f"[OK] Best model saved to {model_path}")

    # Final loss plot
    plotting.plot_loss(max_epochs, loss_history, title="Total loss", tag=loss_plot_path)
    print(f"[OK] Loss curve saved to {loss_plot_path}.png")

    result = {
        "net": net,
        "psth": psth,
        "meta": meta,
        "loss_history": loss_history,
        "time_mask": time_mask,
    }
    return result

# ===========================
# Global-registry training
# ===========================
import csv
from collections import defaultdict

def _time_bin_smooth_psth(x: tch.Tensor, fps: float, bin_ms: float) -> tch.Tensor:
    return _time_bin_smooth_ctn(x, fps=fps, bin_ms=bin_ms)

def _read_registry_csv(registry_csv_path):
    rows = []
    with open(registry_csv_path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for r in reader:
            rows.append(r)
    if len(rows) == 0:
        raise ValueError("Empty registry csv: %s" % registry_csv_path)
    return rows

def _group_registry_rows(rows):
    """
    Group rows by unit_key. Minimal required keys:
      - unit_key, npz_path, global_idx, array_idx
    """
    by_unit = defaultdict(list)
    max_g = -1
    for r in rows:
        if "unit_key" not in r or "npz_path" not in r or "global_idx" not in r or "array_idx" not in r:
            raise KeyError("Registry row missing required columns. Need unit_key/npz_path/global_idx/array_idx.")
        g = int(r["global_idx"])
        aidx = int(r["array_idx"])
        max_g = max(max_g, g)
        by_unit[str(r["unit_key"])].append((g, aidx, r))
    n_obs = max_g + 1
    return by_unit, n_obs

def _build_keepidx_pos_map(keep_idx_arr):
    # keep_idx_arr: np.ndarray[int], length N_kept
    d = {}
    for i in range(int(keep_idx_arr.shape[0])):
        d[int(keep_idx_arr[i])] = i
    return d

def _preload_units_from_registry(
    by_unit,
    n_exc_virtual,
    device,
    cond_filter,
    max_time,
    psth_bin_ms,
    sample_ignore_ms,
    # ---- optional knobs (won't break existing call sites) ----
    amp_input: float = 1.0,
    include_go_cue: bool = True,
    go_cue_sec: float = 0.10,
    include_reward: bool = True,
    reward_mode: str = "correctport",
    resp_sec: float = 2.0,
):
    """
    Returns:
      units: list[dict] with keys:
        - unit_key, npz_path
        - psth_sub:  [C,T,K]  (target; inhibitory-only subset for this unit)
        - u:         [C,T,D]  (inputs; tone/go/reward)
        - idx_net:   [K] long (indices into full net of size N_total)
        - time_mask: [T] bool (torch)
        - meta: dict
      shared: dict with keys:
        - C, T, fps
        - N_inh_total, N_total
    """
    import numpy as np
    import torch as tch

    def _get_smoother():
        # Prefer psth smoother if present; otherwise fallback to continuous smoother.
        if "_time_bin_smooth_psth" in globals() and callable(globals()["_time_bin_smooth_psth"]):
            return globals()["_time_bin_smooth_psth"]
        if "_time_bin_smooth_ctn" in globals() and callable(globals()["_time_bin_smooth_ctn"]):
            return globals()["_time_bin_smooth_ctn"]
        return None

    smoother = _get_smoother()

    # -----------------------------
    # Pass 1: load each unit, build psth_sub (pre-clip), record (C,T,fps)
    # -----------------------------
    pre = []
    C_ref = None
    fps_ref = None
    g_max = -1
    T_min = None

    for unit_key, items in by_unit.items():
        if len(items) == 0:
            continue

        # all rows in this unit share npz_path
        npz_path = str(items[0][2]["npz_path"])
        for (_, _, rr) in items[1:]:
            if str(rr["npz_path"]) != npz_path:
                raise ValueError(f"unit_key {unit_key} has inconsistent npz_path in registry.")

        psth, meta = load_alm_psth_npz(
            npz_path=npz_path,
            cond_filter=cond_filter,
            max_time=None,          # we handle max_time and cross-unit alignment ourselves
            device=device,
        )

        # optional hard clip (user provided)
        if max_time is not None:
            psth = psth[:, : int(max_time), :]

        keep_idx = meta.get("keep_idx", None)
        if keep_idx is None:
            raise KeyError(
                f"meta['keep_idx'] missing for {npz_path}. "
                "Stage1 npz must contain keep_idx for registry mapping."
            )
        keep_map = _build_keepidx_pos_map(np.asarray(keep_idx, dtype=int))

        # positions in psth dim=2 for this unit
        g_list = []
        pos_list = []
        for (g, array_idx, _) in items:
            ai = int(array_idx)
            if ai not in keep_map:
                raise ValueError(
                    f"array_idx={ai} not found in keep_idx of {npz_path} (unit_key={unit_key}). "
                    "Check registry builder mapping."
                )
            pos_list.append(int(keep_map[ai]))
            g_list.append(int(g))

        if len(g_list) == 0:
            continue

        pos_t = tch.as_tensor(pos_list, dtype=tch.long, device=device)
        psth_sub = psth.index_select(dim=2, index=pos_t)  # [C,T,K]

        # bin/smooth target psth (if requested)
        if psth_bin_ms is not None and float(psth_bin_ms) > 0:
            if smoother is None:
                raise NameError("No smoothing function found. Define _time_bin_smooth_psth or _time_bin_smooth_ctn.")
            fps = float(meta["fps"])
            psth_sub = smoother(psth_sub, fps=fps, bin_ms=float(psth_bin_ms))

        C = int(psth_sub.shape[0])
        T = int(psth_sub.shape[1])
        fps = float(meta["fps"])

        if C_ref is None:
            C_ref = C
        elif C != C_ref:
            raise ValueError(f"Inconsistent C across units: unit {unit_key} has C={C}, ref C={C_ref}")

        if fps_ref is None:
            fps_ref = fps
        else:
            # allow tiny numeric jitter
            if abs(fps - fps_ref) > 1e-3:
                raise ValueError(f"Inconsistent fps across units: unit {unit_key} fps={fps}, ref fps={fps_ref}")

        T_min = T if T_min is None else min(T_min, T)

        g_max = max(g_max, max(g_list))
        pre.append(
            dict(
                unit_key=unit_key,
                npz_path=npz_path,
                psth_sub=psth_sub,
                meta=meta,
                g_list=g_list,
            )
        )

    if len(pre) == 0:
        raise ValueError("No units loaded from registry (by_unit is empty after filtering).")

    if T_min is None or C_ref is None or fps_ref is None:
        raise RuntimeError("Failed to determine shared (C,T,fps).")

    # Final shared T
    T_shared = int(T_min)

    # network sizes
    N_inh_total = int(g_max + 1)  # global inhibitory index is [0..g_max]
    N_total = int(n_exc_virtual) + N_inh_total

    # -----------------------------
    # Pass 2: clip to T_shared, attach lick/reward, build u/time_mask/idx_net
    # -----------------------------
    units = []
    for item in pre:
        unit_key = item["unit_key"]
        npz_path = item["npz_path"]
        meta = item["meta"]
        g_list = item["g_list"]

        psth_sub = item["psth_sub"][:, :T_shared, :]  # [C,T,K] clip

        # attach lick/reward traces (MUST match the final T)
        meta = _maybe_attach_lick_reward_to_meta(meta, npz_path=npz_path, T=T_shared)

        cond_names = list(meta["cond_names"])
        if len(cond_names) != int(psth_sub.shape[0]):
            raise ValueError(
                f"cond_names length mismatch for {unit_key}: "
                f"len(cond_names)={len(cond_names)} but C={int(psth_sub.shape[0])}"
            )

        # build input tensor u: [C,T,D]
        u = _build_input_tensor(
            C=len(cond_names),
            T=T_shared,
            cond_names=cond_names,
            device=device,
            amp_input=float(amp_input),
            include_go_cue=bool(include_go_cue),
            go_cue_sec=float(go_cue_sec),
            include_reward=bool(include_reward),
            meta=meta,
        )

        # build time mask: [T]
        time_mask_np = _build_time_mask_sample_delay_resp(
            T=T_shared,
            fps=float(meta["fps"]),
            meta=meta,
            sample_ignore_ms=float(sample_ignore_ms),
            resp_sec=float(resp_sec),
        )
        time_mask = tch.as_tensor(time_mask_np.astype(np.bool_), device=device)

        # map inhibitory global index -> net index by adding n_exc_virtual offset
        idx_net = tch.as_tensor(
            [int(g) + int(n_exc_virtual) for g in g_list],
            dtype=tch.long,
            device=device,
        )

        units.append(
            dict(
                unit_key=unit_key,
                npz_path=npz_path,
                psth_sub=psth_sub,
                u=u,
                idx_net=idx_net,
                time_mask=time_mask,
                meta=meta,
            )
        )

    shared = dict(C=int(C_ref), T=int(T_shared), fps=float(fps_ref), N_inh_total=N_inh_total, N_total=N_total)
    return units, shared




def train_current_alm_global(
    registry_dir: str,
    animal: str,
    out_dir: str,
    *,
    # training
    max_epochs: int = 3000,
    lr: float = 1e-4,
    weight_decay: float = 0.0,
    seed: int = 0,
    noise_std: float = 0.0,
    grad_clip: float = 1.0,
    # model dynamics
    dt: float = 0.03436,
    tau: float = 0.01,
    substeps: int = 4,
    nonlinearity: str = "tanh",
    dale: bool = False,
    # global sizing
    n_exc_virtual: int = 800,
    # unit/session sampling
    unit_sampling: str = "random",   # "random" | "cycle"
    max_sessions: int = None,        # optional: only use top-K sessions from registry builder
    # data shaping
    cond_filter=None,
    max_time=None,
    psth_bin_ms: float = 0.0,
    sample_ignore_ms: float = 50.0,
    resp_sec: float = 2.0,
):
    import os, time, json
    import numpy as np
    import pandas as pd
    import torch as tch

    os.makedirs(out_dir, exist_ok=True)

    dev = tch.device("cuda" if tch.cuda.is_available() else "cpu")
    rng = np.random.RandomState(int(seed))

    # ----------------------------
    # 1) Load registry (CSV produced by build_global_registry.py)
    # ----------------------------
    # 你 registry_dir 里通常会放 registry.csv；如果你用别的命名，这里改一下即可
    registry_csv = os.path.join(registry_dir, f"{animal}_registry.csv")
    if not os.path.isfile(registry_csv):
        # fallback
        registry_csv = os.path.join(registry_dir, "registry.csv")
    if not os.path.isfile(registry_csv):
        raise FileNotFoundError(f"Cannot find registry csv in {registry_dir} (tried {animal}_registry.csv and registry.csv)")

    df = pd.read_csv(registry_csv)

    # 你 registry 的列名/字段：以你当前 build_global_registry 输出为准
    # 这里要求至少有：unit_key, global_idx, array_idx, npz_path
    required_cols = ["unit_key", "global_idx", "array_idx", "npz_path"]
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        raise KeyError(f"Registry missing columns: {missing}. Got columns={list(df.columns)}")

    # group -> by_unit: unit_key -> list[(global_idx, array_idx, row_dict)]
    by_unit = {}
    for _, r in df.iterrows():
        uk = str(r["unit_key"])
        g = int(r["global_idx"])
        a = int(r["array_idx"])
        by_unit.setdefault(uk, []).append((g, a, dict(r)))

    # optional: limit number of sessions if registry builder already sorted by K desc
    unit_keys = sorted(by_unit.keys())
    if max_sessions is not None and int(max_sessions) > 0:
        unit_keys = unit_keys[: int(max_sessions)]
        by_unit = {k: by_unit[k] for k in unit_keys}

    # ----------------------------
    # 2) Preload unit tensors (psth_sub/u/idx_net/time_mask/meta)
    # ----------------------------
    units, shared = _preload_units_from_registry(
        by_unit=by_unit,
        n_exc_virtual=int(n_exc_virtual),
        device=dev,
        cond_filter=cond_filter,
        max_time=max_time,
        psth_bin_ms=psth_bin_ms,
        sample_ignore_ms=sample_ignore_ms,
    )

    if len(units) == 0:
        raise RuntimeError("No units loaded from registry. Check registry csv and filters.")

    # Determine observed inhibitory count from registry global_idx
    all_g = []
    for u0 in units:
        # idx_net = n_exc_virtual + global_idx (constructed in preload)
        # recover global_idx count by subtracting offset
        all_g.append((u0["idx_net"].detach().cpu().numpy() - int(n_exc_virtual)).astype(int))
    all_g = np.concatenate(all_g, axis=0)
    n_obs = int(all_g.max()) + 1
    n_total = int(n_exc_virtual) + int(n_obs)

    # input dimension
    D_in = int(units[0]["u"].shape[-1])

    # ----------------------------
    # 3) Dale mask (sign by presynaptic type)
    # J[i,j] is from neuron j -> i because rec = rate @ J.T  (see your forward) :contentReference[oaicite:4]{index=4}
    # ----------------------------
    dale_mask = None
    if bool(dale):
        dale_mask = tch.zeros((n_total, n_total), dtype=tch.int8, device=dev)
        # presyn excit (columns 0:n_exc_virtual) -> positive
        dale_mask[:, : int(n_exc_virtual)] = 1
        # presyn inhib (columns n_exc_virtual:) -> negative
        dale_mask[:, int(n_exc_virtual) :] = -1

    # ----------------------------
    # 4) Build model (IMPORTANT: pass substeps!)
    # ----------------------------
    net = ALMCurrentRNN(
        N=int(n_total),
        D_in=int(D_in),
        dt=float(dt),
        tau=float(tau),
        substeps=int(substeps),
        nonlinearity=str(nonlinearity),
        device=dev,
        dale_mask=dale_mask,
    ).to(dev)

    opt = tch.optim.Adam(net.parameters(), lr=float(lr), weight_decay=float(weight_decay))
    loss_fn = LossAverageTrials()

    # ----------------------------
    # 5) Training loop
    # ----------------------------
    best_loss = float("inf")
    best_state = None
    unit_order = list(range(len(units)))

    t0 = time.time()
    for ep in range(int(max_epochs)):
        net.train()

        if unit_sampling == "random":
            ui = int(rng.randint(0, len(units)))
        elif unit_sampling == "cycle":
            ui = unit_order[ep % len(unit_order)]
        else:
            raise ValueError(f"unit_sampling must be 'random' or 'cycle', got {unit_sampling}")

        batch = units[ui]
        u = batch["u"]               # [C,T,D]
        psth_sub = batch["psth_sub"] # [C,T,K]
        idx_net = batch["idx_net"]   # [K] (already includes n_exc_virtual offset)
        time_mask = batch["time_mask"]  # [T] bool

        # ---- numeric sanitation (prevents silent NaNs) ----
        u = tch.nan_to_num(u, nan=0.0, posinf=0.0, neginf=0.0)
        psth_sub = tch.nan_to_num(psth_sub, nan=0.0, posinf=0.0, neginf=0.0)

        opt.zero_grad(set_to_none=True)

        # Forward MUST follow your model API: returns dict with "rate" :contentReference[oaicite:5]{index=5}
        out = net(u, h0=None, noise_std=float(noise_std), return_rate=True)
        rates = out["rate"]  # [C,T,N_total]

        pred_sub = rates.index_select(dim=2, index=idx_net)  # [C,T,K]

        psth_use = psth_sub[:, time_mask, :]
        pred_use = pred_sub[:, time_mask, :]

        loss = loss_fn(psth_use, pred_use)

        # hard stop if non-finite (this is what you are seeing now)
        if not tch.isfinite(loss):
            with tch.no_grad():
                msg = {
                    "ep": ep + 1,
                    "unit_key": batch.get("unit_key", "NA"),
                    "loss": str(loss.detach().cpu().item()),
                    "u_minmax": (float(u.min().cpu()), float(u.max().cpu())),
                    "psth_minmax": (float(psth_sub.min().cpu()), float(psth_sub.max().cpu())),
                    "rate_minmax": (float(rates.min().cpu()), float(rates.max().cpu())),
                    "J_norm": float(net.J.norm().detach().cpu()),
                    "W_norm": float(net.W_in.norm().detach().cpu()),
                    "dt_over_tau": float(net.dt / net.tau),
                    "substeps": int(getattr(net, "substeps", 1)),
                }
            raise FloatingPointError(f"Non-finite loss detected:\n{json.dumps(msg, indent=2)}")

        loss.backward()

        if grad_clip is not None and float(grad_clip) > 0:
            tch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=float(grad_clip))

        opt.step()

        # Dale projection uses apply_dale_mask() (your model method name) :contentReference[oaicite:6]{index=6}
        if bool(dale):
            net.apply_dale_mask()

        loss_val = float(loss.detach().cpu().item())
        if loss_val < best_loss:
            best_loss = loss_val
            best_state = {k: v.detach().cpu().clone() for k, v in net.state_dict().items()}

        if (ep == 0) or ((ep + 1) % 50 == 0):
            elapsed = time.time() - t0
            print(
                "[global] ep=%d/%d loss=%.6f best=%.6f unit=%s (K=%d) elapsed=%.1fs"
                % (ep + 1, int(max_epochs), loss_val, float(best_loss),
                   batch.get("unit_key", "NA"), int(idx_net.numel()), elapsed)
            )

    # ----------------------------
    # 6) Save best
    # ----------------------------
    if best_state is None:
        best_state = net.state_dict()

    tag = f"{animal}_global_nobs{n_obs}_nexc{int(n_exc_virtual)}_ntotal{n_total}"
    model_path = os.path.join(out_dir, f"rnn_current_{tag}.pt")
    meta_path = os.path.join(out_dir, f"rnn_current_{tag}.meta.json")

    tch.save(best_state, model_path)

    meta_out = {
        "animal": animal,
        "registry_csv": registry_csv,
        "n_exc_virtual": int(n_exc_virtual),
        "n_obs_inh": int(n_obs),
        "n_total": int(n_total),
        "D_in": int(D_in),
        "dt": float(dt),
        "tau": float(tau),
        "substeps": int(substeps),
        "nonlinearity": str(nonlinearity),
        "dale": bool(dale),
        "psth_bin_ms": float(psth_bin_ms),
        "sample_ignore_ms": float(sample_ignore_ms),
        "resp_sec": float(resp_sec),
        "best_loss": float(best_loss),
        "unit_sampling": str(unit_sampling),
        "max_sessions": None if max_sessions is None else int(max_sessions),
    }
    with open(meta_path, "w") as f:
        json.dump(meta_out, f, indent=2)

    print(f"[OK] Saved model -> {model_path}")
    print(f"[OK] Saved meta  -> {meta_path}")




================================================
FILE: current_rnn/utils_celltype.py
================================================
# current_rnn/utils_celltype.py

from __future__ import annotations
import numpy as np
import pandas as pd
from typing import Sequence


EXC_KEYWORDS = (

)

INH_KEYWORDS = (
    "Vip",
    "Sst",
    "Pvalb",
    "Lamp5",
    "Sncg",
    "Serpinf1",
    "Meis2"        
)


def subclass_to_is_excitatory(subclass: str) -> bool:

    if subclass is None:
        return True

    s = str(subclass).lower().strip()
    if s in ("", "nan", "none"):
        return True

    has_exc = any(k in s for k in EXC_KEYWORDS)
    has_inh = any(k in s for k in INH_KEYWORDS)

    if has_exc and not has_inh:
        return True
    if has_inh and not has_exc:
        return False

    # 模糊情况默认 excitatory（通常是 IT-like）
    return True


def load_is_excitatory_from_npz(npz_path: str) -> np.ndarray:

    data = np.load(npz_path, allow_pickle=True)

    if "cell_types" not in data.files:
        raise KeyError(f"{npz_path} 中没有字段 'cell_types'")

    subclasses = data["cell_types"]  # dtype=object, len=N
    subclasses = np.asarray(subclasses).astype(str)

    is_exc = np.array(
        [subclass_to_is_excitatory(s) for s in subclasses],
        dtype=bool
    )
    return is_exc



================================================
FILE: legacy_rnn/cross_validating.py
================================================
import json 
import torch as tch
from losses import *
from model import  SingleTrialLicks 
from plotting import *
from utils import *
import numpy as np
import time
import pickle
import random
from sklearn.model_selection import train_test_split

path_save = '../results/'

#loading hiperparameters data
with open('parameters_list.json') as f:
    default_parameters = json.load(f)


def cross_validate(files_list, session_names = [], net_params=None, n_pop=15, hemi='right', max_time_index =275, lr=5e-4, max_epochs = 300000, test_every = 50,  optimize_every = 1, random_seed = 42,  info = ''):
    thres_trial_av = 100
    #coeficient losses
    c_coding_av = .02 #rec neurons
    c_trials_av = 0.65 #rec av rates left
    c_time_av = 0.1666
    c_orth = 500
    c_sel = 0.5


    #loading data    
    mean_licks = mean_licks_inputs(files_list, hemi = hemi, max_time_index = max_time_index) 
    single_trial_licks = licks_inputs(files_list, max_time_index =  max_time_index)
    ALM_hemi= load_me_data(files_list, default_parameters, hemi=hemi, max_time_index=max_time_index)
    trial_average = tch.tensor(ALM_hemi['rates'][0:2,:,:], dtype = tch.float32).to(default_parameters['device']).float()
    print('dimensions', hemi, trial_average.shape, mean_licks.shape)
        
    #loading data    
    total_sessions = len(session_names)
    trial_indexes = {}
    for ses_name in session_names:
        trial_indexes[ses_name] = ALM_hemi['indexes'][ses_name]
    trial_average, trial_types = toch_version_ratates_trial_types(ALM_hemi, default_parameters, session_names)
    # single trial activity
    single_trials_activity = toch_single_trials(session_names, default_parameters, max_time_index = max_time_index)
    #indexes of neurons at each sesions
    indexes_neurons_st = [ALM_hemi['indexes'][s] for s in session_names]
    total_sessions = len(indexes_neurons_st )
    #parameters
    default_parameters['n_latents'] = n_pop
    default_parameters['n_neurons'] = ALM_hemi['rates'].shape[2]
    #trial average
    LossTrials = LossAverageTrials()
    losses_trial_av = np.zeros(max_epochs)
    #loss on the modes
    LossSelectivity = SelectivityLoss(trial_average, default_parameters)
    losses_sel = np.zeros(max_epochs)
    #loss on the orthogonality of the weights
    LossWeights = LossOrthogonality(default_parameters['device']) 
    losses_weights = np.zeros(max_epochs)
    losses_time_av = np.zeros(max_epochs)
    losses_coding_av = np.zeros(max_epochs)
    #Defining losses
    #average over time
    ListLossesTime = [LossAverageTime(default_parameters) for s in session_names]
    #average over neurons
    ListLossesCoding = [SelectivitySingleTrialLoss(trial_average, default_parameters, indexes_neurons_st[s]) for s in range(len(session_names))]

    #number of trials
    n_trials = 0
    for t_type in trial_types:
        n_trials+=len(trial_types[t_type])
    train_idx, test_idx = train_test_split(np.arange(n_trials), test_size=0.2, random_state=random_seed)
    default_parameters['n_trials'] = len(test_idx)
    net = SingleTrialLicks(default_parameters, indexes_neurons_st)
    net.device = default_parameters['device']
    if net_params is not None:
        checkpoint = tch.load(net_params)

        # Remove 'input_trial' from the checkpoint to avoid shape mismatch
        checkpoint = {k: v for k, v in checkpoint.items() if k != 'input_trial'}

        # Load the remaining parameters
        net.load_state_dict(checkpoint, strict=False)
        print('Loaded pretrained network (excluding input_trial)')



    # Freeze all parameters except input_trial
    for name, param in net.named_parameters():
        if name == 'input_trial':
            param.requires_grad = True
        else:
            param.requires_grad = False
    # Optimizer will only update input_trial
    optimizer = tch.optim.Adam([net.input_trial], lr=lr)
    epoch=0
    min_mean_loss = 50. 
    while epoch<max_epochs:
        #adding initial data
        # NOTE: single_trial_licks is a challenge for stitching, fix before stitch sessions
        net.t_start =  np.random.uniform(-4.35, -2.35)
        ind_t_start = int((-2.35-net.t_start)/net.dt)
        #train dataset
        zeros_insert = tch.zeros((2, len(test_idx), ind_t_start), device = 'cuda') 
        s_trials_licks = single_trial_licks[session_names[0]][:,test_idx,:]
        licks_with_zeros = tch.cat([zeros_insert, s_trials_licks], dim=2)
        #licks 
        zeros_insert = tch.zeros((2, ind_t_start, ALM_hemi['rates'].shape[2]), device = 'cuda') 
        mean_licks_zeros = tch.cat([zeros_insert, mean_licks], dim=1)
        t_types = trial_types[session_names[0]][test_idx]

        results, cov = net.forward(mean_licks_zeros, licks_with_zeros, t_types)
        #Reconsutring neural activity average over trials
        total_trial_average = LossTrials(trial_average, results['rates_alm'][:,ind_t_start:,:])
        losses_trial_av[epoch] = total_trial_average.detach().cpu().numpy()
    
        ##Reconsutring average activity over time
        total_time_average = 0
        for s in range(len(session_names)):
            #trial indexes to compute
            single_trial_neural_activity = single_trials_activity[session_names[s]][test_idx][:,:,indexes_neurons_st[s]]
            total_time_average += ListLossesTime[s](single_trial_neural_activity, results['rates_trials'][:,ind_t_start:,indexes_neurons_st[s]])
        total_time_average = total_time_average/float(total_sessions)
        losses_time_av[epoch] = total_time_average .detach().cpu().numpy()
    
        ##Reconsutring average activity over time
        total_coding_average = 0
        for s in range(len(session_names)):
            #trial indexes to compute
            single_trial_neural_activity = single_trials_activity[session_names[s]][test_idx][:,:,indexes_neurons_st[s]]
            total_coding_average += ListLossesCoding[s](net, single_trial_neural_activity, results['latents_trials'][:,ind_t_start:,:]) # Note: problem here with stitching
        total_coding_average  = total_coding_average /float(total_sessions)
        losses_coding_av[epoch] = total_coding_average.detach().cpu().numpy()

        #Loss orthogonality factors
        total_orth = LossWeights(cov)
        losses_weights[epoch] = total_orth.detach().cpu().numpy()

        #Loss selectivity
        total_selectivity = LossSelectivity(net)
        losses_sel[epoch] = total_selectivity.detach().cpu().numpy()

        # loss input trials
        l2_input_loss = tch.mean(net.input_trial ** 2)


        #defining total loss
        loss_factors =  c_orth * total_orth + c_sel * total_selectivity
        
        if thres_trial_av<losses_trial_av[epoch]:
            loss_reconstruction = total_trial_average
            net.is_trial_average = True
        else:
            net.is_trial_average = False
            loss_reconstruction = c_coding_av * total_coding_average + c_trials_av * total_trial_average + c_time_av * total_time_average
        total_loss = 0.7 * loss_reconstruction + 0.3 * loss_factors + 0.05 * l2_input_loss 
        total_loss= total_loss/ optimize_every

        #mean reconstruction loss
        mean_trial = np.mean(losses_trial_av[max(0, epoch-100):epoch])
        mean_total_loss = total_loss.detach().cpu().numpy()
        mean_time = np.mean(losses_time_av[max(0, epoch-100):epoch])
        mean_coding = np.mean(losses_coding_av[max(0, epoch-100):epoch])
        sel_loss = np.mean(losses_sel[max(0, epoch-100):epoch])
        weights_loss = np.mean(losses_weights[max(0, epoch-100):epoch])
        print(f'Epoch {epoch}'+f'| Total Loss {mean_total_loss}' +f' | Trial Av. = {mean_trial}'+f' | Epoch Av. = {mean_time}'+f' | Coding Av. = {mean_coding}'+ f'| Sel. = {sel_loss}'+f' | Orth. = {np.mean(weights_loss)}' +f' | Inputs = {l2_input_loss.detach().cpu().numpy()}' )
        
        ##optimizing
        optimizer.zero_grad()
        total_loss.backward()
        tch.nn.utils.clip_grad_norm_(net.parameters(),  max_norm=12., norm_type=2)
        optimizer.step()

            
        epoch += 1
        if epoch != 0 and epoch %test_every == 0 and mean_trial < min_mean_loss:
            min_mean_loss = min(min_mean_loss, mean_trial)
            print('saving net')
            name_f = path_save+'net_ALM_'+str(n_pop)+'_rseed_'+str(random_seed)+ '_test.pth'
            tch.save(net.state_dict(), name_f)   
        if epoch != 0 and epoch % test_every == 0:
            # Bundle everything into a single dict (include seed)
            losses_dict = {
                "meta": {
                    "epoch": epoch,
                    "n_pop": n_pop,
                    "test_every": test_every,
                    "random_seed": random_seed,
                },
                "trial_average": losses_trial_av,
                "time_average": losses_time_av,
                "projection": losses_coding_av,
                "weights": losses_weights,
                "selectivity": losses_sel,
            }

            os.makedirs(path_save, exist_ok=True)
            base = f"npop_{n_pop}_rseed_{random_seed}"
            save_path = os.path.join(path_save, f"losses_{base}_test.p")
            with open(save_path, "wb") as f:
                pickle.dump(losses_dict, f)

            # Plot (tag files with seed to avoid overwrites)
            plot_map = {
                "Loss Trial Average":  "trial_average",
                "Loss Epoch Average":  "time_average",
                "Projection Loss":     "projection",
            }
            for name_loss, key in plot_map.items():
                name_file = os.path.join(path_save, f"{key}_{base}")
                plot_loss(epoch, losses_dict[key], name_loss, tag=name_file)

 



================================================
FILE: legacy_rnn/losses.py
================================================
import torch as tch 
import numpy as np




class LossSparsity:
    def __init__(self, device):
        self.device = device
        self.l1_loss = tch.nn.L1Loss()

    def __call__(self, net):
        J_rec = net.J_rec
        total_loss = self.l1_loss(J_rec, tch.zeros(J_rec.shape).to(self.device))
        return total_loss

class SelectivityLoss:
    def __init__(self, rates, params_dict):
        self.dt = params_dict['dt']
        self.t_min_input = params_dict['t_min_input']
        self.t_max_input = params_dict['t_max_input']
        self.t_start = params_dict['t_start']
        self.t_go = params_dict['t_go']
        self.ind_delay = int((self.t_max_input- self.t_start)/self.dt)
        self.ind_sample = int((self.t_min_input - self.t_start)/self.dt)
        self.ind_go = int((self.t_go - self.t_start)/self.dt)
        self.d_ind = int(0.6/self.dt)
        self.compute_factors(rates)
        self.gram_schmidt(rates)
        self.cos =  tch.nn.CosineSimilarity(dim=0)
        self.mode_sample = 0
        self.mode_delay = 1
        self.mode_choice = 2
        self.alpha_delay = 1.5
        
    def __call__(self, net):
        #sample vectors
        net_sample_alm = net.decoder_alm[self.mode_sample,:]
        #delay vectors
        net_delay_alm = net.decoder_alm[self.mode_delay,:]
        #choice vectors
        net_choice_alm = net.decoder_alm[self.mode_choice,:]

        #losses
        loss_sample = (1 - self.cos(net_sample_alm, self.sample_alm))
        loss_delay = (1 - self.cos(net_delay_alm, self.delay_alm))
        loss_choice = (1 - self.cos(net_choice_alm, self.choice_alm))

        total_loss = (loss_sample + self.alpha_delay * loss_delay + loss_choice )/3.
        return total_loss

    def compute_factors(self, rates):
        self._sample_vectors(rates)
        self._delay_vectors(rates)
        self._choice_vectors(rates)

    def gram_schmidt(self, rates):
        self._sample_vectors(rates)
        self._delay_vectors(rates)
        self._choice_vectors(rates)
        vectors = tch.stack([self.sample_alm, self.delay_alm, self.choice_alm], dim=1) 
        # Perform QR decomposition for orthonormalization
        Q, R = tch.linalg.qr(vectors)

        # Q now contains the orthonormalized vectors
        orthonormal_vectors = Q.T  # Transpose to get them as a list

        # If you need them separately
        orthonormal_sample_alm, orthonormal_delay_alm, orthonormal_choice_alm = orthonormal_vectors
        self.sample_alm = tch.sign(R[0,0]) *  orthonormal_sample_alm # right increases
        self.delay_alm = tch.sign(R[1,1]) * orthonormal_delay_alm
        self.choice_alm = tch.sign(R[2,2]) * orthonormal_choice_alm
    
    def _sample_vectors(self, rates):
        y_alm = rates
        #calculating latent vectors
        vec_alm = y_alm[1,:, :] - y_alm[0, :, :]
        self.sample_alm = tch.mean(vec_alm[self.ind_delay-self.d_ind:self.ind_delay,:], axis=0)
        #self.sample_alm = tch.mean(vec_alm[self.ind_sample:self.ind_sample+self.d_ind,:], axis=0)

    def _delay_vectors(self, rates):
        y_alm = rates
        #calculating latent vectors
        vec_alm = y_alm[1,:, :] - y_alm[0, :, :]
        self.delay_alm = tch.mean(vec_alm[self.ind_go-self.d_ind:self.ind_go, :], axis=0)
    
    def _choice_vectors(self,rates):
        y_alm = rates
        #calculating latent vectors
        d_ind = int(0.4/self.dt)
        vec_alm = y_alm[1, :, :] - y_alm[0, :, :]
        self.choice_alm = tch.mean(vec_alm[self.ind_go:self.ind_go + d_ind, :], axis=0)
    


class SelectivitySingleTrialLoss:
    def __init__(self, rates, params_dict, indexes_neurons):
        self.dt = params_dict['dt']
        self.t_min_input = params_dict['t_min_input']
        self.t_max_input = params_dict['t_max_input']
        self.t_start = params_dict['t_start']
        self.t_go = params_dict['t_go']
        self.ind_delay = int((self.t_max_input- self.t_start)/self.dt)
        self.ind_sample = int((self.t_min_input - self.t_start)/self.dt)
        self.ind_go = int((self.t_go - self.t_start)/self.dt)
        self.d_ind = int(0.6/self.dt)
        self.compute_factors(rates)
        self.gram_schmidt(rates)
        self.mode_sample = 0
        self.mode_delay = 1
        self.mode_choice = 2
        self.indexes = indexes_neurons

    def __call__(self, net, rates_data, latents_trials):

        proj_sample_data, proj_delay_data, proj_choice_data = self.project_data(rates_data)
  

        #print(tch.mean(proj_delay_data), tch.mean(proj_delay_model))
        loss_sample = tch.mean(tch.square(proj_sample_data - latents_trials[:,:,self.mode_sample]))
        loss_delay = tch.mean(tch.square(proj_delay_data - latents_trials[:,:,self.mode_delay]))
        loss_choice = tch.mean(tch.square(proj_choice_data - latents_trials[:,:,self.mode_choice]))
        total_loss = (loss_sample + loss_delay + loss_choice )/3.
        return total_loss

    def compute_factors(self, rates):
        self._sample_vectors(rates)
        self._delay_vectors(rates)
        self._choice_vectors(rates)
    
    def project_data(self, rates_data):
        #losses
        proj_sample_data = rates_data @ self.sample_alm[self.indexes] 
        proj_delay_data = rates_data @ self.delay_alm[self.indexes]
        proj_choice_data = rates_data @ self.choice_alm[self.indexes] 
        return proj_sample_data, proj_delay_data, proj_choice_data

    def gram_schmidt(self, rates):
        self._sample_vectors(rates)
        self._delay_vectors(rates)
        self._choice_vectors(rates)
        vectors = tch.stack([self.sample_alm, self.delay_alm, self.choice_alm], dim=1) 
        # Perform QR decomposition for orthonormalization
        Q, R = tch.linalg.qr(vectors)

        # Q now contains the orthonormalized vectors
        orthonormal_vectors = Q.T  # Transpose to get them as a list

        # If you need them separately
        orthonormal_sample_alm, orthonormal_delay_alm, orthonormal_choice_alm = orthonormal_vectors
        self.sample_alm = tch.sign(R[0,0]) *  orthonormal_sample_alm # right increases
        self.delay_alm = tch.sign(R[1,1]) * orthonormal_delay_alm
        self.choice_alm = tch.sign(R[2,2]) * orthonormal_choice_alm

    def _sample_vectors(self, rates):
        y_alm = rates
        #calculating latent vectors
        vec_alm = y_alm[1,:, :] - y_alm[0, :, :]
        self.sample_alm = tch.mean(vec_alm[self.ind_delay-self.d_ind:self.ind_delay,:], axis=0)

    def _delay_vectors(self, rates):
        y_alm = rates
        #calculating latent vectors
        vec_alm = y_alm[1,:, :] - y_alm[0, :, :]
        self.delay_alm = tch.mean(vec_alm[self.ind_go-self.d_ind:self.ind_go, :], axis=0)
    
    def _choice_vectors(self,rates):
        y_alm = rates
        #calculating latent vectors
        d_ind = int(0.4/self.dt)
        vec_alm = y_alm[1, :, :] - y_alm[0, :, :]
        self.choice_alm = tch.mean(vec_alm[self.ind_go:self.ind_go + d_ind, :], axis=0)
    

class LossAverageTrials:
    def __init__(self):
        self.alpha = 0.1
        
    def __call__(self, av_trials_data, rates_alm):
        #calculating losses
        total_loss = tch.mean(tch.square(av_trials_data- rates_alm))
        return total_loss

class LossAverageTime:
    def __init__(self, params_dict):
        self.t_min_input = params_dict['t_min_input']
        self.t_max_input = params_dict['t_max_input']
        self.t_start = params_dict['t_start']
        self.t_go = params_dict['t_go']
        self.dt = params_dict['dt']

        self.t_after_go = 0.4
        t_sample_s = self.t_min_input - self.t_start 
        t_sample_e = self.t_max_input - self.t_start
        t_delay_e = self.t_go - self.t_start
        t_response = self.t_after_go - self.t_start

        self.ind_sample_s =  int(t_sample_s/self.dt)
        self.ind_sample_e = int(t_sample_e/self.dt)
        self.ind_delay_e1 = int(t_delay_e/(2 * self.dt))
        self.ind_delay_e2 = int(t_delay_e/self.dt)
        self.ind_response = int(t_response/self.dt)

    def __call__(self, rates_data, rates_model):
        # mean spikes across neurons
        av_time_model = self.compute_time_averages_4background(rates_model)
        av_time_data = self.compute_time_averages_4background(rates_data)
        #calculating losses
        total_loss = tch.mean(tch.square(av_time_data - av_time_model))
        return total_loss

    def compute_time_averages_4(self, rates):
        average_sample = tch.mean(rates[:, self.ind_sample_s:self.ind_sample_e, :], axis = 1)  
        average_delay1 = tch.mean(rates[:, self.ind_sample_e:self.ind_delay_e1, :], axis = 1) 
        average_delay2 = tch.mean(rates[:, self.ind_delay_e1:self.ind_delay_e2,:], axis = 1) 
        average_response = tch.mean(rates[:, self.ind_delay_e2:self.ind_response, :], axis = 1) 
        av_time_model = tch.stack((average_sample, average_delay1, average_delay2, average_response)) #condition, trials, neurons
        return av_time_model
    def compute_time_averages_3(self, rates):
        average_sample = tch.mean(rates[:, self.ind_sample_s:self.ind_sample_e, :], axis = 1)  
        average_delay = tch.mean(rates[:, self.ind_sample_e:self.ind_delay_e2, :], axis = 1) 
        average_response = tch.mean(rates[:, self.ind_delay_e2:self.ind_response, :], axis = 1) 
        av_time_model = tch.stack((average_sample, average_delay, average_response)) #condition, trials, neurons
        return av_time_model
    def compute_time_averages_4background(self, rates):
        average_background = tch.mean(rates[:, 0:self.ind_sample_s, :], axis = 1)  
        average_sample = tch.mean(rates[:, self.ind_sample_s:self.ind_sample_e, :], axis = 1)  
        average_delay = tch.mean(rates[:, self.ind_sample_e:self.ind_delay_e2, :], axis = 1) 
        average_response = tch.mean(rates[:, self.ind_delay_e2:self.ind_response, :], axis = 1) 
        av_time_model = tch.stack(( average_background, average_sample, average_delay, average_response)) #condition, trials, neurons
        return av_time_model

class LossAllSpikes:
    def __init__(self, indexes_neurons):
        self.indexes_neurons = indexes_neurons

    def __call__(self, spikes, rates):
        # mean spikes across neurons
        total_loss = tch.mean(tch.square(spikes- rates))
        return total_loss
    


class LossAverageNeurons:
    def __init__(self, indexes_neurons):
        self.indexes_neurons = indexes_neurons

    def __call__(self, av_neurons_data, rates):
        # mean spikes across neurons
        av_neurons_model = self.compute_average_neurons(rates)
        total_loss = tch.mean(tch.square(av_neurons_data - av_neurons_model))
        return total_loss
    
    def compute_average_neurons(self, rates):
        av_neurons_model = tch.mean(rates[:,:, self.indexes_neurons], axis = 2)#spikes per s
        return av_neurons_model

class LossOrthogonality:
    def __init__(self, device):
        self.device = device
        
    def __call__(self, cov_matrix):
        cov_alm = cov_matrix['cov_alm']
        eye_alm = tch.eye(cov_alm.shape[0]).to(self.device).float()
        total_loss = tch.mean(tch.square(cov_alm - eye_alm))
        return total_loss







================================================
FILE: legacy_rnn/main_test.py
================================================
from cross_validating import *
import os
from os import listdir
from os.path import isfile, join
import pickle

#stitch all sessions
path_dandi= '../data/MAPDANDI_Functional/'
directory = os.fsencode(path_dandi)
files_list = []
for file in os.listdir(directory):
    filename = os.fsdecode(file)
    if filename[30:31]=='.':
        data = pickle.load(open(path_dandi+filename, 'rb'))
        if len(data)>0:
            n_neurons = data['average_trials'].shape[1]
            if n_neurons>0:
                files_list.append(filename)

files_list = ['sub-442571_ses-20190228T140832.p']
n_pop = 10
random_seed = 38
net_params = 'net_ALM_'+str(int(n_pop))+'_rseed_'+str(int(random_seed))+'_train.pth'
hemi = 'right' #training on just left hemisphere neurons
max_epochs =50000
max_time_index = 275
cross_validate(files_list, session_names = ['sub-442571_ses-20190228T140832.p'], net_params=net_params, n_pop=n_pop, hemi=hemi, max_time_index =max_time_index,  lr=5e-4, max_epochs = max_epochs,  test_every = 50,  optimize_every = 1, random_seed=random_seed)

 









================================================
FILE: legacy_rnn/main_train.py
================================================
from training import *
import os
from os import listdir
from os.path import isfile, join
import pickle

#stitch all sessions
path_dandi= '../data/MAPDANDI_Functional/'
directory = os.fsencode(path_dandi)
files_list = []
for file in os.listdir(directory):
    filename = os.fsdecode(file)
    if filename[30:31]=='.':
        data = pickle.load(open(path_dandi+filename, 'rb'))
        if len(data)>0:
            n_neurons = data['average_trials'].shape[1]
            if n_neurons>0:
                files_list.append(filename)

files_list = ['sub-442571_ses-20190228T140832.p']
n_pop = 10
net_params = None#'net_ALM_20_5.pth'
hemi = 'right' #training on just left hemisphere neurons
max_epochs = 400000
max_time_index = 275
random_seed = 38
train(files_list, session_names = ['sub-442571_ses-20190228T140832.p'], net_params=net_params, n_pop=n_pop, hemi=hemi, max_time_index =max_time_index,  lr=5e-4, max_epochs = max_epochs,  test_every = 50,  optimize_every = 1, random_seed=random_seed)

 









================================================
FILE: legacy_rnn/model.py
================================================
import torch as tch 
#from tqdm import trange
import numpy as np
import torch.nn.functional as F





class SingleTrialLicks(tch.nn.Module):
    def __init__(self, params_dict, indexes_neurons_st):
        super(SingleTrialLicks, self).__init__()
        self.device = tch.device(params_dict['device'])
        self.dt = params_dict['dt']
        self.input_noise = params_dict['input_noise']
        self.t_min_input = params_dict['t_min_input']
        self.t_max_input = params_dict['t_max_input']
        self.t_min_test = params_dict['t_max_input']
        self.t_max_test = params_dict['t_max_input'] + 0.15
        self.t_start = params_dict['t_start']
        self.t_go = params_dict['t_go']

        self.is_trial_average = True

        # left and right
        self.bs = 2 #left and right trials
        self.n_trials = params_dict['n_trials']

        # number of populations
        self.n_pop_alm = params_dict['n_latents'] # number of latents

        # number of neurons
        self.n_neurons_alm = params_dict['n_neurons'] #number of neurons

        # transfer function:
        self.phi = tch.tanh
        #self.phi = tch.sigmoid
    
        # This implementation allows for non-unifrom neuron properties
        self.tau_alm = params_dict['tau'] 

        #indexes for neurons that are recorded at single trials
        self.single_trial_mask = tch.zeros((self.bs, self.n_trials, self.n_neurons_alm), device=self.device)
        for indexes in indexes_neurons_st:
            self.single_trial_mask[:,:, indexes] = 1
        #other cortex
        self.input_stim = tch.nn.Parameter(tch.rand(self.bs, self.n_pop_alm), requires_grad=True)
        self.input_go = tch.nn.Parameter(tch.rand(self.n_pop_alm), requires_grad=True)
        self.input_licks = tch.nn.Parameter(tch.rand(self.bs, self.n_neurons_alm), requires_grad=True)

         #building network parameters
        self.build_coef_phi()
        self.build_biases()
        self.build_input_trial()
        self.build_decoder()
        self.build_communication_recurrent()

        #perturbing the model
        self.input_test = tch.zeros(self.n_neurons_alm).to(self.device)     
        self.to(self.device)

    def build_coef_phi(self):
        # transfer function:
        self.coef_phi_alm = tch.nn.Parameter(20 * tch.ones(self.n_neurons_alm), requires_grad=True)
        
    def build_biases(self):
        # biases
        amp_biases_alm = .7
        self.biases_alm = tch.nn.Parameter(amp_biases_alm * tch.randn(self.n_neurons_alm), requires_grad=True)
        
    def build_decoder(self, amp_init=1.):
        #decoder ALM left
        amp_decoder_alm = amp_init/np.sqrt(self.n_neurons_alm)
        decoder_init_alm = amp_decoder_alm * tch.randn(self.n_pop_alm, self.n_neurons_alm)
        self.decoder_alm = tch.nn.Parameter(decoder_init_alm, requires_grad=True)  
    
    def build_input_trial(self, amp_init=.1):
        #input trial
        amp_trial = amp_init/np.sqrt(self.n_pop_alm)
        input_trial = amp_trial * tch.randn(self.n_pop_alm, self.n_trials)
        self.input_trial = tch.nn.Parameter(input_trial, requires_grad=True) 

    def build_communication_recurrent(self,  amp_init=.2):
        # Cortico-cortical matrices
        J_rec_init = amp_init * tch.randn(self.n_pop_alm , self.n_pop_alm)
        self.J_rec = tch.nn.Parameter(J_rec_init, requires_grad = True)

    def _input_test(self, t):
        """Input current for the sample period"""
        input_test = self.input_test
        if t > self.t_min_test and t < self.t_max_test:
            input_current = input_test
        else:
            input_current = tch.zeros_like(input_test).to(self.device)
        return input_current

    def _input_sample(self, t):
        """Input current for the sample period
         see Chen et al, Cell, 2024
        """
        input_stim = self.input_stim
        if t > self.t_min_input and t < self.t_min_input + 0.15:
            input_current = input_stim
        elif t > self.t_min_input + 0.25 and t < self.t_min_input + 0.4:
            input_current  = input_stim
        elif t > self.t_min_input + 0.5 and t < self.t_min_input + 0.65:
            input_current =  input_stim
        else:
            input_current = tch.zeros_like(input_stim).to(self.device)
        return input_current
     
    def _input_go(self, t):
        """Input current for the go cue
         see Chen et al, Cell, 2024
        """
        input_go = self.input_go
        if t>self.t_go and t < self.t_go + 0.1:
            input_current  = input_go 
        else:
            input_current = tch.zeros_like(input_go).to(self.device)
        return input_current
    
    def _input_mean_licks(self, t, mean_licks):
        """Input current corresponding
        to the left and right licks,
        motor propioceptive inputs
        """
        input_licks = self.input_licks
        i=int(t/self.dt)
        if  self.t_go + 0.1<t:
            input_current_mean  = tch.einsum('bj,bj->bj', input_licks, mean_licks[:,i,:])
        else:
            input_current_mean = tch.zeros((self.bs, self.n_neurons_alm)).to(self.device)
        return input_current_mean

    def _input_single_trial_licks(self, t, single_trial_licks):
        """Input current corresponding
        to the left and right licks,
        motor propioceptive inputs
        """
        input_licks = self.input_licks
        i=int(t/self.dt)
        if  self.t_go + 0.1<t:
            # Heree there is a big problem with stiching
            #fix before stitch sessions
            input_current_single_trial  = tch.einsum('bj,bs,bsj->bsj', input_licks, single_trial_licks[:,:, i], self.single_trial_mask)
            input_current_single_trial = input_current_single_trial[0] + input_current_single_trial[1]
        else:
            input_current_single_trial = tch.zeros((self.n_trials, self.n_neurons_alm)).to(self.device)
        return input_current_single_trial 
    
    def initial_conditions(self):
        #initial condition
        self.u_init_alm = 0.15 * tch.randn(self.n_pop_alm).to(self.device)
        m_alm = tch.stack([self.u_init_alm, self.u_init_alm]).to(self.device)
        m_trials = 0.15 * tch.randn((self.n_trials, self.n_pop_alm)).to(self.device)
        #init rates alm left
        current_inp = self.biases_alm 
        current_rec = m_alm @ (self.J_rec.T @ self.decoder_alm)  
        current_rec_trials = m_trials @ (self.J_rec.T @ self.decoder_alm)
        current = current_rec + current_inp
        current_trials = current_rec_trials + current_inp
        fr_phi_alm =  self.coef_phi_alm * (self.phi(current) + tch.ones_like(current))/2.
        fr_phi_trials = self.coef_phi_alm * (self.phi(current_trials) + tch.ones_like(current_trials))/2.
        init_cond = dict(
            m_alm = m_alm, #mean over trials
            fr_alm = fr_phi_alm,
            h_alm = current,
            m_trials = m_trials,
            fr_trials = fr_phi_trials,
            h_trials = current_trials
        )
        return init_cond
    

    def update_alm_mean(self, r_rec, mean_licks, t):
        """"Update alm mean"""
        #current input
        current_noise = self.input_noise * tch.randn_like(self.biases_alm)
        current_inp = self.biases_alm  + current_noise
        #input test
        current_test = self._input_test(t)
        #current task
        current_task = (self._input_sample(t)+ self._input_go(t)) @ self.decoder_alm
        current_licks = self._input_mean_licks(t, mean_licks) 
        #current recurrent
        overlap = r_rec @ self.decoder_alm.T
        current_rec = overlap @ (self.J_rec.T @ self.decoder_alm) 
        #total current
        current = current_rec + current_inp + current_test + current_task + current_licks
        fr_phi =  self.coef_phi_alm * (self.phi(current) + tch.ones_like(current))/2.
        #euler update
        r_rec = r_rec + self.dt * (-r_rec + fr_phi) / self.tau_alm
        return overlap, current, r_rec

    def update_alm_trials(self, r_rec, single_trial_licks, t, trial_type):
        """"Update alm trial by trial"""
        #current input
        current_noise = self.input_noise * tch.randn_like(self.biases_alm)
        current_inp = self.biases_alm + current_noise
        # current trials
        current_trials =  self.input_trial.T @ self.decoder_alm 
        #input test
        current_test = self._input_test(t)
        #current task
        current_licks = self._input_single_trial_licks(t, single_trial_licks) 
        #left trial recieve left current and right trial right current
        left_trials = tch.zeros(self.n_trials).to(self.device)
        right_trials = tch.zeros(self.n_trials).to(self.device)
        left_trials[trial_type==0] = 1 #left
        right_trials[trial_type==1] = 1 #right
        current_task_l_r = self._input_sample(t) @ self.decoder_alm + self._input_go(t) @ self.decoder_alm
        current_task = tch.einsum('i,l->il', left_trials, current_task_l_r[0])
        current_task += tch.einsum('i,l->il', right_trials, current_task_l_r[1])
        #current recurrent
        overlap = r_rec @ self.decoder_alm.T
        current_rec = overlap @ (self.J_rec.T @ self.decoder_alm) 
        #total current
        current = current_rec + current_inp + current_test + current_task + current_trials + current_licks
        fr_phi =  self.coef_phi_alm * (self.phi(current) + tch.ones_like(current))/2.
        #euler update
        r_rec = r_rec + self.dt * (-r_rec + fr_phi) / self.tau_alm
        return overlap, current, r_rec

    
    def covarainces_decoder(self):
        cov_alm = self.decoder_alm @ self.decoder_alm.T
        cov_decoders = dict(
            cov_alm = cov_alm
        )
        return cov_decoders
        
    def forward(self, mean_licks, single_trial_licks, trial_types):
        bs = mean_licks.shape[0]
        n_times = mean_licks.shape[1]
        #varibales alm left 
        latents_alm = tch.zeros(bs, n_times, self.n_pop_alm).to(self.device)
        rates_alm = tch.zeros(bs, n_times, self.n_neurons_alm).to(self.device)
        currents_alm = tch.zeros(bs, n_times, self.n_neurons_alm).to(self.device)
        #variable trials
        latents_trials = tch.zeros(self.n_trials, n_times, self.n_pop_alm).to(self.device)
        rates_trials = tch.zeros(self.n_trials, n_times, self.n_neurons_alm).to(self.device)
        currents_trials = tch.zeros(self.n_trials, n_times, self.n_neurons_alm).to(self.device)
    
        t = self.t_start
        init_cond = self.initial_conditions()
        m_alm = init_cond['m_alm']
        fr_alm = init_cond['fr_alm']
        h_alm = init_cond['h_alm']
        #trials
        m_trials = init_cond['m_trials']
        fr_trials = init_cond['fr_trials']
        h_trials = init_cond['h_trials']
        for i in range(n_times):
            #store variables alm 
            latents_alm[:,i,:] = m_alm
            rates_alm[:,i,:] = fr_alm
            currents_alm[:,i,:] = h_alm
            latents_trials[:,i,:] = m_trials
            rates_trials[:,i,:] = fr_trials
            currents_trials[:,i,:] = h_trials
            #update variables alm left
            m_alm, h_alm, fr_alm = self.update_alm_mean(fr_alm, mean_licks, t)
            if self.is_trial_average==False:
                #update acording single trials
                m_trials, h_trials, fr_trials = self.update_alm_trials(fr_trials,  single_trial_licks, t, trial_types)
            t += self.dt 
        cov_decoder = self.covarainces_decoder()
        results = {'latents_alm': latents_alm,
                    'rates_alm': rates_alm,
                    'currents_alm':currents_alm,
                    'latents_trials': latents_trials,
                    'rates_trials': rates_trials,
                    'currents_trials':currents_trials
                    }
        return results, cov_decoder 




================================================
FILE: legacy_rnn/plotting.py
================================================
import matplotlib.pyplot as plt
import torch as tch
import numpy as np

def plot_loss(epoch, losses, title, tag = ''):
    plt.figure()
    plt.semilogy(range(epoch), losses[:epoch])
    plt.title(title)
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.savefig(tag + '.png',  bbox_inches = 'tight')
    plt.close()


def plot_neurons(net, rates, default_parameters, t_del = -.03, tag = ''):    
    with tch.set_grad_enabled(False):
        y_alm_l = rates['ALM_l']
        y_alm_r = rates['ALM_r']
        input_net = {'ALM_l':y_alm_l}
        results, _ = net(input_net)
        rates_alm_l = results['rates_alm_l']
        rates_alm_r = results['rates_alm_r']
        rates_octx_l = results['rates_octx_l']
        rates_octx_r = results['rates_octx_r']
        rates_alm_l = rates_alm_l.detach().cpu().numpy()
        rates_alm_r = rates_alm_r.detach().cpu().numpy()
        rates_octx_l = rates_octx_l.detach().cpu().numpy()
        rates_octx_r = rates_octx_r.detach().cpu().numpy()
        y_alm_l = y_alm_l.detach().cpu().numpy()
        y_alm_r = y_alm_r.detach().cpu().numpy()
        t_start = default_parameters['t_start']
        dt = default_parameters['dt']
        n_time = y_alm_l.shape[1]
        x = np.linspace(0, n_time, n_time) * dt
        x = x + t_start
        n_neurons = 1000
        for j in range(0, n_neurons,10):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, rates_alm_l[0, :, j], 'r--',  lw =3) 
            plt.plot(x, y_alm_l[0, :, j], 'r-', lw =3) 
            plt.plot(x, rates_alm_l[1, :, j], 'b--',  lw =3) 
            plt.plot(x, y_alm_l[1, :, j], 'b-', lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title("ALM L")
            plt.savefig('out/neuronal_dynamics/neural_ALM_L_'+ tag + '{}.png'.format(j),  bbox_inches = 'tight')
            plt.close()
        for j in range(0, n_neurons,10):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, rates_alm_r[0, :, j], 'r--',  lw =3) 
            plt.plot(x, y_alm_r[0, :, j], 'r-', lw =3) 
            plt.plot(x, rates_alm_r[1, :, j], 'b--',  lw =3) 
            plt.plot(x, y_alm_r[1, :, j], 'b-', lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title('ALM R')
            plt.savefig('out/neuronal_dynamics/neural_ALM_R_'+ tag + '{}.png'.format(j),  bbox_inches = 'tight')
            plt.close()
        for j in range(0, 200,20):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, rates_octx_l[0, :, j], 'r-',  lw =3) 
            plt.plot(x, rates_octx_l[1, :, j], 'b-',  lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title("ALM L")
            plt.savefig('out/neuronal_dynamics/neural_octx_L_'+ tag + '{}.png'.format(j),  bbox_inches = 'tight')
            plt.close()
        for j in range(0, 200,20):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, rates_octx_r[0, :, j], 'r-',  lw =3) 
            plt.plot(x, rates_octx_r[1, :, j], 'b-',  lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title('ALM R')
            plt.savefig('out/neuronal_dynamics/neural_octx_R_'+ tag + '{}.png'.format(j),  bbox_inches = 'tight')
            plt.close()


def plot_latents(net,  rates, default_parameters, t_del = -.03, tag = ''):   
    with tch.set_grad_enabled(False):
        y_alm_l = rates['ALM_l']
        input_net = {'ALM_l':y_alm_l}
        results, _ = net(input_net)
        latents_alm_l = results['latents_alm_l']
        latents_alm_r = results['latents_alm_r']
        latents_alm_l = latents_alm_l.detach().cpu().numpy()
        latents_alm_r = latents_alm_r.detach().cpu().numpy()
     
   
        t_start = default_parameters['t_start']
        dt = default_parameters['dt']
        n_time = y_alm_l.shape[1]
        x = np.linspace(0, n_time, n_time) * dt
        x = x + t_start
        for j in range(latents_alm_l.shape[2]):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, latents_alm_l[0, :, j], 'r-',  lw =3) 
            plt.plot(x, latents_alm_l[1, :, j], 'b-',  lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title("ALM L")
            plt.savefig('out/latents/latents_ALM_L_'+tag + '{}.png'.format(j), bbox_inches = 'tight')
            plt.close()
        for j in range(latents_alm_r.shape[2]):
            plt.figure(figsize=(6, 3))
            plt.axvline(x=net.t_min_input + t_del, color='gray', linestyle='--')
            plt.axvline(x=net.t_go + t_del, color='gray', linestyle='--') 
            plt.axvline(x=net.t_max_input + t_del, color='gray', linestyle='--')
            plt.plot(x, latents_alm_r[0, :, j], 'r-',  lw =3) 
            plt.plot(x, latents_alm_r[1, :, j], 'b-',  lw =3) 
            plt.xlabel('Time (s)')
            plt.ylabel('Mode value')
            plt.title("ALM R")
            plt.savefig('out/latents/latents_ALM_R_'+tag + '{}.png'.format(j), bbox_inches = 'tight')
            plt.close()





================================================
FILE: legacy_rnn/training.py
================================================
import json 
import torch as tch
from losses import *
from model import  SingleTrialLicks 
from plotting import *
from utils_alm import *
import numpy as np
import time
import pickle
import random
from sklearn.model_selection import train_test_split

path_save = '../results/'

#loading hiperparameters data
with open('parameters_list.json') as f:
    default_parameters = json.load(f)


def train(files_list, session_names = [], net_params=None, n_pop=15, hemi='right', max_time_index =275, lr=5e-4, max_epochs = 300000, test_every = 50,  optimize_every = 1, random_seed = 42,  info = ''):
    thres_trial_av = 100
    #coeficient losses
    c_coding_av = .02 #rec neurons
    c_trials_av = 0.65 #rec av rates left
    c_time_av = 0.1666
    c_orth = 500
    c_sel = 0.5


    #loading data    
    mean_licks = mean_licks_inputs(files_list, hemi = hemi, max_time_index = max_time_index) 
    single_trial_licks = licks_inputs(files_list, max_time_index =  max_time_index)
    ALM_hemi= load_me_data(files_list, default_parameters, hemi=hemi, max_time_index=max_time_index)
    trial_average = tch.tensor(ALM_hemi['rates'][0:2,:,:], dtype = tch.float32).to(default_parameters['device']).float()
    print('dimensions', hemi, trial_average.shape, mean_licks.shape)
        
    #loading data    
    total_sessions = len(session_names)
    trial_indexes = {}
    for ses_name in session_names:
        trial_indexes[ses_name] = ALM_hemi['indexes'][ses_name]
    trial_average, trial_types = toch_version_ratates_trial_types(ALM_hemi, default_parameters, session_names)
    # single trial activity
    single_trials_activity = toch_single_trials(session_names, default_parameters, max_time_index = max_time_index)
    #indexes of neurons at each sesions
    indexes_neurons_st = [ALM_hemi['indexes'][s] for s in session_names]
    total_sessions = len(indexes_neurons_st )
    #parameters
    default_parameters['n_latents'] = n_pop
    default_parameters['n_neurons'] = ALM_hemi['rates'].shape[2]
    #trial average
    LossTrials = LossAverageTrials()
    losses_trial_av = np.zeros(max_epochs)
    #loss on the modes
    LossSelectivity = SelectivityLoss(trial_average, default_parameters)
    losses_sel = np.zeros(max_epochs)
    #loss on the orthogonality of the weights
    LossWeights = LossOrthogonality(default_parameters['device']) 
    losses_weights = np.zeros(max_epochs)
    losses_time_av = np.zeros(max_epochs)
    losses_coding_av = np.zeros(max_epochs)
    #Defining losses
    #average over time
    ListLossesTime = [LossAverageTime(default_parameters) for s in session_names]
    #average over neurons
    ListLossesCoding = [SelectivitySingleTrialLoss(trial_average, default_parameters, indexes_neurons_st[s]) for s in range(len(session_names))]

    #number of trials
    n_trials = 0
    for t_type in trial_types:
        n_trials+=len(trial_types[t_type])
    train_idx, test_idx = train_test_split(np.arange(n_trials), test_size=0.2, random_state=random_seed)
    default_parameters['n_trials'] = len(train_idx)
    net = SingleTrialLicks(default_parameters, indexes_neurons_st)
    net.device = default_parameters['device']
    if net_params is not None:
        try:
            net.load_state_dict(tch.load(net_params))
            print('Loading network')
        except:
            print('Different network sizes')
    optimizer = tch.optim.Adam(net.parameters(), lr=lr)
    epoch=0
    min_mean_loss = 50. 
    while epoch<max_epochs:
        #adding initial data
        # NOTE: single_trial_licks is a challenge for stitching, fix before stitch sessions
        net.t_start =  np.random.uniform(-4.35, -2.35)
        ind_t_start = int((-2.35-net.t_start)/net.dt)
        #train dataset
        zeros_insert = tch.zeros((2, len(train_idx), ind_t_start), device = 'cuda') 
        s_trials_licks = single_trial_licks[session_names[0]][:,train_idx,:]
        licks_with_zeros = tch.cat([zeros_insert, s_trials_licks], dim=2)
        #licks 
        zeros_insert = tch.zeros((2, ind_t_start, ALM_hemi['rates'].shape[2]), device = 'cuda') 
        mean_licks_zeros = tch.cat([zeros_insert, mean_licks], dim=1)
        t_types = trial_types[session_names[0]][train_idx]

        results, cov = net.forward(mean_licks_zeros, licks_with_zeros, t_types)
        #Reconsutring neural activity average over trials
        total_trial_average = LossTrials(trial_average, results['rates_alm'][:,ind_t_start:,:])
        losses_trial_av[epoch] = total_trial_average.detach().cpu().numpy()
    
        ##Reconsutring average activity over time
        total_time_average = 0
        for s in range(len(session_names)):
            #trial indexes to compute
            single_trial_neural_activity = single_trials_activity[session_names[s]][train_idx][:,:,indexes_neurons_st[s]]
            total_time_average += ListLossesTime[s](single_trial_neural_activity, results['rates_trials'][:,ind_t_start:,indexes_neurons_st[s]])
        total_time_average = total_time_average/float(total_sessions)
        losses_time_av[epoch] = total_time_average .detach().cpu().numpy()
    
        ##Reconsutring average activity over time
        total_coding_average = 0
        for s in range(len(session_names)):
            #trial indexes to compute
            single_trial_neural_activity = single_trials_activity[session_names[s]][train_idx][:,:,indexes_neurons_st[s]]
            total_coding_average += ListLossesCoding[s](net, single_trial_neural_activity, results['latents_trials'][:,ind_t_start:,:]) # Note: problem here with stitching
        total_coding_average  = total_coding_average /float(total_sessions)
        losses_coding_av[epoch] = total_coding_average.detach().cpu().numpy()

        #Loss orthogonality factors
        total_orth = LossWeights(cov)
        losses_weights[epoch] = total_orth.detach().cpu().numpy()

        #Loss selectivity
        total_selectivity = LossSelectivity(net)
        losses_sel[epoch] = total_selectivity.detach().cpu().numpy()

        # loss input trials
        l2_input_loss = tch.mean(net.input_trial ** 2)


        #defining total loss
        loss_factors =  c_orth * total_orth + c_sel * total_selectivity
        
        if thres_trial_av<losses_trial_av[epoch]:
            loss_reconstruction = total_trial_average
            net.is_trial_average = True
        else:
            net.is_trial_average = False
            loss_reconstruction = c_coding_av * total_coding_average + c_trials_av * total_trial_average + c_time_av * total_time_average
        total_loss = 0.7 * loss_reconstruction + 0.3 * loss_factors + 0.05 * l2_input_loss 
        total_loss= total_loss/ optimize_every

        #mean reconstruction loss
        mean_trial = np.mean(losses_trial_av[max(0, epoch-100):epoch])
        mean_total_loss = total_loss.detach().cpu().numpy()
        mean_time = np.mean(losses_time_av[max(0, epoch-100):epoch])
        mean_coding = np.mean(losses_coding_av[max(0, epoch-100):epoch])
        sel_loss = np.mean(losses_sel[max(0, epoch-100):epoch])
        weights_loss = np.mean(losses_weights[max(0, epoch-100):epoch])
        print(f'Epoch {epoch}'+f'| Total Loss {mean_total_loss}' +f' | Trial Av. = {mean_trial}'+f' | Epoch Av. = {mean_time}'+f' | Coding Av. = {mean_coding}'+ f'| Sel. = {sel_loss}'+f' | Orth. = {np.mean(weights_loss)}' +f' | Inputs = {l2_input_loss.detach().cpu().numpy()}' )
        
        ##optimizing
        optimizer.zero_grad()
        total_loss.backward()
        tch.nn.utils.clip_grad_norm_(net.parameters(),  max_norm=12., norm_type=2)
        optimizer.step()

            
        epoch += 1
        if epoch != 0 and epoch %test_every == 0 and mean_trial < min_mean_loss:
            min_mean_loss = min(min_mean_loss, mean_trial)
            print('saving net')
            name_f = path_save+'net_ALM_'+str(n_pop)+'_rseed_'+str(random_seed)+ '_train.pth'
            tch.save(net.state_dict(), name_f)   
        if epoch != 0 and epoch % test_every == 0:
            # Bundle everything into a single dict (include seed)
            losses_dict = {
                "meta": {
                    "epoch": epoch,
                    "n_pop": n_pop,
                    "test_every": test_every,
                    "random_seed": random_seed,
                },
                "trial_average": losses_trial_av,
                "time_average": losses_time_av,
                "projection": losses_coding_av,
                "weights": losses_weights,
                "selectivity": losses_sel,
            }

            os.makedirs(path_save, exist_ok=True)
            base = f"npop_{n_pop}_rseed_{random_seed}"
            save_path = os.path.join(path_save, f"losses_{base}_train.p")
            with open(save_path, "wb") as f:
                pickle.dump(losses_dict, f)

            # Plot (tag files with seed to avoid overwrites)
            plot_map = {
                "Loss Trial Average":  "trial_average",
                "Loss Epoch Average":  "time_average",
                "Projection Loss":     "projection",
            }
            for name_loss, key in plot_map.items():
                name_file = os.path.join(path_save, f"{key}_{base}")
                plot_loss(epoch, losses_dict[key], name_loss, tag=name_file)

 



================================================
FILE: legacy_rnn/utils.py
================================================
import numpy as np
import os
import pickle
import torch as tch 


#path_dandi = '../data/MAPDANDI/'
path_dandi = '../data/MAPDANDI_Functional/'

def hemi_indexes(data, x_hemi = 5600):
    """
    ccf_x   :  int   # (um)  Left-to-Right (ML axis) --> v axis
    threshold ccf_x 5600
    """
    ml = np.array([ccf[0] for ccf in data['ccf']])
    indexes_right = ml>x_hemi
    indexes_left = ml<=x_hemi
    return indexes_left, indexes_right

def mean_licks_inputs(list_sessions, hemi = 'left', max_time_index = 350, ind_start=50):
    trial_average, indexes = trial_average_all_neurons(list_sessions, hemi = hemi, max_time_index= max_time_index)
    trial_average = tch.tensor(trial_average, dtype = tch.float32).to('cuda').float()
    mean_licks =  tch.zeros_like(trial_average)
    ind_ses = 0
    for file in list_sessions:
        data = pickle.load(open(path_dandi + file,'rb'))
        indexes_left, indexes_right = hemi_indexes(data)
        if hemi=='left':
            indexes_neurons = indexes_left
        else:
            indexes_neurons = indexes_right
        data_bh = pickle.load(open(path_dandi+ file.rstrip('.p') + '_behavior.p', 'rb'))
        m_left_licks = np.mean(data_bh['rates_left_licks'][(data_bh['trial_type']==0) * (data_bh['trial_responses']=='hit'),ind_start:max_time_index + ind_start], axis = 0)
        m_right_licks = np.mean(data_bh['rates_right_licks'][(data_bh['trial_type']==1) * (data_bh['trial_responses']=='hit'),ind_start:max_time_index + ind_start], axis = 0)
        for l in range(ind_ses,ind_ses+np.sum(indexes_neurons)):
            mean_licks[0, :, l] = tch.tensor(m_left_licks, dtype = tch.float32, device = 'cuda')
            mean_licks[1, :, l] = tch.tensor(m_right_licks,dtype = tch.float32, device = 'cuda')
        ind_ses+=np.sum(indexes_neurons)
    return mean_licks

def licks_inputs(list_sessions, max_time_index = 350, ind_start=50):
    licks_per_session = {}
    for file in list_sessions:
        data_bh = pickle.load(open(path_dandi+ file.rstrip('.p') + '_behavior.p', 'rb'))
        left_licks = data_bh['rates_left_licks'][:, ind_start:max_time_index + ind_start]
        right_licks = data_bh['rates_right_licks'][:, ind_start:max_time_index + ind_start]
        sess_licks = np.array([left_licks, right_licks]) 
        sess_licks = tch.tensor(sess_licks, dtype = tch.float32, device = 'cuda')
        licks_per_session[file] = sess_licks
    return licks_per_session

def trial_average_all_neurons(list_sessions, hemi = 'left', max_time_index = 350):
    mean_rates = []
    indexes_list = {}
    s = 0
    for file in list_sessions:
        data = pickle.load(open(path_dandi + file,'rb'))
        indexes_left, indexes_right = hemi_indexes(data)
        if hemi=='left':
            indexes_neurons = indexes_left
        else:
            indexes_neurons = indexes_right
        rates = np.array([data['average_trials_left'][0:max_time_index, indexes_neurons], data['average_trials_right'][0:max_time_index, indexes_neurons]]) 
        mean_rates.append(rates)
        indexes_list[file] = range(s, s + data['average_trials'][:, indexes_neurons].shape[1])
        s+=data['average_trials'][:,indexes_neurons].shape[1]
    if len(list_sessions)>1:
        trial_average = np.concatenate(mean_rates, axis=2)
    else:
        trial_average = rates 
    return trial_average, indexes_list

def time_averages(list_sessions, default_parameters, hemi = 'left'):
    time_averages = {}
    for file in list_sessions:
        data = pickle.load(open(path_dandi + file,'rb'))
        indexes_left, indexes_right = hemi_indexes(data)
        if hemi=='left':
            indexes_neurons = indexes_left
        else:
            indexes_neurons = indexes_right
        t_average = np.einsum('ijk->kij', data['average_time'][:,indexes_neurons,:]) #neuron,condition, trial->condition, trial, neuron
        t_average = tch.tensor(t_average, dtype = tch.float32).to(default_parameters['device']).float()
        time_averages[file] = t_average
    return time_averages

def neurons_averages(list_sessions, default_parameters, hemi = 'left'):
    neurons_averages = {}
    for file in list_sessions:
        data = pickle.load(open(path_dandi+file,'rb'))
        n_average = data['average_neurons']#np.einsum('ijk->jki', data['neurons_average'])
        n_average = tch.tensor(n_average, dtype = tch.float32).to(default_parameters['device']).float()
        neurons_averages[file] = n_average
    return neurons_averages


def number_of_trials(list_sessions):
    """List of number of left and right trials"""
    num_trials = {}
    for file in list_sessions:
        data = pickle.load(open(path_dandi + file,'rb'))
        n_trials = len(data['trial_type'])
        num_trials[file] = n_trials
    return num_trials

def lists_of_trial_types(list_sessions):
    """List of number of left and right trials"""
    trial_types = {}
    for file in list_sessions:
        data = pickle.load(open(path_dandi + file,'rb'))
        trial_types[file] = data['trial_type']
    return trial_types

def lists_of_responses(list_sessions):
    """List of number of left and right trials"""
    trial_responses = {}
    for file in list_sessions:
        data = pickle.load(open(path_dandi + file,'rb'))
        trial_responses[file] = data['trial_responses']
    return trial_responses

def load_me_data(list_sessions, default_parameters, hemi = 'left', max_time_index=350):
    """
    rates: trial average firing rates for correct left and right
    indexes: indexes of neurons for each session
    n_trials: number of trials per session
    trial_types: left or right trials
    time_average: the average over some epochs for each trial
    neuron average: the average over the entire recorded neurons at this session (left and right hemi)
    responses: 'hit, miss, ignore'
    """
    trial_average, indexes = trial_average_all_neurons(list_sessions, hemi = hemi, max_time_index= max_time_index)
    #List of number of trials
    n_trials = number_of_trials(list_sessions)
    trial_types = lists_of_trial_types(list_sessions)
    time_av = time_averages(list_sessions, default_parameters, hemi = hemi)
    neurons_av = neurons_averages(list_sessions, default_parameters)
    responses = lists_of_responses(list_sessions)
    ALM_data = {
        'rates':trial_average,
        'indexes':indexes,
        'n_trials':n_trials,
        'trial_types':trial_types,
        'time_average': time_av,
        'neurons_average':neurons_av,
        'responses':responses
    }
    return ALM_data



def toch_version_ratates_trial_types(ALM_hemi, default_parameters, session_names):
    #only correct trials for training
    rates = tch.tensor(ALM_hemi['rates'][0:2,:,:], dtype = tch.float32).to(default_parameters['device']).float()
    # behavior_lick_times - 0: left lick; 1: right lick
    trial_types = {}
    for ses_name in session_names:
        t_types = ALM_hemi['trial_types'][ses_name]
        t_types = tch.tensor(t_types, dtype = tch.float32).to(default_parameters['device']).float()
        trial_types[ses_name] = t_types
    return rates, trial_types



def toch_single_trials(session_names, default_parameters, max_time_index = 350):
    #only correct trials for training
    single_trials_activity= {}
    for ses_name in session_names:
        data = pickle.load(open(path_dandi + ses_name.rstrip('.p') + '_all_spikes.p', 'rb'))
        data_tensor = tch.tensor(data[:,0:max_time_index,:], dtype = tch.float32).to(default_parameters['device']).float()
        single_trials_activity[ses_name] = data_tensor
    return single_trials_activity



================================================
FILE: results_current/rnn_current_kd95_20220823_205730_0.pt
================================================
[Binary file]


================================================
FILE: results_current/rnn_current_kd95_global_nobs100_nexc400_ntotal500.meta.json
================================================
{
  "animal": "kd95",
  "registry_csv": "/home/jingyi.xu/ALM/results/registry/kd95/kd95_registry.csv",
  "n_exc_virtual": 400,
  "n_obs_inh": 100,
  "n_total": 500,
  "D_in": 6,
  "dt": 0.03436,
  "tau": 0.01,
  "substeps": 4,
  "nonlinearity": "tanh",
  "dale": true,
  "psth_bin_ms": 200.0,
  "sample_ignore_ms": 0.0,
  "resp_sec": 2.0,
  "best_loss": 0.0005070164916105568,
  "unit_sampling": "random",
  "max_sessions": 0
}


================================================
FILE: results_current/rnn_current_kd95_global_nobs100_nexc400_ntotal500.pt
================================================
[Binary file]


================================================
FILE: results_current(200ms)/rnn_current_kd95_20220823_205730_0.pt
================================================
[Binary file]


================================================
FILE: results_current(no reward)/rnn_current_kd95_20220823_205730_0.pt
================================================
[Binary file]


================================================
FILE: results_current1222/rnn_current_kd95_global_nobs100_nexc400_ntotal500.meta.json
================================================
{
  "animal": "kd95",
  "registry_csv": "/home/jingyi.xu/ALM/results/registry/kd95/kd95_registry.csv",
  "n_exc_virtual": 400,
  "n_obs_inh": 100,
  "n_total": 500,
  "D_in": 6,
  "dt": 0.03436,
  "tau": 0.01,
  "substeps": 4,
  "nonlinearity": "tanh",
  "dale": true,
  "psth_bin_ms": 200.0,
  "sample_ignore_ms": 0.0,
  "resp_sec": 2.0,
  "best_loss": 5.3823569032829255e-06,
  "unit_sampling": "random",
  "max_sessions": 0
}


================================================
FILE: results_current1222/rnn_current_kd95_global_nobs100_nexc400_ntotal500.pt
================================================
[Binary file]


================================================
FILE: results_global/eval_kd95/eval_per_unit_rnn_current_kd95_global_nobs100_nexc400_ntotal500.csv
================================================
unit_key,npz_path,K,loss_mse,mse_neuron_mean,mse_neuron_median
20221004_104619.0,/home/jingyi.xu/ALM/results/stage1/kd95/psth_20221004_104619.0.npz,50,0.008829326368868351,0.008829326368868351,0.005080492235720158
20221004_104619.41,/home/jingyi.xu/ALM/results/stage1/kd95/psth_20221004_104619.41.npz,50,0.00859472993761301,0.00859472993761301,0.003085504751652479



================================================
FILE: results_global/eval_kd95/eval_summary_rnn_current_kd95_global_nobs100_nexc400_ntotal500.json
================================================
{
  "animal": "kd95",
  "model": "/home/jingyi.xu/code_rnn/results_current/rnn_current_kd95_global_nobs100_nexc400_ntotal500.pt",
  "registry_dir": "/home/jingyi.xu/ALM/results/registry/kd95",
  "n_units": 2,
  "n_exc_virtual": 400,
  "N_total": 500,
  "D_in": 6,
  "psth_bin_ms": 200.0,
  "sample_ignore_ms": 50.0,
  "resp_sec": 2.0,
  "noise_std": 0.05,
  "loss_mean": 0.00871202815324068,
  "loss_median": 0.00871202815324068,
  "loss_min": 0.00859472993761301,
  "loss_max": 0.008829326368868351,
  "plot_strategy": "best_global_topk",
  "plot_n": 16
}

