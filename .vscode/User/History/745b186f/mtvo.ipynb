{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "from utils import *\n",
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "from losses import *\n",
    "from model import  SingleTrialLicks \n",
    "\n",
    "#stitch all sessions\n",
    "path_dandi= '../data/MAPDANDI_Functional/'\n",
    "directory = os.fsencode(path_dandi)\n",
    "files_list = []\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename[30:31]=='.':\n",
    "        data = pickle.load(open(path_dandi+filename, 'rb'))\n",
    "        if len(data)>0:\n",
    "            n_neurons = data['average_trials'].shape[1]\n",
    "            if n_neurons>0:\n",
    "                files_list.append(filename)\n",
    "\n",
    "#loading hiperparameters data\n",
    "with open('parameters_list.json') as f:\n",
    "    default_parameters = json.load(f)\n",
    "\n",
    "n_pop = 12\n",
    "net = None#'net_ALM_hemi_right8.pth'\n",
    "hemi = 'right' #training on just left hemisphere neurons\n",
    "max_epochs = 4\n",
    "lr=5e-4\n",
    "c_av = 0.7\n",
    "c_orth = 500\n",
    "c_sel = 0.5\n",
    "test_every = 50\n",
    "optimize_every = 1\n",
    "\n",
    "\n",
    "#loading data  \n",
    "max_time_index = 275 \n",
    "mean_licks = mean_licks_inputs(files_list, hemi = hemi, max_time_index = max_time_index) \n",
    "single_trial_licks = licks_inputs(files_list, max_time_index =  max_time_index)\n",
    "ALM_hemi= load_me_data(files_list, default_parameters, hemi=hemi, max_time_index=max_time_index)\n",
    "trial_average = tch.tensor(ALM_hemi['rates'][0:2,:,:], dtype = tch.float32).to(default_parameters['device']).float()\n",
    "print('dimensions', hemi, trial_average.shape, mean_licks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ses_name \u001b[38;5;129;01min\u001b[39;00m session_names:\n\u001b[32m      6\u001b[39m     trial_indexes[ses_name] = ALM_hemi[\u001b[33m'\u001b[39m\u001b[33mindexes\u001b[39m\u001b[33m'\u001b[39m][ses_name]\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m trial_average, trial_types = \u001b[43mtoch_version_ratates_trial_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43mALM_hemi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m indexes_neurons_st = [ALM_hemi[\u001b[33m'\u001b[39m\u001b[33mindexes\u001b[39m\u001b[33m'\u001b[39m][s] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m session_names]\n\u001b[32m     11\u001b[39m total_sessions = \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(indexes_neurons_st ))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/capsule/code/utils.py:154\u001b[39m, in \u001b[36mtoch_version_ratates_trial_types\u001b[39m\u001b[34m(ALM_hemi, default_parameters, session_names)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtoch_version_ratates_trial_types\u001b[39m(ALM_hemi, default_parameters, session_names):\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m#only correct trials for training\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     rates = \u001b[43mtch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mALM_hemi\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrates\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_parameters\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdevice\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.float()\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# behavior_lick_times - 0: left lick; 1: right lick\u001b[39;00m\n\u001b[32m    156\u001b[39m     trial_types = {}\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "session_names = ['sub-456772_ses-20191120T115527.p']\n",
    "#loading data    \n",
    "total_sessions = len(session_names)\n",
    "trial_indexes = {}\n",
    "for ses_name in session_names:\n",
    "    trial_indexes[ses_name] = ALM_hemi['indexes'][ses_name]\n",
    "trial_average, trial_types = toch_version_ratates_trial_types(ALM_hemi, default_parameters, session_names)\n",
    "\n",
    "\n",
    "indexes_neurons_st = [ALM_hemi['indexes'][s] for s in session_names]\n",
    "total_sessions = float(len(indexes_neurons_st ))\n",
    "st_licks = tch.zeros(single_trial_licks[session_names[0]].shape)\n",
    "\n",
    "\n",
    "default_parameters['n_latents'] = n_pop\n",
    "default_parameters['n_neurons'] = ALM_hemi['rates'].shape[2]\n",
    "\n",
    "\n",
    "#trial average\n",
    "LossTrials = LossAverageTrials()\n",
    "losses_trial_av = np.zeros(max_epochs)\n",
    "#loss on the modes\n",
    "LossSelectivity = SelectivityLoss(trial_average, default_parameters)\n",
    "losses_sel = np.zeros(max_epochs)\n",
    "#loss on the orthogonality of the weights\n",
    "LossWeights = LossOrthogonality(default_parameters['device']) \n",
    "losses_weights = np.zeros(max_epochs)\n",
    "losses_time_av = np.zeros(max_epochs)\n",
    "losses_neurons_av = np.zeros(max_epochs)\n",
    "#Defining losses\n",
    "#average over time\n",
    "ListLossesTime = [LossAverageTime(ALM_hemi['indexes'][s], default_parameters) for s in session_names]\n",
    "#average over neurons\n",
    "ListLossesNeurons = [LossAverageNeurons(ALM_hemi['indexes'][s]) for s in session_names]\n",
    "\n",
    "\n",
    "n_trials = 0\n",
    "for t_type in trial_types:\n",
    "    n_trials+=len(trial_types[t_type])\n",
    "default_parameters['n_trials'] = n_trials\n",
    "net = SingleTrialLicks(default_parameters, indexes_neurons_st)\n",
    "net.device = default_parameters['device']\n",
    "\n",
    "\n",
    "epoch=0\n",
    "min_mean_loss = 10. \n",
    "thres_trial_av = 10.\n",
    "mean_loss = 100.\n",
    "while epoch<1:\n",
    "    #adding initial data\n",
    "    results, cov = net.forward(mean_licks, single_trial_licks, trial_types)\n",
    "    #Reconsutring neural activity average over trials\n",
    "    total_trial_average = LossTrials(trial_average, results['rates_alm'])\n",
    "    losses_trial_av[epoch] = total_trial_average.detach().cpu().numpy()\n",
    "    \n",
    "    ##   Reconsutring average activity over neurons\n",
    "    #total_average_neurons = 0\n",
    "    #l=0\n",
    "    #for s in session_names:\n",
    "    #    total_average_neurons += ListLossesNeurons[s](ALM_hemi['neurons_average'][s], results['rates_trials'][indexes_neurons_st[l]])\n",
    "    #    l+=1\n",
    "    #total_average_neurons = total_average_neurons/total_sessions\n",
    "    #losses_neurons_av[epoch] = total_average_neurons.detach().cpu().numpy()\n",
    "    epoch+=1\n",
    "        #Reconsutring average activity over time\n",
    "    #    total_time_average = 0\n",
    "    #    ind_trial = 0\n",
    "    #    total_average_neurons = 0\n",
    "    #    for s in range(total_sessions):\n",
    "            #trial indexes to compute\n",
    "    #        total_time_average += ListLossesTime[s](ALM_hemi['time_average'][s][:,trial_indexes[s],:], results['rates_trials'][ind_trial:ind_trial+d_ind])\n",
    "    #        ind_trial+=d_ind\n",
    "    #    total_time_average = total_time_average/total_sessions\n",
    "    #    losses_time_av[epoch] = total_time_average .detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dandi = '../data/MAPDANDI_Functional/'\n",
    "data_bh = pickle.load(open(path_dandi+ 'sub-456772_ses-20191120T115527' + '_behavior.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "licks = licks_inputs(files_list, max_time_index = 350, ind_start=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 243, 350])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "licks['sub-456772_ses-20191120T115527.p'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ses = load_me_data(['sub-456772_ses-20191120T115527.p'], default_parameters, hemi = 'left', max_time_index=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([243])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ses['n_trials']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(243,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bh['inds_good_trials'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['inds_left_hit', 'inds_right_hit', 'inds_good_trials', 'trial_type', 'trial_responses', 'time_left_licks', 'time_right_licks', 'rates_left_licks', 'rates_right_licks', 'jaw_time_series', 'nose_time_series', 'time_jaw', 'time_nose', 'bins'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bh.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 275, 4244])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_licks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 243, 275])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_trial_licks['sub-456772_ses-20191120T115527.p'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([243, 275, 12])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['latents_trials'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrates_trials\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindexes_neurons_st\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "results['rates_trials'][indexes_neurons_st[l],:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/IPython/core/formatters.py:770\u001b[39m, in \u001b[36mPlainTextFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    763\u001b[39m stream = StringIO()\n\u001b[32m    764\u001b[39m printer = pretty.RepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m.verbose,\n\u001b[32m    765\u001b[39m     \u001b[38;5;28mself\u001b[39m.max_width, \u001b[38;5;28mself\u001b[39m.newline,\n\u001b[32m    766\u001b[39m     max_seq_length=\u001b[38;5;28mself\u001b[39m.max_seq_length,\n\u001b[32m    767\u001b[39m     singleton_pprinters=\u001b[38;5;28mself\u001b[39m.singleton_printers,\n\u001b[32m    768\u001b[39m     type_pprinters=\u001b[38;5;28mself\u001b[39m.type_printers,\n\u001b[32m    769\u001b[39m     deferred_pprinters=\u001b[38;5;28mself\u001b[39m.deferred_printers)\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m \u001b[43mprinter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    771\u001b[39m printer.flush()\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stream.getvalue()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/IPython/lib/pretty.py:411\u001b[39m, in \u001b[36mRepresentationPrinter.pretty\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    400\u001b[39m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[32m    401\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    402\u001b[39m                     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\n\u001b[32m    403\u001b[39m                     \u001b[38;5;66;03m# check if cls defines __repr__\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    409\u001b[39m                     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(_safe_getattr(\u001b[38;5;28mcls\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m__repr__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    410\u001b[39m                 ):\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/IPython/lib/pretty.py:786\u001b[39m, in \u001b[36m_repr_pprint\u001b[39m\u001b[34m(obj, p, cycle)\u001b[39m\n\u001b[32m    784\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[32m    785\u001b[39m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m786\u001b[39m output = \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    787\u001b[39m lines = output.splitlines()\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m p.group():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/_tensor.py:463\u001b[39m, in \u001b[36mTensor.__repr__\u001b[39m\u001b[34m(self, tensor_contents)\u001b[39m\n\u001b[32m    459\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    460\u001b[39m         Tensor.\u001b[34m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents=tensor_contents\n\u001b[32m    461\u001b[39m     )\n\u001b[32m    462\u001b[39m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_tensor_str\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/_tensor_str.py:698\u001b[39m, in \u001b[36m_str\u001b[39m\u001b[34m(self, tensor_contents)\u001b[39m\n\u001b[32m    696\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad(), torch.utils._python_dispatch._disable_current_modes():\n\u001b[32m    697\u001b[39m     guard = torch._C._DisableFuncTorch()\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/_tensor_str.py:618\u001b[39m, in \u001b[36m_str_intern\u001b[39m\u001b[34m(inp, tensor_contents)\u001b[39m\n\u001b[32m    616\u001b[39m                     tensor_str = _tensor_str(\u001b[38;5;28mself\u001b[39m.to_dense(), indent)\n\u001b[32m    617\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m618\u001b[39m                     tensor_str = \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layout != torch.strided:\n\u001b[32m    621\u001b[39m     suffixes.append(\u001b[33m\"\u001b[39m\u001b[33mlayout=\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.layout))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/_tensor_str.py:350\u001b[39m, in \u001b[36m_tensor_str\u001b[39m\u001b[34m(self, indent)\u001b[39m\n\u001b[32m    346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[32m    347\u001b[39m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[32m    348\u001b[39m     )\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m     formatter = _Formatter(\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m summarize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    351\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/_tensor_str.py:386\u001b[39m, in \u001b[36mget_summarized_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    384\u001b[39m     start = [\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, PRINT_OPTS.edgeitems)]\n\u001b[32m    385\u001b[39m     end = [\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - PRINT_OPTS.edgeitems, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))]\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.stack([\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (start + end)])\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.stack([get_summarized_data(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/_tensor_str.py:386\u001b[39m, in \u001b[36mget_summarized_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    384\u001b[39m     start = [\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, PRINT_OPTS.edgeitems)]\n\u001b[32m    385\u001b[39m     end = [\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - PRINT_OPTS.edgeitems, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))]\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.stack([\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (start + end)])\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.stack([get_summarized_data(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/torch/_tensor_str.py:376\u001b[39m, in \u001b[36mget_summarized_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dim == \u001b[32m1\u001b[39m:\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.size(\u001b[32m0\u001b[39m) > \u001b[32m2\u001b[39m * PRINT_OPTS.edgeitems:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mPRINT_OPTS\u001b[49m\u001b[43m.\u001b[49m\u001b[43medgeitems\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[43mPRINT_OPTS\u001b[49m\u001b[43m.\u001b[49m\u001b[43medgeitems\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    380\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "results['rates_trials']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
